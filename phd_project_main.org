#+STARTUP: hideblocks
#+PROPERTY: header-args :eval never-export
#+OPTIONS: ^:{}

#+SETUPFILE: /home/lucas/org-html-themes-master/org/theme-readtheorg-local.setup
#+HTML_HEAD: <style>pre.src {background-color: #3F3F3F ; color: #e5e5e5;}</style>

#+TITLE:  Integration of different Omics Data
#+AUTHOR: Lucas Michel TodÃ³
#+EMAIL:  lucas.michel@isglobal.org
#+DATE:   10/12/2018

#+LaTeX: \pagebreak

* Introduction
This is a working draft of my PhD project.

#+LaTeX: \pagebreak
* Chip-Seq Data
** Pre-processing
*** Reads Quality Control
The first step is to evaluate the quality of the reads using ~fastqc~
We check the report for any possible problem in the data.
#+begin_example
$fastqc ./*\.fastq
#+end_example
*** Clean reads: BBDUK
The next step is to "clean" the read files using ~BBDUK~
#+begin_src python :tangle ./Scripts/raw_reads_to_bam.py
import subprocess as sp
import os

## Functions

def call_BBDUK(in1, in2, out1, out2, outm, ref, params):
    cmd = ("bbduk.sh in={} in2={} "
           "out={} out2={} outm={} "
           "ref={}") .format(in1, in2, out1, out2, outm, ref)

    cmd = cmd+" "+params
    sp.call(cmd, shell=True)

## Calls

params = "ktrim=r k=22 mink=6 overwrite=t"
ref = "/home/lucas/Programs/bbmap/resources/adapters.fa"

root_path = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Raw_Data/"
read1s = []
read2s = []
for path, subdirs, files in os.walk(root_path):
    for f in files:
        if all(x in f for x in ["read1", ".fastq"]):
            read1s.append(os.path.join(path, f))
        elif all(x in f for x in ["read2", ".fastq"]):
            read2s.append(os.path.join(path, f))
        else:
            print(f)


read1s = sorted(read1s)
read2s = sorted(read2s)
outpath = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Clean_Reads/"

for pair in zip(read1s, read2s):
    in1, in2 = pair[0], pair[1]
    out1 = outpath + pair[0].rsplit("/", 1)[1].replace(".fastq", "_clean.fastq")
    out2 = outpath + pair[1].rsplit("/", 1)[1].replace(".fastq", "_clean.fastq")
    outm = outpath + pair[0].rsplit("/", 1)[1].replace(".fastq", "_badreads.fastq")
    call_BBDUK(in1, in2, out1, out2, outm, ref, params)
#+end_src
*** Align Reads: Bowtie2
For each pair of .fastq read files we create an aligned BAM file.
#+begin_src python :tangle ./Scripts/raw_reads_to_bam.py
## Funtions

def call_Bowtie2(in1, in2, out, params):
    cmd = "bowtie2 -1 {} -2 {} -S {}" .format(in1, in2, out)
    cmd = cmd+" "+params
    print(cmd)
    sp.call(cmd, shell=True)

## Calls
params = ("-p 4 --very-sensitive --local "
          "-5 4 -3 4 -I 50 -X 200 "
          "-x /home/lucas/Programs/bowtie2-2.3.0-legacy/Pf3D7")

inpath = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Data/Clean_Reads/"
# files = [f for f in os.listdir(inpath)if f.endswith("_clean.fastq.gz")]

# read1s = sorted([f for f in files if "read1" in f])
# read2s = sorted([f for f in files if "read2" in f])

read1s = ['i10-E5HAme_26899_TAGCTT_read1_clean.fastq.gz',
          'i2-E5HAin_26891_CGATGT_read1_clean.fastq.gz',
          'i6-E5HAac_26895_GCCAAT_read1_clean.fastq.gz']

read2s = ['i10-E5HAme_26899_TAGCTT_read2_clean.fastq.gz',
          'i2-E5HAin_26891_CGATGT_read2_clean.fastq.gz',
          'i6-E5HAac_26895_GCCAAT_read2_clean.fastq.gz']

outpath = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Data/Current/"

for pair in zip(read1s, read2s):
    name = pair[0].split("_")[0]

    in1, in2 = inpath+pair[0], inpath+pair[1]
    #out = inpath+name+".sam"
    out = outpath+name+".sam"
    call_Bowtie2(in1, in2, out, params)
#+end_src
*** From SAM to BAM
Convert to human-readable sam format to binary bam format.
#+begin_src python :tangle ./Scripts/raw_reads_to_bam.py
import subprocess as sp
import sys
from tqdm import tqdm

## Functions

def from_sam_to_bam(samfile):
    name = samfile.rsplit(".")[0]
    cmd = "samtools view -bS {} > {}" .format(samfile, name+".bam")
    sp.call(cmd, shell=True)

    ### Erase SAM after creating BAM
    # cmd = "rm {}" .format(samfile)
    # sp.call(cmd, shell=True)

    cmd = "samtools sort {} > {}" .format(name+".bam", name+"_sort.bam")
    sp.call(cmd, shell=True)

    ### Erase bam after creating sortedBAM
    cmd = "rm {}" .format(name+".bam")
    sp.call(cmd, shell=True)

    cmd = "samtools index {} > {}" .format(name+"_sort.bam", name+"_sort.bam.bai")
    sp.call(cmd, shell=True)

    ## Filter only >=q5 reads
    cmd = "samtools view -b -q 5 {} > {}" .format(name+"_sort.bam", name+"_q5_sort.bam")
    sp.call(cmd, shell=True)

## Calls

#indir = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Data/Bams/"
indir = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Data/New_Bams/"
samfiles = [f for f in os.listdir(indir) if f.endswith(".sam")]

for f in tqdm(samfiles):
    sam = indir+f
    from_sam_to_bam(sam)

#+end_src
*** Remove Duplicates
We finally use ~RemoveDuplicates~ from the ~PICARD~ suite to prune any
duplicated reads.
#+begin_src python :tangle ./Scripts/raw_reads_to_bam.py
import os

def remove_duplicates(indir, outdir, bam):

    i = indir+bam
    o = outdir+bam.replace(".bam", "_noDup.bam")
    m = outdir+bam.replace(".bam", "_metrics.txt")

    cmd = ("java -jar /home/lucas/Programs/picard.jar MarkDuplicates "
           "REMOVE_DUPLICATES=true I={} O={} M={}") .format(i, o, m)

    sp.call(cmd, shell=True)

# indir = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Data/Bams/"
# bams = sorted([b for b in os.listdir(indir) if b.endswith(".bam")])
# outdir = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Data/New_Coverage/NoDupBams/"


indir = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Data/Current/"
bams = sorted([b for b in os.listdir(indir) if b.endswith("q5_sort.bam")])
outdir = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Data/Current/"

for bam in bams:
    remove_duplicates(indir, outdir, bam)
#+end_src
** Files description
This are all the files generated by analyzing the ChIP-Sequencing data we have.
*** Folders
**** Bams
BAM format raw alignments. This files represent the alignment of the obtained reads to the reference genome, without further processing.
**** RPKMs
Reads per kilo-base million reads. For each sample (IP and input) we calculate the RPKMs in 100bp bins. This files can bu used to visualize the normalized by number of reads coverage for each sample.
**** RPKMs_normInput
Normalized by input RPKMs. We first calculate RPKMs as above, and we then normalize by input. Coverage is calculated as log2(IP_rpkm/input_rpkm). This files can be use to visualize the normalized (by number of reads and input) coverage.
**** Peak_Calling_MACS2
We use MACS2 to make the peak-calling for all samples. In this folder there are all the files generated by MACS2. The ..._Macspeaks_peaks.xls are the tables with the peaks you are probably looking for.
**** DiffPeaks_MACS2callpeaks
"Old" differential peaks approach. Here we use MACS2 peak-caller (just as in the individual peak-callings) but we use one sample IP as IP, and another sample IP as input. Peak files generated by  this process are in this folder. Peaks in sample A over sample B appear in the file A_over_B_difpeaks_peaks.xls.
**** DiffPeaks_MACS2callpeaks_OverlappedAndFiltered
The files obtained in the previous folder are filtered using a fold-change threshold (fc >= 2) and overlapped with their corresponding individual peak-callings. This means that if a peak is called in the sample A over sample B contrast, we make sure that it also appears as a peak in the sample A individual (vs input) peak-calling. The files are stored both in csv and bed formats.
**** DiffPeaks_BdgDiff
Differential peaks called using MACS2 bdgdiff subcommand. For each contrast a file with peaks in condition1, condition2 and common is created. Condition1 always corresponds to the first sample in the filename. For example, file A_vs_B_g200_l150_c1_c1.0_cond1.bed contains the differential peaks in sample A (while cond2 will have the peaks in sample B).
**** DiffPeaks_BdgDiff_BetaFit
Filtered peaks obtained from the previous MACS2 bdgdiff call. To filter them, we use a probabilistic approach. The main idea is that we retain only the most extreme scoring peaks regarding the peaks score distribution.

The whole process is the following: we first use a quantile based approach to remove outliers in the peaks score distribution. We then fit a beta distribution to the resulting pruned scores. We use this fitted beta to retain only peaks that are above the score that accumulates certain probability (0.99).
**** DiffPeaks_BdgDiff_CrossOld
Filtered peaks obtained from the previous MACS2 bdgdiff call. In this case, we retain only the peaks that overlap a peak called using the "old" differential-peaks approach of using the "normal" MACS2 peak-caller with one sample as IP and another as input. The same betafit method as above is used with a more stringent threshold (0.999) to retain the highest scoring peaks that do not overlap any peak called with the "old" method.
**** Duplication_Deletion_Regions
Bed files defining, for each pair of samples, regions of the genome that are considered either duplications or deletions. The approach used to generate this files consists in making the subtraction between both samples inputs and detecting regions with outlier values (both samples inputs should be only different in scale and therefor, in absence of deletions/insertions, the subtraction should remain more or less constant).
**** BetaFit_DuplDel_Filtered
Peak files obtained in the DiffPeaks_BdgDiff_BetaFit, filtered to remove those peaks that overlap a duplication/deletion region as defined in the previous step. This is the final differential peaks file for this method.
**** CorssOld_DuplDel_Filtered
Peak files obtained in the DiffPeaks_BdgDiff_CrossOld, filtered to remove those peaks that overlap a duplication/deletion region as defined in the previous step. This is the final differential peaks file for this method.

** Scripts
Here are all the scripts used to generate the files.
*** Functions
Here we define the functions we will be using in the rest of the script.
#+begin_src python :tangle whole_chipseq_pipe.py
#### Functions ####
import subprocess
import os
import itertools
import pybedtools as pb
import subprocess as sp
import numpy as np
import matplotlib.pyplot as plt
import scipy.stats
import pandas as pd
import itertools

## Functions
def get_RPKMs(bam, out):

    cmd = ('bamCoverage -b {} '
       '--outFileFormat bedgraph '
       '--normalizeUsing RPKM '
       '-p 8 '
       '-bs 100 '
       '-o {}')

    subprocess.call(cmd .format(bam, out), shell=True)


def get_RPKMs_normInput(bam_IP, bam_in, bs, out):

    cmd = ('bamCompare -b1 {} -b2 {} '
       '--outFileFormat bedgraph '
       '--scaleFactorsMethod None '
       '--normalizeUsing RPKM '
       '-p 8 '
       '-bs {} '
       '-o {}')

    subprocess.call(cmd .format(bam_IP, bam_in, bs, out), shell=True)

def subtract_bams(bam1, bam2, outname):

    cmd = ('bamCompare -b1 {} -b2 {} '
           '--operation subtract '
           '-bs 100 '
           '-p 8 '
           '--outFileFormat bedgraph '
           '--scaleFactorsMethod None '
           '--normalizeUsing RPKM '
           '--smoothLength 500 '
           '-o {}')
    sp.call(cmd .format(bam1, bam2, outname), shell=True)


def getName(filename):
    if '/' in filename:
        filename = filename.rsplit("/", 1)[1] #Remove path
    out = filename.split("_", 1)[0] #Remove added names
    return(out)


def getDepth(peaksfile):
    dlist = []
    with open(peaksfile) as f:
        for line in f:
            if line.startswith("# total fragments "):
                d = line.split(":")[1].strip()
                dlist.append(int(d))
    depth = int(round(min(dlist) / 1000000))
    return(str(depth))


def macs2callpeak(t, c, params):

    # Make sure we are using apropiate MACS2 version (2.1.2)
    print("You are using MACS version:")
    cmd = "macs2 --version"
    subprocess.call(cmd, shell=True)
    print("\n")

    cmd = ("macs2 callpeak -t {} -c {} ") .format(t, c) + params

    subprocess.call(cmd, shell=True)


def macs2DifPeaks(t1, c1, t2, c2, g, l, c, outdir):

    # Make sure we are using apropiate MACS2 version (2.1.2)
    print("You are using MACS version:")
    cmd = "macs2 --version"
    subprocess.call(cmd, shell=True)
    print("\n")

    t1pile = getName(t1) + "_me_Macspeaks_treat_pileup.bdg"
    c1pile = getName(t1) + "_me_Macspeaks_control_lambda.bdg"

    t2pile = getName(t2) + "_me_Macspeaks_treat_pileup.bdg"
    c2pile = getName(t2) + "_me_Macspeaks_control_lambda.bdg"

    peaks1 = getName(t1) + "_me_Macspeaks_peaks.xls"
    peaks2 = getName(t2) + "_me_Macspeaks_peaks.xls"

    d1 = getDepth(peaks1)
    d2 = getDepth(peaks2)

    prefix = getName(t1)+"_vs_"+getName(t2)+"_g{}_l{}_c{}" .format(g,l,c)

    cmd = ("macs2 bdgdiff "
           "--t1 {} --c1 {} "
           "--t2 {} --c2 {} "
           "--d1 {} --d2 {} "
           "--outdir {} "
           "--o-prefix {} "
           "-g {} -l {} --cutoff {}") .format(t1pile, c1pile,
                                              t2pile, c2pile,
                                              d1, d2,
                                              outdir,
                                              prefix,
                                              g, l, c)

    print(cmd)
    subprocess.call(cmd, shell=True)

def manormDifPeaks(peaks1, peaks2, reads1, reads2, params):

    #Check which MaNorm version we are using:
    print("\n")
    print("You are using MANorm version:")
    cmd = "manorm --version"
    subprocess.call(cmd, shell=True)
    print("\n")

    cmd = ("manorm --p1 {} --p2 {} --r1 {} --r2 {} ") .format(peaks1, peaks2,
                                                              reads1, reads2)
    cmd = cmd + params
    subprocess.call(cmd, shell=True)

def create_log2_tracks(treat, ctl):
    outfile = treat.replace('.bam', '_log2.bdg')
    cmd = 'bamCompare -b1 {} -b2 {} -o {} -of bedgraph -p8' .format(treat, ctl, outfile)
    subprocess.call(cmd, shell=True)

#+end_src
*** Dirs and variables
We set the working directory and create some variables to store the BAM files.
#+begin_src python :tangle whole_chipseq_pipe.py
#### Set directories and variables ####

#wd = '/mnt/Disc4T/Projects/Chip_Seq_Data_2021/'
wd = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/'
os.chdir(wd)

#bamdir = '/mnt/Disc4T/Projects/Chip_Seq_Data_2021/Bams/'
bamdir = './Bams/'
bams = [b for b in os.listdir(bamdir) if b.endswith('_sort_q5.bam')]
IPs = [f for f in bams if '_me_' in f or '_ac_' in f]
IPs.sort()
inputs = [f for f in bams if '_in_' in f]
inputs.sort()
me_files = [f for f in bams if '_me_' in f]
me_files.sort()
ac_files = [f for f in bams if '_ac_' in f]
ac_files.sort()

#+end_src
*** Calls
**** Sample-wise
***** Get RPKMs
We use DeepTools to get raw and normalized by input RPKMs per sample.
#+begin_src python :tangle whole_chipseq_pipe.py
#### Get RPKMs ####
os.makedirs('./RPKMs', exist_ok=True)
outdir = './RPKMs/'

for bam in bams:
    out = outdir+bam.replace('.bam', '_RPKMs.bdg')
    get_RPKMs(bamdir+bam, out)

#### Get normalized by input RPKMs ####
os.makedirs('./RPKMs_normInput', exist_ok=True)
outdir = './RPKMs_normInput/'

for ip in IPs:
    prefix = ip.split('_')[0]
    inpt = [f for f in inputs if prefix in f][0]
    print(ip, inpt)
    pair = [ip, inpt]
    out = outdir+pair[0].replace('.bam', '_RPKMs_normInput.bdg')
    get_RPKMs_normInput(bamdir+pair[0],
                        bamdir+pair[1],
                        50,
                        out)
#+end_src
***** Call Peaks
We use MACS2 to make the peak-calling for all samples.
#+begin_src python :tangle whole_chipseq_pipe.py
#### Peak-Calling ####

os.makedirs('./Peak_Calling_MACS2', exist_ok=True)
outdir = './Peak_Calling_MACS2/'

params_form = ("-f BAMPE -B "
               "-g 2.41e7 "
               "--keep-dup all "
               "--fe-cutoff 1.5 "
               "--nomodel "
               "--extsize 150 "
               "-n {} "
               f"--outdir {outdir}")

for ip in IPs:
    prefix = ip.split('_')[0]
    inpt = [f for f in inputs if prefix in f][0]
    print(ip, inpt)
    pair = [ip, inpt]

    t = bamdir + pair[0]
    c = bamdir + pair[1]
    name = pair[0].split("_")[0]+'_'+pair[0].split("_")[1]+"_Macspeaks"
    params = params_form .format(name)

    macs2callpeak(t, c, params)

    print("==============================")
    print("Finished {}!" .format(name))
    print("==============================\n\n\n")
#+end_src
***** Get 3prime, ORF, and 5prime coverage
****** Previous Steps
#+begin_src python :tangle binned_coverage.py
# Create genome dict
genome={}
genome_file = './PlasmoDB-46_Pfalciparum3D7_Genome.fasta'
with open(genome_file, 'r+') as infile:
    for line in infile:
        if line.startswith('>'):
            linelist = line.strip().split(' | ')
            chrom = linelist[0].replace('>', '')
            seize = linelist[3].replace('length=', '')
            genome[chrom] = (0, int(seize))

# Import GFF
gff_file = './PlasmoDB-46_Pfalciparum3D7_withGDV1_ncRNAs.gff'
gff = pb.BedTool(gff_file)

## Filter genes only
sel = ['gene', 'asRNA', 'lncRNA']#, "rRNA", "snoRNA", "snRNA", "tRNA", "ncRNA"]
gene_gff = gff.filter(lambda x: x.fields[2] in sel)

## Discard Apicoplast
gene_gff = gene_gff.filter(lambda x: x.chrom != 'Pf3D7_API_v3')
gene_gff.saveas('filtered_only_genes.gff')

## Sort Gene-GFF
cmd = 'python ./gff_sorter.py filtered_only_genes.gff > filtered_only_genes_sorted.gff'
sp.call(cmd, shell=True)
#+end_src
****** Get binned GFF
For each gene we want to select the preceding 1000bp (3'), the coding region and the following 1000bp (5').
#+begin_src python :tangle whole_chipseq_pipe.py

def cut_3_CDS_5(gff, three=1000, five=1000):

    ref = pb.BedTool(gff)
    current_chrom = ''
    ngenes = len(ref)
    str_bed = ''
    first_in_chrom = False
    last_in_chrom = False

    for idx, gene in enumerate(ref):

        ## Check Orientation:
        strain = gene.fields[6]

        ## Check if first/last in chromosome
        chrom = gene.chrom

        ## Get Gene_id
        gid = gene.fields[8].split(';')[0].replace('ID=', '')

        ## Set 3prime, and 5prime (ORF is already defined)
        if current_chrom != chrom:
            first_in_chrom = True
            # print('First in chrom!')
            # print(gene)
            # print('---------------')

        if idx == ngenes-1:
            ## First check if we are in the last gene!
            last_in_chrom = True
        else:
            if ref[idx+1].chrom != chrom:
                last_in_chrom = True

        ## Set new starts and new stops (3prime, 5prime) depending on strain:
        if strain == '+':
            start_3 = gene.start-three
            stop_3 = gene.start
            start_5 = gene.stop
            stop_5 = gene.stop+five
        else:
            start_3 = gene.stop
            stop_3 = gene.stop+three
            start_5 = gene.start-five
            stop_5 = gene.start

        ## Check overlapp previous and following genes
        if strain == '+':
            if first_in_chrom:
                pass
            else:
                if  start_3 < ref[idx-1].stop:
                    start_3 = ref[idx-1].stop+1

            if last_in_chrom:
                pass
            else:
                if stop_5 > ref[idx+1].start:
                    stop_5 = ref[idx+1].start-1

            # print('Previous gene:')
            # print(ref[idx-1])
            # print('Current gene:')
            # print(gene)
            # print('New start-stop:')
            # print(newstart, newstop)
            # print('--------------------------')
        else:
            if first_in_chrom:
                pass
            else:
                if  start_5 < ref[idx-1].stop:
                    start_5 = ref[idx-1].stop+1

            if last_in_chrom:
                pass
            else:
                if stop_3 > ref[idx+1].start:
                    stop_3 = ref[idx+1].start-1

            # print('Next gene:')
            # print(ref[idx+1])
            # print('Current gene:')
            # print(gene)
            # print('New start-stop:')
            # print(newstart, newstop)
            # print('--------------------------')

        ## Check we dont go < 0
        if start_3 < 0: start_3 = 0
        if start_5 < 0: start_5 = 0

        ## Check we don't go > chrom length
        if stop_3 > genome[chrom][1]: stop_3 = genome[chrom][1]
        if stop_5 > genome[chrom][1]: stop_5 = genome[chrom][1]

        ## Check start always < stop
        if start_3 >= stop_3: stop_3 = start_3+1
        if start_5 >= stop_5: stop_5 = start_3+1


        first_in_chrom = False
        last_in_chrom = False
        current_chrom = chrom

        if strain == '+':
            newline = [gene.chrom, start_3, stop_3, gid+'_3prime']
            newline = [str(x) for x in newline]
            str_bed += '\t'.join(newline)+'\n'

            newline = [gene.chrom, gene.start, gene.stop, gid]
            newline = [str(x) for x in newline]
            str_bed += '\t'.join(newline)+'\n'

            newline = [gene.chrom, start_5, stop_5, gid+'_5prime']
            newline = [str(x) for x in newline]
            str_bed += '\t'.join(newline)+'\n'
        else:
            newline = [gene.chrom, start_5, stop_5, gid+'_5prime']
            newline = [str(x) for x in newline]
            str_bed += '\t'.join(newline)+'\n'

            newline = [gene.chrom, gene.start, gene.stop, gid]
            newline = [str(x) for x in newline]
            str_bed += '\t'.join(newline)+'\n'

            newline = [gene.chrom, start_3, stop_3, gid+'_3prime']
            newline = [str(x) for x in newline]
            str_bed += '\t'.join(newline)+'\n'



    out_bed = pb.BedTool(str_bed, from_string=True)
    return(out_bed)

ref = './filtered_only_genes_sorted.gff'
binned_bed = cut_3_CDS_5(ref)
binned_bed.saveas('binned_1000_3prime_1000_5prime.bed')



#+end_src
**** Pair-wise
***** Differential peaks using MACS2 'callpeak'
In this approach differential peaks are called using one sample as input and another sample as control (as if it was an input) and using the 'normal' MACS2 peakcaller.

#+BEGIN_SRC python :tangle whole_chipseq_pipe.py

os.makedirs('./RPKMs_normInput', exist_ok=True)
outdir = './DiffPeaks_MACS2callpeak/'

# Call PeakCalling
params_form = ("-f BAMPE -B "
               "-g 2.41e7 "
               "--keep-dup all "
               "--fe-cutoff 1.5 "
               "--nomodel "
               "--extsize 150 "
               "-n {} "
               f"--outdir {outdir}")

contrasts = list(itertools.permutations(me_files, 2))

for pair in contrasts:

    t = bamdir + pair[0]
    c = bamdir + pair[1]
    name = pair[0].split("_")[0]+"_over_"+pair[1].split("_")[0]+"_difpeaks"
    params = params_form .format(name)

    macs2callpeak(t, c, params)

    print("==============================")
    print("Finished {}!" .format(name))
#+END_SRC
***** Filter and Overlap peaks
As postprocessing of MACS2 differential peak calling we can apply this two small scripts:
- peak_overlapper.py : This overlaps two peaks.xls files (from macs2). The peaks on the first file will only be reatained if they overlap a peak in the second file. Afterwards it can apply filters to FE and/or qval.
- csv_to_bed.py : This simply converts a peaks.xls file (from macs2) into bed format. (for visualitzation for example).

#+BEGIN_SRC python :tangle whole_chipseq_pipe.py
## Overlap and Filter

difpeaksdir = './DiffPeaks_MACS2callpeak/'

cmd = 'python3 ./peak_overlapper.py -p1 {} -p2 {} -f 2'

dif_peaks = [f for f in os.listdir(difpeaksdir) if f.endswith('_difpeaks_peaks.xls')]
dif_peaks.sort()

for f in dif_peaks:
    ref_peaks = './Peak_Calling_MACS2/'+f.split('_')[0]+'_me_Macspeaks_peaks.xls'

    print(cmd .format(difpeaksdir+f, ref_peaks))
    subprocess.call(cmd .format(difpeaksdir+f, ref_peaks), shell=True)


## Convert to Bed
cmd = 'python3 ./csv_to_bed.py {}'

overlaps = [f for f in os.listdir(difpeaksdir) if f.endswith('overlappandfilter.csv')]

for f in overlaps:
    print(cmd .format(difpeaksdir+f))
    subprocess.call(cmd .format(difpeaksdir+f), shell=True)

## Create output folders and move files there

os.makedirs('./DiffPeaks_MACS2callpeak_OverlappedAndFiltered/', exist_ok=True)
cmd = ('mv ./DiffPeaks_MACS2callpeak/*overlappandfilter* '
       './DiffPeaks_MACS2callpeak_OverlappedAndFiltered')

subprocess.call(cmd, shell=True)
#+END_SRC
***** Call BdgDiff
In this approach we use the MACS2 differential peaks subcomand BdgDiff. We use a low threshold because peaks will be filtered in posterior steps.
#+begin_src python :tangle whole_chipseq_pipe.py
#### Call BdgDiff ####

path_chips = [bamdir + c for c in me_files]
path_inputs = [bamdir + i for i in inputs]

# Ensure same ordering (by name)
path_chips = sorted(path_chips)
path_inputs = sorted(path_inputs)

## Differential Peak-Calling
pairs = zip(path_chips, path_inputs)
difs = list(itertools.combinations(pairs, 2))

## Change to input dir and set outdir

os.chdir('./Peak_Calling_MACS2')
os.makedirs('../DiffPeaks_BdgDiff', exist_ok=True)
outdir = '../DiffPeaks_BdgDiff/'

for dif in difs:
    g, l, c = 200, 150, 1
    macs2DifPeaks(dif[0][0], dif[0][1], dif[1][0], dif[1][1], g, l, c, outdir)

os.chdir('../')
#+end_src
***** Call BdgDiff default params
In this approach we use the MACS2 differential peaks subcomand BdgDiff with default params to compare.
#+begin_src python :tangle whole_chipseq_pipe.py
#### Call BdgDiff ####

path_chips = [bamdir + c for c in me_files]
path_inputs = [bamdir + i for i in inputs]

# Ensure same ordering (by name)
path_chips = sorted(path_chips)
path_inputs = sorted(path_inputs)

## Differential Peak-Calling
pairs = zip(path_chips, path_inputs)
difs = list(itertools.combinations(pairs, 2))

## Change to input dir and set outdir

os.chdir('./Peak_Calling_MACS2')
os.makedirs('../DiffPeaks_BdgDiff_default_params', exist_ok=True)
outdir = '../DiffPeaks_BdgDiff_default_params'

for dif in difs:
    g, l, c = 100, 200, 3
    macs2DifPeaks(dif[0][0], dif[0][1], dif[1][0], dif[1][1], g, l, c, outdir)

os.chdir('../')
#+end_src
***** Filter BdgDiff Peaks
We filter the peaks obtained in the previous BdgDiff call. Two kinds of filters are applied:
- BetaFit: We first use a quantile based approach to remove outliers in the peaks score distribution. We then fit a beta distribution to it. We use this fitted beta to retain only peaks that are above the score that accumulates certain probability (0.99).
- CrossOld: We retain only the peaks that overlap a peak called using the "old" differential-peaks approach of using the "normal" MACS2 peak-caller with one sample as IP and another as input. The same betafit method as above is used with a more stringent threshold (0.999) to retain the highest scoring non-overlapping peaks.
#+begin_src python :tangle whole_chipseq_pipe.py
me_files
me_names = [getName(f) for f in me_files]
difs = list(itertools.permutations(me_names, 2))

oldFC = 20

betafld = './DiffPeaks_BdgDiff_BetaFit/'
os.makedirs(betafld, exist_ok=True)

crossoldfld = './DiffPeaks_BdgDiff_CrossOld/'
os.makedirs(crossoldfld, exist_ok=True)

for pair in difs:

    print(pair)

    bedfiles = os.listdir('./DiffPeaks_BdgDiff/')
    subset = [f for f in bedfiles if pair[0]+'_' in f and pair[1]+'_' in f]
    if subset[0].startswith(pair[0]):
        bed = './DiffPeaks_BdgDiff/{}_vs_{}_g200_l150_c1_c1.0_cond1.bed'
        bedname = bed .format(*pair)
    else:
        bed = './DiffPeaks_BdgDiff/{}_vs_{}_g200_l150_c1_c1.0_cond2.bed'
        bedname = bed .format(pair[1], pair[0])

    overbed = ('./DiffPeaks_MACS2callpeak_OverlappedAndFiltered/'
               '{}_over_{}_difpeaks_peaks_{}_overlappandfilter.bed')

    overbedname = overbed .format(*pair, oldFC)

    bed = pb.BedTool(bedname)
    overbed = pb.BedTool(overbedname)

    ## Set dinamic filter based on Beta distribution

    cumprobs = [0.99]

    for prob in cumprobs:

        strprob = str(prob).replace('.', '')
        name = bedname.rsplit('/', 1)[1]
        outname = betafld+name.replace('.bed', '_beta_cdf_{}.bed' .format(strprob))

        scores = [float(feat.score) for feat in bed]
        Q1 = np.quantile(scores,0.25)
        Q3 = np.quantile(scores,0.75)
        IQR = Q3 - Q1
        mult = 1

        low_out = Q1 - mult*IQR
        high_out = Q3 + mult*IQR

        no_outlier_scores = [x for x in scores if x > low_out and x < high_out]
        fit = scipy.stats.beta.fit(no_outlier_scores)
        th = scipy.stats.beta.ppf(prob, *fit)

        thbed = bed.filter(lambda x: float(x.score) >= th).saveas(outname)
        print(th)

    ## Filter using 'old', intersecting

    ## Set astringent score threshold (for peaks in bdgdiff with no overlapp in 'old')
    perc = 0.999
    scores = [float(feat.score) for feat in bed]
    Q1 = np.quantile(scores,0.25)
    Q3 = np.quantile(scores,0.75)
    IQR = Q3 - Q1
    mult = 1

    low_out = Q1 - mult*IQR
    high_out = Q3 + mult*IQR

    no_outlier_scores = [x for x in scores if x > low_out and x < high_out]
    fit = scipy.stats.beta.fit(no_outlier_scores)
    th = scipy.stats.beta.ppf(prob, *fit)

    ## Get overlaps with old
    cross = bed.intersect(overbed, loj=True)

    ## Retain only those peaks with overlap in old or score > threshold
    subset = cross.filter(lambda x: x.fields[5] != '.' or
                          float(x.fields[4]) >= th)

    outname = crossoldfld+name.replace('.bed', '_crossold{}_th{}.bed' .format(oldFC, perc))
    subset.saveas(outname)

    ## Use pandas to eliminate columns
    df = pd.read_csv(outname, sep='\t', header = None)
    df.iloc[:,:5].to_csv(outname, sep='\t', header = False, index = False)

    ## Get peaks in 'old' that don't overlapp with bdfdiff
    ## Should we keept those? No! This wat we are truly using BdgDiff
    #oldunique = overbed.intersect(bed, v=True)


## Plot graphs

# bedname = ''

# bed = pb.BedTool(bedname)
# scores = [float(feat.score) for feat in bed]

# Q1 = np.quantile(scores,0.25)
# Q3 = np.quantile(scores,0.75)
# IQR = Q3 - Q1
# mult = 1

# low_out = Q1 - mult*IQR
# high_out = Q3 + mult*IQR

# no_outlier_scores = [x for x in scores if x > low_out and x < high_out]

# #plt.hist(scores, bins = 200, density=True)
# plt.hist(no_outlier_scores, bins = 200, density=True)
# plt.style.use('ggplot')

# # find minimum and maximum of xticks, so we know
# # where we should compute theoretical distribution
# xt = plt.xticks()[0]
# xmin, xmax = min(xt), max(xt)
# #lnspc = np.linspace(xmin, xmax, len(scores))
# lnspc = np.linspace(xmin, xmax, len(no_outlier_scores))

# ## Normal
# #fit = scipy.stats.norm.fit(scores)
# fit = scipy.stats.norm.fit(no_outlier_scores)
# pdf_norm = scipy.stats.norm.pdf(lnspc, *fit)
# plt.plot(lnspc, pdf_norm, label="Norm")

# plt.show()
# ## Beta
# #fit = scipy.stats.beta.fit(scores)
# fit = scipy.stats.beta.fit(no_outlier_scores)
# pdf_beta = scipy.stats.beta.pdf(lnspc, *fit)
# plt.plot(lnspc, pdf_beta, label="Beta")

# plt.show()

# ## Gamma
# fit = scipy.stats.gamma.fit(scores)
# pdf_gamma = scipy.stats.gamma.pdf(lnspc, *fit)
# plt.plot(lnspc, pdf_gamma, label="Gamma")

# ## Exponential
# fit = scipy.stats.expon.fit(scores)
# pdf_expon = scipy.stats.expon.pdf(lnspc, *fit)
# plt.plot(lnspc, pdf_expon, label="Expon")

#+end_src
***** Old Dupl/Del (deprecated)
****** Check for del/dupl areas by Pairs (deprecated)
Our aim is to detect large duplicated or deleted regions in our samples genome. This approach consists in making the difference between two coverage tracks and detect regions with outlier values.
#+begin_src python :tangle whole_chipseq_pipe.py
## Create pairwise comparison coverage Bedgraph
os.makedirs('./Input_Subtractions/', exist_ok=True)

for pair in itertools.combinations(inputs, 2):
    name1 = pair[0].split('_')[0]
    name2 = pair[1].split('_')[0]
    outname = './Input_Subtractions/'+name1+'_minus_'+name2+'_100bp_500smth_RPKM_cov.bdg'
    print(pair)
    print(outname)
    subtract_bams(bamdir+pair[0], bamdir+pair[1], outname)

## Load Bedgraph and put threshold

subtractions = os.listdir('./Input_Subtractions')
ddfld = './Duplication_Deletion_Regions/'
os.makedirs(ddfld, exist_ok=True)

for s in subtractions:

    mergenlen = 200
    minlen = 500
    probs = [1-1e-6, 1-1e-10]

    bedname = s
    print(bedname)
    bed = pb.BedTool('./Input_Subtractions/'+s)

    ## Filter by prob

    for prob in probs:

        strprob = str(prob).replace('.', '')

        scores = [float(feat.name) for feat in bed]
        Q1 = np.quantile(scores,0.25)
        Q3 = np.quantile(scores,0.75)
        IQR = Q3 - Q1
        mult = 1.5

        low_out = Q1 - mult*IQR
        high_out = Q3 + mult*IQR
        no_outlier_scores = [x for x in scores if x > low_out and x < high_out]

        fit = scipy.stats.norm.fit(no_outlier_scores)
        th = scipy.stats.norm.interval(prob, *fit)

        thbed = bed.filter(lambda x: float(x.name) <= th[0] or
                           float(x.name) >= th[1])
        print(prob)
        print(th)

        ## Filter by length
        ## first cluster toghether peaks
        clustered_bed = thbed.merge(d = mergenlen)

        len_th_bed = clustered_bed.filter(lambda x: float(x.stop) - float(x.start) >= minlen)

        ## Create bed output
        outname = ddfld+bedname.replace('.bdg', '_norm_pdf_{}_minlen{}.bed' .format(strprob, minlen))
        str_bed = ''
        for feat in len_th_bed:
            newline = [feat.chrom, feat.start, feat.stop]
            newline = [str(x) for x in newline]
            str_bed += '\t'.join(newline)+'\n'
        outbed = pb.BedTool(str_bed, from_string=True).saveas(outname)
#+end_src
****** Check for del/dupl Individual Method (deprecated)
#+begin_src python
## Load Bedgraph and put threshold

ddfld = './Duplication_Deletion_Regions_Individual/'
os.makedirs(ddfld, exist_ok=True)

rpkms_fld = './RPKMs/'

in_files = [f for f in os.listdir(rpkms_fld) if '_in_' in f and f.endswith('RPKMs.bdg')]

for f in in_files:

    f = in_files[1]
    mergenlen = 200
    minlen = 500
    probs = [1-1e-6]

    bedname = f
    print(bedname)
    bed = pb.BedTool(rpkms_fld+f)

    ## Filter by prob

    for prob in probs:
        prob = probs[0]
        strprob = str(prob).replace('.', '')

        scores = [float(feat.name) for feat in bed]
        Q1 = np.quantile(scores,0.25)
        Q3 = np.quantile(scores,0.75)
        IQR = Q3 - Q1
        mult = 1.5

        low_out = Q1 - mult*IQR
        high_out = Q3 + mult*IQR
        no_outlier_scores = [x for x in scores if x > low_out and x < high_out]

        fit = scipy.stats.expon.fit(no_outlier_scores)
        th = scipy.stats.expon.interval(prob, *fit)


        thbed = bed.filter(lambda x: float(x.name) <= th[0] or
                           float(x.name) >= th[1])
        print(prob)
        print(th)

        ## Filter by length
        ## first cluster toghether peaks
        clustered_bed = thbed.merge(d = mergenlen)

        len_th_bed = clustered_bed.filter(lambda x: float(x.stop) - float(x.start) >= minlen)

        ## Create bed output
        outname = ddfld+bedname.replace('.bdg', '_norm_pdf_{}_minlen{}.bed' .format(strprob, minlen))
        str_bed = ''
        for feat in len_th_bed:
            newline = [feat.chrom, feat.start, feat.stop]
            newline = [str(x) for x in newline]
            str_bed += '\t'.join(newline)+'\n'
        outbed = pb.BedTool(str_bed, from_string=True).saveas(outname)


##Plot graphs

bedname = './RPKMs/B11_in_sort_q5_RPKMs.bdg'

bed = pb.BedTool(bedname)
scores = [float(feat.name) for feat in bed]

Q1 = np.quantile(scores,0.25)
Q3 = np.quantile(scores,0.75)
IQR = Q3 - Q1
mult = 1.5

low_out = Q1 - mult*IQR
high_out = Q3 + mult*IQR

no_outlier_scores = [x for x in scores if x > low_out and x < high_out]

#plt.hist(scores, bins = 200, density=True)
plt.hist(no_outlier_scores, bins = 200, density=True)
plt.style.use('ggplot')

# find minimum and maximum of xticks, so we know
# where we should compute theoretical distribution
xt = plt.xticks()[0]
xmin, xmax = min(xt), max(xt)
#lnspc = np.linspace(xmin, xmax, len(scores))
lnspc = np.linspace(xmin, xmax, len(no_outlier_scores))

## Normal
fit = scipy.stats.powerlaw.fit(no_outlier_scores)
pdf_norm = scipy.stats.powerlaw.pdf(lnspc, *fit)
plt.plot(lnspc, pdf_norm, label="Norm")

plt.show()

#+end_src
****** Check for del/dupl Mean Method (deprecated)
#+begin_src python
ddfld = './Duplication_Deletion_Regions_Mean/'
os.makedirs(ddfld, exist_ok=True)

rpkms_fld = './RPKMs/'

in_files = [f for f in os.listdir(rpkms_fld) if '_in_' in f and f.endswith('RPKMs.bdg')]

for f in in_files:

    f = in_files[1]
    mergelen = 200
    minlen = 500
    bedname = f
    print(bedname)
    bed = pb.BedTool(rpkms_fld+f)

    cov = [float(feat.name) for feat in bed]

    fact_up = 1.75
    fact_dw = 0.05
    th_up = np.mean(cov)*fact_up
    th_dw = np.mean(cov)*fact_dw

    thbed = bed.filter(lambda x: float(x.name) <= th_dw or float(x.name) >= th_up)
    print(th_dw, th_up)

    ## Filter by length
    ## first cluster toghether peaks
    clustered_bed = thbed.merge(d = mergelen, c = 4, o = 'mean')

    len_th_bed = clustered_bed.filter(lambda x: float(x.stop) - float(x.start) >= minlen)
    ## Create bed output
    outname = ddfld+bedname.replace('.bdg', '_bymean_fact_{}_{}_minlen{}_mergelen_{}.bed' .format(fact_up, fact_dw, minlen, mergelen))
    str_bed = ''
    for feat in len_th_bed:
        newline = [feat.chrom, feat.start, feat.stop]
        newline = [str(x) for x in newline]
        str_bed += '\t'.join(newline)+'\n'
    outbed = pb.BedTool(str_bed, from_string=True).saveas(outname)
#+end_src
****** Remove del/dupl present in all strains (deprecated)
#+begin_src python
import itertools

## Functions
def check_overlapp_perc(feat, bed, perc_th, exclude = False):
    """
    Check wether "feat" overlaps any feature in "bed" and if the overlapp spans
    >= "perc_th" % of "feat" (in length) If exclude = True keep peaks that don't
    overlapp another.
    """
    is_match = False
    for interval in bed:
        if interval.chrom == feat.chrom:
            # Check overlapp
            if feat.start <= interval.stop and interval.start <= feat.stop:
                #Check percentage overlapp
                bigger_start = max([feat.start, interval.start])
                smaller_end = min([feat.stop, interval.stop])
                perc_overlapp = (smaller_end - bigger_start/len(feat))*100

                if perc_overlapp >= perc_th: is_match = True
            else:
                pass
        else:
            pass

    if exclude: is_match = not is_match
    return(is_match)

## Fuzzy start-stop comparison implementation
# fuzz_start = interval.start - fuzz <= feat.start <= interval.start + fuzz
# fuzz_stop = interval.stop - fuzz <= feat.stop <= interval.stop + fuzz
# if  fuzz_start and fuzz_stop:


def overlapp_couples(bed1, bed2, indir):

    bed = pb.BedTool(indir+bed1)
    refbed = pb.BedTool(indir+bed2)

    prefix1 = bed1.split('_')[0]
    prefix2 = bed2.split('_')[0]
    outname = '+'.join([prefix1, prefix2]) + f'_overlapp_perc_{perc}.bed'

    outbed = bed.filter(lambda b: check_overlapp_perc(b, refbed, perc))
    outbed.saveas(indir+outname)

    print(outname)

## Calls
indir = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/Duplication_Deletion_Regions_Mean/'

suffix = '_bymean_fact_1.75_0.1_minlen500_mergelen_200.bed'
preffix = ('1.2B', '10G', 'A7K9', 'E5K9', 'B11')
dupl_del_files = [f for f in os.listdir(indir)
                  if f.startswith(preffix)
                  and f.endswith(suffix)]
perc = 80

## Cross all with all, 2 by 2, and retain common peaks
overlapp_couples(dupl_del_files[0], dupl_del_files[1], indir)
overlapp_couples(dupl_del_files[2], dupl_del_files[3], indir)
overlapp_couples(
    'A7K9+B11_overlapp_perc_80.bed',
    '1.2B+10G_overlapp_perc_80.bed',
    indir
)
overlapp_couples(
    'A7K9+B11+1.2B+10G_overlapp_perc_80.bed',
    'E5K9_in_sort_q5_RPKMs_bymean_fact_1.75_0.1_minlen500_mergelen_200.bed',
    indir
)

## Cross each one with the common peaks bed and keep only NON-overlapping peaks
for bed in dupl_del_files:

    ref = 'A7K9+B11+1.2B+10G+E5K9_overlapp_perc_80.bed'
    refbed = pb.BedTool(indir+ref)

    outname = bed.replace('.bed', '_filtered.bed')
    bed1 = pb.BedTool(indir+bed)
    outbed = bed1.filter(lambda b: check_overlapp_perc(b, refbed, perc, exclude=True))
    outbed.saveas(indir+outname)
    print(outname)

#+end_src
***** Check for Del and Dupl Mean Method Separate (current)
#+begin_src python
##### Functions #####

def add_names(bed, featname):
    i = 1
    str_bed = ''
    for feat in bed:
        newline = [feat.chrom, feat.start, feat.stop, featname+'_'+str(i), feat.name]
        newline = [str(x) for x in newline]
        str_bed += '\t'.join(newline)+'\n'
        i += 1
    outbed = pb.BedTool(str_bed, from_string=True)
    return(outbed)

def set_score_x(feat, x):
        feat.score = x
        return(feat)

def get_dupl_del(bed, fact_up, fact_dw, score_col, mergelen, minlen):

    bedname = bed.rsplit('/', 1)[1]
    print(bedname)
    bed = pb.BedTool(bed)
    cov = [float(feat.fields[score_col]) for feat in bed]

    th_up = np.mean(cov)*fact_up
    th_dw = np.mean(cov)*fact_dw

    thbed_up = bed.filter(lambda x: float(x.name) >= th_up)
    thbed_dw = bed.filter(lambda x: float(x.name) <= th_dw)

    ## Cluster peaks together
    clu_bed_up = thbed_up.merge(d = mergelen, c = 4, o = 'mean')
    clu_bed_dw = thbed_dw.merge(d = mergelen, c = 4, o = 'mean')

    ## Filter peaks by length
    len_bed_up = clu_bed_up.filter(lambda x: float(x.stop) - float(x.start) >= minlen)
    len_bed_dw = clu_bed_dw.filter(lambda x: float(x.stop) - float(x.start) >= minlen)

    ## Add name (and move score to 5th column)

    blueprint = '_bymean_{}_fact_{}_minlen{}_mergelen_{}.bed'

    suffix_up =  blueprint .format('dupl', fact_up, minlen, mergelen)
    outname_up = ddfld+bedname.replace('.bdg', suffix_up)

    suffix_dw = blueprint .format('del', fact_dw, minlen, mergelen)
    outname_dw = ddfld+bedname.replace('.bdg', suffix_dw)

    dupl_bed = add_names(len_bed_up, 'duplication').each(set_score_x, 1).saveas(outname_up)
    del_bed = add_names(len_bed_dw, 'deletion').each(set_score_x, -1).saveas(outname_dw)

    ## Merge dupl and del
    strfact = '{}up_{}dw' .format(fact_up, fact_dw)
    suffix = blueprint .format('dupl_del', strfact, minlen, mergelen)
    outname = ddfld+bedname.replace('.bdg', suffix)
    cmd = f'cat {outname_up} {outname_dw} > {outname}'
    sp.call(cmd, shell = True)

    ## Sort and set score for all features to 1
    outbed = pb.BedTool(outname).sort().saveas(outname)


 ##### Calls #####

ddfld = './Duplication_Deletion_Regions_Mean_Separate_DuplDel/'
os.makedirs(ddfld, exist_ok=True)

rpkms_fld = './RPKMs/'

in_files = [f for f in os.listdir(rpkms_fld) if '_in_' in f and f.endswith('RPKMs.bdg')]

## Params
fact_up = 1.75
fact_dw = 0.1
score_col = 3
mergelen = 200
minlen = 500

for f in in_files:
    get_dupl_del(rpkms_fld+f, fact_up, fact_dw, score_col, mergelen, minlen)
#+end_src
***** Check dupl/del present in ALL strains (current)
#+begin_src python
ddfld = './Duplication_Deletion_Regions_Mean_Separate_DuplDel/'
os.listdir(ddfld)

prefixes = ('1.2B', '10G', 'A7K9', 'E5K9', 'B11')
suffix = '_bymean_dupl_del_fact_1.75up_0.1dw_minlen500_mergelen_200.bed'
files_to_cross = [f for f in os.listdir(ddfld) if f.endswith(suffix) and f.startswith(prefixes)]

##### Join all dupl_del files and select regions dupl/del in ALL samples

str_beds = ' '.join([ddfld+f for f in files_to_cross])
cmd = 'awk \'{print}\' '+f'{str_beds} > {ddfld}allstrains_supl_del.bed'
sp.call(cmd, shell = True)

join_bed = pb.BedTool(ddfld+'allstrains_supl_del.bed').sort()

result = join_bed.genome_coverage(bg=True, g=ddfld+'Pf3D7.genome')
result.saveas(ddfld+'final_allsrtains_dupl_del.bdg')
filter_bed = result.filter(lambda x: int(x.name) >= 5)
filter_bed.saveas(ddfld+'final_allstrains_dupl_del_>5.bdg')

##### Cross each dupl/del file with the ALLstraisn dupl/del file

## Functions

def check_overlapp_perc(feat, bed, perc_th, exclude = False):
    """
    Check wether "feat" overlaps any feature in "bed" and if the overlapp spans
    >= "perc_th" % of "feat" (in length) If exclude = True keep peaks that don't
    overlapp another.
    """
    is_match = False
    for interval in bed:
        if interval.chrom == feat.chrom:
            # Check overlapp
            if feat.start <= interval.stop and interval.start <= feat.stop:
                #Check percentage overlapp
                bigger_start = max([feat.start, interval.start])
                smaller_end = min([feat.stop, interval.stop])
                perc_overlapp = (smaller_end - bigger_start/len(feat))*100

                if perc_overlapp >= perc_th: is_match = True
            else:
                pass
        else:
            pass

    if exclude: is_match = not is_match
    return(is_match)

## Calls

files_to_cross
perc = 80

## Retain only NON-overlapping peaks

for bed in files_to_cross:

    ref = 'final_allstrains_dupl_del_>5.bdg'
    refbed = pb.BedTool(ddfld+ref)

    outname = bed.replace('.bed', '_filtered.bed')
    bed1 = pb.BedTool(ddfld+bed)
    outbed = bed1.filter(lambda b: check_overlapp_perc(b, refbed, perc, exclude=True))
    outbed.saveas(ddfld+outname)
    print(outname)
#+end_src
***** Cross supl/del with genes
#+begin_src python
import os
import pybedtools as pb

indir = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/Duplication_Deletion_Regions_Mean_Separate_DuplDel/'
os.chdir(indir)

dupl_del_files = [f for f in os.listdir(indir) if f.endswith('_filtered.bed')]

ref_dir = '/mnt/Disc4T/Projects/PhD_Project/Data/PlasmoDB-52_Pfalciparum3D7.gff'
gff = pb.BedTool(ref_dir)

types = set([entry.fields[2] for entry in gff])
gene_types = [
    'ncRNA_gene',
    'protein_coding_gene',
    'pseudogene'
]

outdir = './Crossed_with_genes/'
os.makedirs(outdir, exist_ok=True)

for bed_f in dupl_del_files:

    gene_gff = gff.filter(lambda x: x.fields[2] in gene_types)
    print(bed_f)
    outfile = outdir+bed_f.replace('.bed', '_genes.tsv')
    dd_bed = pb.BedTool(bed_f)
    cross = dd_bed.intersect(gene_gff, wao = True)

    with open(outfile, 'w+') as out_file:
        for x in cross:
            #print(x)
            if x.fields[5] != '.':
                #print(x)
                attrs_field = x.fields[13].split(';')
                attrs_dict = {x.split('=')[0]:x.split('=')[1] for x in attrs_field}
                out_line = [
                    attrs_dict['ID'],
                    attrs_dict.get('Name', ''),
                    attrs_dict.get('description', '')
                ]
                #print(out_line)
                out_file.write('\t'.join(out_line)+'\n')

#+end_src
***** Cross peaks with indels (deprecated)
In this filtering step we remove those peaks that overlap a duplicated or deleted region as defined in the previous step.
#+begin_src python :tangle whole_chipseq_pipe.py
wd = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/'
os.chdir(wd)

me_names = [getName(f) for f in me_files]
difs = list(itertools.combinations(me_names, 2))
betafitfld = './BetaFit_DuplDel_Filtered/'
crossoldfld = './CrossOld_DuplDel_Filtered/'
os.makedirs(betafitfld, exist_ok=True)
os.makedirs(crossoldfld, exist_ok=True)

for pair in difs:

    subst = './Duplication_Deletion_Regions/{}_minus_{}_100bp_500smth_RPKM_cov_norm_pdf_0999999_minlen500.bed'
    subst = subst .format(pair[0], pair[1])
    subst_bed = pb.BedTool(subst)

    for n in [1,2]:
        peak = './DiffPeaks_BdgDiff_BetaFit/{}_vs_{}_g200_l150_c1_c1.0_cond{}_beta_cdf_099.bed'
        peak = peak .format(pair[0], pair[1], n)
        peak_bed = pb.BedTool(peak)
        filtered_bed = peak_bed.intersect(subst_bed, v=True)
        outname = peak.replace('.bed', '_IndelDup_filtered.bed')
        outname = outname.replace('./DiffPeaks_BdgDiff_BetaFit/', betafitfld)
        filtered_bed.saveas(outname)

        peak = './DiffPeaks_BdgDiff_CrossOld/{}_vs_{}_g200_l150_c1_c1.0_cond{}_crossold20_th0.999.bed'
        peak = peak .format(pair[0], pair[1], n)
        peak_bed = pb.BedTool(peak)
        filtered_bed = peak_bed.intersect(subst_bed, v=True)
        outname = peak.replace('.bed', '_IndelDup_filtered.bed')
        outname = outname.replace('./DiffPeaks_BdgDiff_CrossOld/', crossoldfld)
        filtered_bed.saveas(outname)

#+end_src
** Annotate Peaks
*** Merge all peaks
#+begin_src python :tanlge ./Scripts/merge_peaks.py :session fra :results none
import os
import pybedtools as pb

#wd = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Data/New_Coverage/New_Peaks/"
wd = '/mnt/Disc4T/Projects/Chip_Seq_Data_2021/Peak_Calling_MACS2/'
os.chdir(wd)

bed1 = pb.BedTool("10G_me_Macspeaks_peaks.narrowPeak")
bed2 = pb.BedTool("B11_me_Macspeaks_peaks.narrowPeak")
bed3 = pb.BedTool("E5K9_me_Macspeaks_peaks.narrowPeak")
bed4 = pb.BedTool("1.2B_me_Macspeaks_peaks.narrowPeak")
bed5 = pb.BedTool("A7K9_me_Macspeaks_peaks.narrowPeak")
#bed6 = pb.BedTool("NF54_Macspeaks_peaks.bed")

all_bed = bed1.cat(bed2, bed3, bed4, bed5)
#bed12B_10G = bed4.cat(bed1)

all_bed.saveas("all_peaks.bed")
#bed12B_10G.saveas("12B_10G_peaks.bed")
#+end_src
*** Annotate MACS2 peaks
#+begin_src python :tangle ./Scripts/annotate_MACS2_peaks.py :session fra :results none
import pybedtools as pb
import pandas as pd
import os

gff = "/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/final_binned_1000tss_wholegene_parsed.bed"
peaksdir = "/mnt/Disc4T/Projects/Chip_Seq_Data_2021/Peak_Calling_MACS2/"
peaks = [f for f in os.listdir(peaksdir) if f.endswith(".narrowPeak")]

ref = pb.BedTool(gff)
ref = ref.sort()

def annotate_bed(bedfile):

    bed = pb.BedTool(bedfile)
    anot = bed.intersect(ref, wao=True)

    parsed_anot = []
    for interval in anot:
        originalfields = interval.fields[0:10]
        if interval.fields[10] == ".":
            gid, anot = "intergenic", "NA"
        else:
            gid = interval.fields[13]
            anot = interval.fields[14]
        parsed_anot.append(originalfields + [gid, anot])

    df = pd.DataFrame(parsed_anot)
    outfile = bedfile.replace(".narrowPeak", "_annotated.csv")
    df.to_csv(outfile, sep="\t", header=False, index=False)

for peak in peaks:
    bedfile = peaksdir+peak
    annotate_bed(bedfile)

#+end_src
*** Annotate MACS2-BDGdiff-BetaFit-DDfiltered DifPeaks
#+begin_src python :tangle ./Scripts/annotate_peaks.py :results none
import pybedtools as pb
import pandas as pd
import os

## Function

def annotate_bed(bedfile):

    bed = pb.BedTool(bedfile)
    anot = bed.intersect(ref, wao=True)

    parsed_anot = []
    for interval in anot:
        originalfields = interval.fields[0:5]
        if interval.fields[5] == ".":
            gid, anot = "intergenic", "NA"
        else:
            gid = interval.fields[8]
            anot = interval.fields[9]
        parsed_anot.append(originalfields + [gid, anot])

    df = pd.DataFrame(parsed_anot)
    outfile = bedfile.replace(".bed", "_annotated.csv")
    df.to_csv(outfile, sep="\t", header=False, index=False)

## Calls

gff = "/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/final_binned_1000tss_wholegene_parsed.bed"
peaksdir = "/mnt/Disc4T/Projects/Chip_Seq_Data_2021/BetaFit_DuplDel_Filtered/"
peaks = [f for f in os.listdir(peaksdir) if f.endswith("_filtered.bed")]

ref = pb.BedTool(gff)
ref = ref.sort()

for peak in peaks:
    bedfile = peaksdir+peak
    annotate_bed(bedfile)



#+end_src
** Compare with Fraschka DataSet (Revise)
#+begin_src python :tangle ./Scripts/fraschka.py :session fra
  import pandas as pd
  #pd.DataFrame(het_genes).to_csv("/media/lucas/Disc4T/Projects/PhD_Project/het_genes.csv", header = None, index = False)

  frascka = pd.read_csv("/media/lucas/Disc4T/Projects/PhD_Project/Fraschka/fraschka_all.csv", header = None)
  fra = set(frascka[0].tolist())

  both = het_genes & fra
  ours = het_genes - fra
  theirs = fra - het_genes

  len(het_genes)
  len(fra)

  len(both)
  len(ours)
  len(theirs)

  for x in ours:
      print(x)
#+end_src
** Binned Coverage
*** Binned Gene-Model
We will produce two types of coverage output:
1. A bw/bedgraph file with normalized input corrected coverage over the whole genome. For this we will bin the genome in 150bp fragments.
2. A gene-centered bed file with a coverage model for every gene in the genome.

The gene coverage model we will be using will be the following:

We will construct a gene model for downstream analysis. The gene model consists
in a 23 slots array for each gene. Each slots represents the following:

- 1-2: Coverage of previous gene 2 (gene previous to previous gene)
- 3-4: Coverage of previous gene 1
- 5-9: Coverage in 5' region
- 10-14: Coverage in gene body (CDS)
- 15-19: Coverage in 3' region
- 20-21: Coverage of next gene 1
- 22-23: Coverage of next gene 2

The underlying idea is to capture information not only about the gene itself
(and its 5' and 3' regions) but also on the neighboring genes.

[[file:Report/gene_model_nobackground.png]]

**** Get medium size of a gene in P.falciparum:
To get an idea of how big the bins should be we will investigate a little the
mean size of a gene in P.falciparum.
***** Get sizes from gff (python)
#+begin_src python
  import os
  import pybedtools as pb
  from statistics import mean

  os.chdir("/media/lucas/Disc4T/Projects/PhD_Project/Subprojects/")
  gff = pb.BedTool("/home/lucas/ISGlobal/Gen_Referencies/PlasmoDB-43_Pfalciparum3D7.gff")

  lengths = []
  for gene in gff:
      if gene.fields[2] == "gene":
          bp = gene.stop - gene.start
          lengths.append(bp)

  with open("gene_lengths.txt", "w+") as outfile:
      for g in lengths:
          outfile.write(str(g)+"\n")
#+end_src

***** Plot them (R)
#+begin_src R
  lens <- read.csv("./gene_lengths.txt")
  lens <- as.numeric(lens[,1])
  hist(lens, xlim = c(0,10000), breaks = 200)
#+end_src
Mean gene size is around 1000bp.
**** Binned Coverage (gene model)
We will use our binned bed as guide and our generated 150bp coverage bw file as input to calculate average coverage over each bin of interest.
#+begin_src python :tangle ./Scripts/gene_model_coverage.py
import pybedtools as pb
import numpy as np
import pandas as pd
import os
from collections import defaultdict

indir = "/mnt/Disc4T/Projects/Cristina_ChIP_All/Data/New_Coverage/Binsize_150/"

#bin_bed = pb.BedTool("/mnt/Disc4T/Projects/PhD_Project/Data/PlasmoDB-45_Pfalciparum3D7_bin5_2prevGenes.bed")

bin_bed = pb.BedTool("/mnt/Disc4T/Projects/PhD_Project/Data/PlasmoDB-46_Pfalciparum3D7_withGDV1_ncRNAs_bin5_2prevGenes.bed")

cov_files = [f for f in os.listdir(indir) if f.endswith("_normInp_ps1.bdg.gz")]

#cov_files = ['NF54_me_q5_sort_noDup_RPKM_normInp_ps1.bdg.gz']

for cov in cov_files:

    flstr = indir+cov
    cov = pb.BedTool(flstr)
    print(flstr, "Converted to bed!")
    outfile = flstr.replace(".bdg.gz", "_5binned_cov_2prevpost.csv")
    #logfile = outfile.replace(".bed", ".log")
    genevals = defaultdict(list)

    for interval in bin_bed:

        gene = interval.name
        pos = interval.score

        # Not all of them have a match!
        try:
            match = cov.tabix_intervals(interval)
            val = np.mean([float(x.fields[3]) for x in match])
            genevals[gene].append((val, pos))

        except:
            pass

    # Rearrange values deppending on strandness (we have to "flip" genes on "-" strand)
    sorted_genevals = {}
    for gene, val in genevals.items():
        svals = sorted(val, key = lambda x:int(x[1]))
        vals = [x[0] for x in svals]
        sorted_genevals[gene] = vals

    # Write output
    df = pd.DataFrame.from_dict(sorted_genevals, orient='index')
    df.to_csv(outfile)
    print("Done with file: {}" .format(flstr))

#+end_src
**** Binned Coverage (gene model) NEW
***** BGZIP and TABIX coverage files
#+begin_src python
import os
import subprocess as sp

wd = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/RPKMs_normInput/'
os.chdir(wd)

#cov_files = [f for f in os.listdir() if f.endswith('_me_sort_q5_RPKMs_normInput.bdg')]
cov_files = [f for f in os.listdir() if f.endswith('_ac_sort_q5_RPKMs_normInput.bdg')]

for f in cov_files:
    outf = f.replace('.bdg', '.bdg.gz')
    cmd = f'bgzip -f {f} > {outf}'
    print(cmd)
    sp.call(cmd, shell=True)

gz_files = [f for f in os.listdir() if f.endswith('.bdg.gz')]

for f in gz_files:
    cmd = f'tabix -p bed {f}'
    print(cmd)
    sp.call(cmd, shell=True)
#+end_src
***** Cross Coverage
We will use our binned bed as guide and our generated 150bp coverage bw file as input to calculate average coverage over each bin of interest.
#+begin_src python :tangle ./Scripts/gene_model_coverage.py
import numpy as np
import pandas as pd
import os
import pybedtools as pb
from collections import defaultdict

wd = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/RPKMs_normInput/'
os.chdir(wd)

indir = './'
bin_bed = pb.BedTool("/mnt/Disc4T/Projects/PhD_Project/Data/PlasmoDB-46_Pfalciparum3D7_withGDV1_ncRNAs_bin5_2prevGenes.bed")

cov_files = [f for f in os.listdir(indir) if f.endswith(".bdg.gz")]
#cov = cov_files[0]

for cov in cov_files:

    flstr = indir+cov
    cov = pb.BedTool(flstr)
    print(flstr, "Converted to bed!")
    outfile = flstr.replace(".bdg.gz", "_5binned_cov_2prevpost.csv")
    #logfile = outfile.replace(".bed", ".log")
    genevals = defaultdict(list)

    for interval in bin_bed:

        #interval = bin_bed[0]
        gene = interval.name
        pos = interval.score

        # Not all of them have a match!
        try:
            match = cov.tabix_intervals(interval)
            val = np.mean([float(x.fields[3]) for x in match])
            genevals[gene].append((val, pos))

        except:
            pass

    # Rearrange values deppending on strandness (we have to "flip" genes on "-" strand)
    sorted_genevals = {}
    for gene, val in genevals.items():
        svals = sorted(val, key = lambda x:int(x[1]))
        vals = [x[0] for x in svals]
        sorted_genevals[gene] = vals

    # Write output
    df = pd.DataFrame.from_dict(sorted_genevals, orient='index')
    df.to_csv(outfile)
    print("Done with file: {}" .format(flstr))

#+end_src
***** Create Heatmaps
:PROPERTIES:
:header-args:R: :session gene_model_cov :tangle ./Scripts/gene_model_cov.R :results none
:END:
****** Load Data
#+begin_src R
library(ggplot2)
library(tsne)
library(reshape2)
library(scales)
library(tidyverse)

#### Load Data ####
wd <- '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/RPKMs_normInput/'
setwd(wd)

## Coverage
cov_12B <- read_csv('1.2B_me_sort_q5_RPKMs_normInput_5binned_cov_2prevpost.csv')
cov_10G <- read_csv('10G_me_sort_q5_RPKMs_normInput_5binned_cov_2prevpost.csv')
cov_A7 <- read_csv('A7K9_me_sort_q5_RPKMs_normInput_5binned_cov_2prevpost.csv')
cov_E5 <- read_csv('E5K9_me_sort_q5_RPKMs_normInput_5binned_cov_2prevpost.csv')
cov_B11 <- read_csv('B11_me_sort_q5_RPKMs_normInput_5binned_cov_2prevpost.csv')


strains <- list(df12B=cov_12B,
                df10G=cov_10G,
                dfA7=cov_A7,
                dfE5=cov_E5,
                dfB11=cov_B11
                )

trans.data <- read.csv("/mnt/Disc4T/Projects/PhD_Project/External_Data/trasncription_parsed.csv",
                       stringsAsFactors = F)


## Change dfs in a list
strains <- lapply(strains, function(df) {
    colnames(df)[1] <- "Gene_id"
    df
})

## Convert list into individual objects again
list2env(strains, envir=.GlobalEnv)

##Create numeric non-na mtxs
nona.mtxs <- lapply(strains, function(df) {
    mtx <- as.matrix(df[complete.cases(df),-1])
    rownames(mtx) <- df[complete.cases(df),1] %>% pull()
    mtx
})

names(nona.mtxs) <- c("mtx12B", "mtx10G", 'mtxA7', 'mtxE5', 'mtxB11')

##Create side-by-side matrices
mtx_12b10g <- cbind(nona.mtxs$mtx12B, nona.mtxs$mtx10G)

mtx_all <- cbind(nona.mtxs$mtx12B,
                 nona.mtxs$mtx10G,
                 nona.mtxs$mtxA7,
                 nona.mtxs$mtxE5,
                 nona.mtxs$mtxB11
                 )

colnames(mtx_all) <- 1:dim(mtx_all)[2]


##Create diferences matrices
dif_12b10g <- nona.mtxs$mtx12B-nona.mtxs$mtx10G

## Load Gene Characteristics
variant <- read.csv("/home/lucas/ISGlobal/Gen_Referencies/Gens_variants_extended.txt",
                    header = TRUE, sep = "\t")

het_genes = read.csv("/mnt/Disc4T/Projects/PhD_Project/het_genes.csv",
                     header = F, stringsAsFactors = F)[,1]

fraschka = read.csv("/mnt/Disc4T/Projects/PhD_Project/Fraschka/fraschka_all.csv",
                    header = F, stringsAsFactors = F)[,1]

both = intersect(het_genes, fraschka)
ours = setdiff(het_genes, fraschka)
theirs = setdiff(fraschka, het_genes)

subtelomeric = read.csv("/mnt/Disc4T/Projects/PhD_Project/Island_Peaks/subtel_genes.csv",
                        header = F, stringsAsFactors = F)[,1]

## Create Gene info DF

anot <- read.csv("/mnt/Disc4T/Projects/PhD_Project/chip_seq_genes_annotated.csv",
                 sep = "\t", header = FALSE)

geneDF = as.data.frame(strains$df12B$Gene_id)
colnames(geneDF) <- "Gene_id"

geneDF["Annot"] <- anot$V2
geneDF["Annot"] <- gsub("Plasmodium", "Pl.", geneDF$Annot)
geneDF["Annot"] <- gsub("protein", "prot.", geneDF$Annot)
geneDF["Annot"] <- gsub("membrane", "memb.", geneDF$Annot)
geneDF["Annot"] <- gsub("conserved", "cvd.", geneDF$Annot)
geneDF["Annot"] <- gsub("function", "func.", geneDF$Annot)
geneDF["Annot"] <- gsub("unknown", "ukwn.", geneDF$Annot)
geneDF["Annot"] <- gsub("exported", "xptd.", geneDF$Annot)
geneDF["Annot"] <- gsub("pseudogene", "pseudo", geneDF$Annot)
geneDF["Annot"] <- gsub("putative", "put.", geneDF$Annot)
geneDF["Annot"] <- gsub("%2C", "", geneDF$Annot)


geneDF["Epi"] <- "non-variant"
geneDF[geneDF$Gene_id %in% both, "Epi"] <- "Both"
geneDF[geneDF$Gene_id %in% ours, "Epi"] <- "Ours"
geneDF[geneDF$Gene_id %in% theirs, "Epi"] <- "Theirs"

geneDF["Trans"] <- trans.data$Dif_12B.10G
geneDF["Subtelomeric"] <- "Normal"
geneDF[geneDF$Gene_id %in% subtelomeric, "Subtelomeric"] <- "Subtelomeric"
island <- geneDF$Epi != "non-variant" & geneDF$Subtelomeric != "Subtelomeric"
geneDF[island, "Subtelomeric"] <- "Island"

geneDFnona <- geneDF[geneDF$Gene_id %in% rownames(nona.mtxs$mtx12B),]

#+end_src
****** PCA
#+begin_src R
cvgDF <- geneDFnona[geneDFnona$Epi != "non-variant",]
cvg_mtx <- dif_12b10g[rownames(dif_12b10g) %in% cvgDF$Gene_id,]

dif_pca <- prcomp(dif_12b10g)
cvg_pca <- prcomp(cvg_mtx)

dif_pca_df <- as.data.frame(dif_pca$x[, c(1,2)])
dif_pca_df <- cbind(dif_pca_df, geneDFnona[,-1])

cvg_pca_df <- as.data.frame(cvg_pca$x[, c(1,2)])
cvg_pca_df <- cbind(cvg_pca_df, cvgDF[,-1])


alpha <- sapply(dif_pca_df$Epi == "non-variant", function(x) if (x) {0.1} else {1})

#### PCA plots ####
## All-genes
p <- ggplot(dif_pca_df, aes(x=PC1, y=PC2, color = Epi))
p <- p + geom_point(alpha=alpha)
p

p <- ggplot(dif_pca_df, aes(x=PC1, y=PC2, color = Subtelomeric))
p <- p + geom_point(alpha=alpha)
p

p <- ggplot(dif_pca_df, aes(x=PC1, y=PC2, color = Trans))
p <- p + geom_point(alpha=alpha)
p <- p + scale_color_gradient2(midpoint = 0, low="red", mid = "black", high="green")
p

## CVGs
p <- ggplot(cvg_pca_df, aes(x=PC1, y=PC2, color = Epi))
p <- p + geom_point()
p

p <- ggplot(cvg_pca_df, aes(x=PC1, y=PC2, color = Subtelomeric))
p <- p + geom_point()
p

p <- ggplot(cvg_pca_df, aes(x=PC1, y=PC2, color = Trans))
p <- p + geom_point()
p <- p + scale_color_gradient2(midpoint = 0, low="red", mid = "black", high="green")
p

#+end_src
****** Get Diferential-Peak genes
#+begin_src R
difpeaks12B <- read.csv("/home/lucas/ISGlobal/Chip_Seq/DATA/Aligns/q5/Narrow_fe15/XLS_contrasts/Overlapped_and_filetred/calcFE/bed/annotated2/1.2B_10G_peaks_overlappandfilter_calcFE_annotated.csv",
                        sep = "\t",
                        stringsAsFactors = FALSE)

difpeaks10G <- read.csv("/home/lucas/ISGlobal/Chip_Seq/DATA/Aligns/q5/Narrow_fe15/XLS_contrasts/Overlapped_and_filetred/calcFE/bed/annotated2/10G_1.2B_peaks_overlappandfilter_calcFE_annotated.csv",
                        sep = "\t",
                        stringsAsFactors = FALSE)

hetdifgenes <-  unique(c(difpeaks12B$Gene, difpeaks10G$Gene))

hetdifDF <- geneDFnona[geneDFnona$Gene_id %in% hetdifgenes,]

hetdifDF
hetdif_mtx <- dif_12b10g[rownames(dif_12b10g) %in% hetdifDF$Gene_id,]

hetdif_pca <- prcomp(hetdif_mtx)

hetdif_pca_df <- as.data.frame(hetdif_pca$x[, c(1,2)])
hetdif_pca_df <- cbind(hetdif_pca_df, hetdifDF[,-1])

#### PCA plots ####
## All-genes
p <- ggplot(hetdif_pca_df, aes(x=PC1, y=PC2, color = Trans))
p <- p + geom_point()
p <- p + scale_color_gradient2(midpoint = 0, low="red", mid = "black", high="green")
p


hist(hetdifDF$Trans, breaks = 20)
#+end_src
****** Heatmap function
#+begin_src R
customHeatmap <- function(df, limits){
  df <- melt(df)
  p <- ggplot(df, aes(x = variable, y = Gene_id, fill = value)) +
    geom_tile(colour="snow3",size=0.10) +
    scale_fill_gradient2(midpoint = 0,
                         low = "green",
                         mid = "black",
                         high = "red",
                         limits = limits,
                         oob=squish) +
    theme(
      strip.background = element_blank(),
      axis.title = element_blank(),
      strip.text.x = element_blank(),
      axis.line.x = element_blank(),
      axis.ticks.x = element_blank(),
      axis.text.x = element_blank())
  p
}
#+end_src
****** Difference approax
#+begin_src R
## Absolute value of difference
heatDF <- cbind(hetdifDF[,-3], abs(hetdif_mtx))

## Make hierarquical Clustering
dmtx <- dist(abs(hetdif_mtx), method = "euclidean")
cl <- hclust(dmtx, method = 'average')
heatDF$Gene_id <- factor(heatDF$Gene_id, levels = heatDF$Gene_id[cl$order])
customHeatmap(heatDF, c(0,2))

## Difference
heatDF <- cbind(hetdifDF[,-3], hetdif_mtx)

## Make hierarquical Clustering
dmtx <- dist(hetdif_mtx, method = "euclidean")
cl <- hclust(dmtx, method = 'average')
heatDF$Gene_id <- factor(heatDF$Gene_id, levels = heatDF$Gene_id[cl$order])
customHeatmap(heatDF, c(-2,2))

#+end_src
****** Side by Side approax
#+begin_src R :results graphics :file heatmap1.png
difpeak_mtx <- mtx_12b10g[rownames(mtx_12b10g) %in% hetdifgenes,]
heatDF <- cbind(hetdifDF[,-4], difpeak_mtx)


heatDF[heatDF$Gene_id == "PF3D7_1220700",]

head(heatDF)
labels <- apply(heatDF, 1, function(x){
  paste0(x[1], ": ", x[2])
})

heatDF["Labels"] <- labels

## Make hierarquical Clustering
dmtx <- dist(difpeak_mtx, method = "euclidean")
cl <- hclust(dmtx, method = 'complete')
heatDF$Labels <- factor(heatDF$Labels, levels = heatDF$Labels[cl$order])
#customHeatmap(heatDF, c(-4,4))

#head(heatDF)
mdf <- melt(heatDF)
mdf["Strain"] <- sapply(mdf$variable, function(x) if (as.numeric(x) < 24) {"12B"} else {"10G"})
#mdf["Strain"] <- strain

p <- ggplot(mdf, aes(x = variable, y = Labels, fill = value)) +

  geom_tile(colour="snow3") +
            #size=0.10,
            #height=.9) +

  scale_fill_gradient2(midpoint = 0,
                       low = "white",
                       high = "red") +

  scale_y_discrete(position = "right") +

  theme(
    strip.background = element_blank(),
    axis.title = element_blank(),
    #strip.text.x = element_blank(),
    axis.line.x = element_blank(),
    axis.ticks.x = element_blank(),
    axis.text.x = element_blank()) +

  facet_grid(~Strain,
             scales="free_x",
             space="free")
p

##ggsave("/mnt/Disc4T/Projects/PhD_Project/dif12b_10g_heatmap.png", p,
##       device = "png", width = 40, height = 20,  units = "cm")


head(heatDF)

## Labeling each row of the melted df
## n <- dim(heatDF)[1]
## strain <- factor(c(rep("12Bpre2", n),
##                    rep("12Bpre2", n),
##                    rep("12Bpre1", n),
##                    rep("12Bpre1", n),
##                    rep(rep("12Bprom", 5), n),
##                    rep(rep("12Bbody", 5), n),
##                    rep(rep("12Bterm", 5), n),
##                    rep("12Bpost1", n),
##                    rep("12Bpost1", n),
##                    rep("12Bpost2", n),
##                    rep("12Bpost2", n),

##                    rep("10Gpre2", n),
##                    rep("10Gpre2", n),
##                    rep("10Gpre1", n),
##                    rep("10Gpre1", n),
##                    rep(rep("10Gprom", 5), n),
##                    rep(rep("10Gbody", 5), n),
##                    rep(rep("10Gterm", 5), n),
##                    rep("10Gpost1", n),
##                    rep("10Gpost1", n),
##                    rep("10Gpost2", n),
##                    rep("10Gpost2", n)),

##                  levels = c("12Bpre2", "12Bpre1",
##                             "12Bprom", "12Bbody", "12Bterm",
##                             "12Bpost1", "12Bpost2",
##                             "10Gpre2", "10Gpre1",
##                             "10Gprom", "10Gbody", "10Gterm",
##                             "10Gpost1", "10Gpost2"))
#+end_src

*** Binned BEDs
**** Aim
We want to create a numeric coverage for each gene. For each gene we will consider the 1000bp before a gene and the first 500bp of the coding sequence.
**** Gene statistics: get the data
#+begin_src python
import pybedtools as pb
import pandas as pd

ref = './filtered_only_genes_sorted.gff'
genome_file = './PlasmoDB-46_Pfalciparum3D7_Genome.fasta'
ref = pb.BedTool(ref)


genome={}
with open(genome_file, 'r+') as infile:
    for line in infile:
        if line.startswith('>'):
            linelist = line.strip().split(' | ')
            chrom = linelist[0].replace('>', '')
            seize = linelist[3].replace('length=', '')
            genome[chrom] = (0, int(seize))


## Set some variables and start!
current_chrom = ''
ngenes = len(ref)
str_bed = ''
first_in_chrom = False
last_in_chrom = False
dist5ps = []
dist3ps = []

for idx, gene in enumerate(ref):

    ## Get gene id
    gid = gene.fields[8].split(';')[0].replace('ID=', '')

    ## Check Orientation:
    strand = gene.fields[6]

    ## Check if first/last in chromosome
    chrom = gene.chrom

    if current_chrom != chrom:
        first_in_chrom = True

    if idx == ngenes-1:
        ## First check if we are in the last gene!
        last_in_chrom = True
    else:
        if ref[idx+1].chrom != chrom:
            last_in_chrom = True

    ## Get distance before and after the gene
    if first_in_chrom:
        predist = gene.start
    else:
        predist = gene.start - ref[idx-1].stop

    if last_in_chrom:
        postdist = genome[chrom][1] - gene.stop
    else:
        postdist = ref[idx+1].start - gene.stop

    ## Set 5p and 3p according to strandness
    if strand == '+':
        dist5p = predist
        dist3p = postdist
    else:
        dist5p = postdist
        dist3p = predist

    ## Reset variables
    first_in_chrom = False
    last_in_chrom = False
    current_chrom = chrom

    ## Get values
    dist5ps.append(dist5p)
    dist3ps.append(dist3p)


gene_lengths = [g.stop - g.start for g in ref]
gene_ids = [g.fields[8].split(';')[0].replace('ID=', '') for g in ref]

len(gene_lengths)
len(gene_ids)
len(dist3ps)
len(dist5ps)

df = pd.DataFrame(list(zip(gene_ids, gene_lengths, dist5ps, dist3ps)),
                  columns = ['Gene_id', 'Gene_len', 'fiveP', 'threeP'])

df.to_csv('gene_lengths.csv', index = False)
#+end_src
**** Gene statistics: Plots
#+begin_src R
library(tidyverse)
library(ggplot2)
library(glue)

gene_df <- read_csv('./Binned_Coverage/gene_lengths.csv')
filtered_df <- gene_df %>%
  filter(fiveP > 0 & threeP > 0)

myHist <- function(df, column){

  column <- ensym(column)
  vals <- df %>% select(!!column) %>% pull()

  qts <- quantile(vals, probs = c(0.05, 0.95))
  mybreaks = as.integer(c(0,
                          qts[1],
                          qts[2],
                          max(vals)/2,
                          max(vals)/(3/4),
                          max(vals),
                          mean(vals)))


  p <- ggplot(df, aes(x = !!column)) +
    geom_histogram(binwidth = 100) +
    geom_vline(xintercept = mean(vals), color = 'red') +
    geom_vline(xintercept = qts[2]) +
    geom_vline(xintercept = qts[1]) +
    scale_x_continuous(breaks = mybreaks)

  ggsave(glue('./Binned_Coverage/distribution_of_{column}.png'), p, device = 'png')
  print(p)
}


myHist(filtered_df, Gene_len)
myHist(filtered_df, fiveP)
myHist(filtered_df, threeP)
#+end_src

**** Previous Steps
#+begin_src python :tangle binned_coverage.py
import pybedtools as pb
import subprocess as sp
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/'
os.chdir(wd)

# Create genome dict
genome={}
genome_file = './PlasmoDB-46_Pfalciparum3D7_Genome.fasta'
with open(genome_file, 'r+') as infile:
    for line in infile:
        if line.startswith('>'):
            linelist = line.strip().split(' | ')
            chrom = linelist[0].replace('>', '')
            seize = linelist[3].replace('length=', '')
            genome[chrom] = (0, int(seize))

# Import GFF
gff_file = './PlasmoDB-46_Pfalciparum3D7_withGDV1_ncRNAs.gff'
gff = pb.BedTool(gff_file)

## Filter genes only
sel = ['gene']# 'asRNA', 'lncRNA', "rRNA", "snoRNA", "snRNA", "tRNA", "ncRNA"]
gene_gff = gff.filter(lambda x: x.fields[2] in sel)

## Discard Apicoplast
gene_gff = gene_gff.filter(lambda x: x.chrom != 'Pf3D7_API_v3')
gene_gff.saveas('filtered_only_genes.gff')

## Sort Gene-GFF
cmd = 'python ./gff_sorter.py filtered_only_genes.gff > filtered_only_genes_sorted.gff'
sp.call(cmd, shell=True)

#+end_src
**** Find exceptions
There are a few genes that fall inside another gene (most notably GDV1 falls "inside" GDV1as). Since we usually don't want defined regulatory regions to span over previous/next gene this is a problem for the script. Therefore we will get those genes and put them in an exceptions list were we will allow for overlaps.
#+begin_src python
import pybedtools as pb
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/'
os.chdir(wd)

gff = pb.BedTool('./filtered_only_genes_sorted.gff')

exceptions = set()
for idx, gene in enumerate(gff):
    if idx > 0 and idx < len(gff)-1:
        gid = gene.fields[8].split(';')[0].replace('ID=', '')

        if gene.chrom == gff[idx-1].chrom:
            if gene.start < gff[idx-1].stop or gene.stop <= gff[idx-1].stop:
                exceptions.add(gid)
                print(gid)

        if gene.chrom == gff[idx+1].chrom:
            if gene.start >= gff[idx+1].start or gene.stop > gff[idx+1].start:
                exceptions.add(gid)
                print(gid)

        # if gid == 'Custom_PF3D7_0935400_as':
        #     print(gff[idx-1].start, gff[idx-1].stop)
        #     print(gene.start, gene.stop)
        #     print(gff[idx+1].start, gff[idx+1].stop)

with open('gene_exceptions.txt', 'w+') as outfile:
    for gene in exceptions:
        outfile.write(gene+'\n')
#+end_src
**** Get intervals of interest (tss+cds)
For each gene we want to select the preceding 1000bp (tss) and the first 500bp of the coding region.
#+begin_src python :tangle binned_coverage.py
import pybedtools as pb
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/'
os.chdir(wd)


def cut_TSS_and_CDS(gff, genome_file, excep_file, tss=1000, cds='wholegene', allowoverlaps=False):

    if not allowoverlaps:
        ## Get a list of genes that fall inside another gene
        with open(excep_file, 'r+') as f:
            exceptions = [g.strip() for g in f.readlines()]

    ## Create dict with lenght of each chromosome
    genome={}
    with open(genome_file, 'r+') as infile:
        for line in infile:
            if line.startswith('>'):
                linelist = line.strip().split(' | ')
                chrom = linelist[0].replace('>', '')
                seize = linelist[3].replace('length=', '')
                genome[chrom] = (0, int(seize))

    ## Set some variables and start loop
    ref = pb.BedTool(gff)
    current_chrom = ''
    ngenes = len(ref)
    str_bed = ''
    first_in_chrom = False
    last_in_chrom = False

    for idx, gene in enumerate(ref):

        ## Get gene id
        gid = gene.fields[8].split(';')[0].replace('ID=', '')

        ## Reset parameters
        cds_correction = 0

        ## Check Orientation:
        strain = gene.fields[6]

        ## Check if first/last in chromosome
        chrom = gene.chrom

        if current_chrom != chrom:
            first_in_chrom = True
            # print('First in chrom!')
            # print(gene)
            # print('---------------')

        if idx == ngenes-1:
            ## First check if we are in the last gene!
            last_in_chrom = True
        else:
            if ref[idx+1].chrom != chrom:
                last_in_chrom = True

        ## Set new start and new stop depending on strain:
        genlen = gene.stop - gene.start
        if cds == 'wholegene': cds = genlen

        if  genlen < cds:
                cds_correction = cds-genlen

        if strain == '+':
            newstart = gene.start-tss
            newstop = gene.start+(cds-cds_correction)
        else:
            newstart = gene.stop-(cds-cds_correction)
            newstop = gene.stop+tss

        if not allowoverlaps:
            ## Check overlapp previous gene if +strain or next gene if -strain
            ## Except for genes in exception list
            if gid not in exceptions:
                if strain == '+':
                    if first_in_chrom:
                        pass
                    else:
                        if newstart < ref[idx-1].stop:
                            newstart = ref[idx-1].stop+1
                            # print('Previous gene:')
                            # print(ref[idx-1])
                            # print('Current gene:')
                            # print(gene)
                            # print('New start-stop:')
                            # print(newstart, newstop)
                            # print('--------------------------')
                else:
                    if last_in_chrom:
                        pass
                    else:
                        if newstop > ref[idx+1].start:
                            newstop = ref[idx+1].start-1
                            # print('Next gene:')
                            # print(ref[idx+1])
                            # print('Current gene:')
                            # print(gene)
                            # print('New start-stop:')
                            # print(newstart, newstop)
                            # print('--------------------------')

        ## Check we dont go < 0
        if newstart < 0: newstart = 0

        ## Check we don't go > chrom length
        if newstop > genome[chrom][1]: newstop = genome[chrom][1]

        ## Check start always < stop
        if newstart >= newstop:
            newstop = newstart+1

        first_in_chrom = False
        last_in_chrom = False
        current_chrom = chrom

        newline = [gene.chrom, newstart, newstop, gene.fields[8].split(';')[0].replace('ID=', '')]
        newline = [str(x) for x in newline]
        str_bed += '\t'.join(newline)+'\n'

    out_bed = pb.BedTool(str_bed, from_string=True)
    return(out_bed)


ref = './filtered_only_genes_sorted.gff'
excep_file = './gene_exceptions.txt'
genome_file = './PlasmoDB-46_Pfalciparum3D7_Genome.fasta'
tss = 0
cds = 1500
allowoverlaps=True

binned_bed = cut_TSS_and_CDS(ref, genome_file, excep_file, tss=tss, cds=cds, allowoverlaps=allowoverlaps)
binned_bed.saveas(f'./Bin_Beds/final_binned_{tss}tss_{cds}orf_allowoverlaps_{allowoverlaps}.bed')

#+end_src
**** Cross coverage with binned Bed (deprecated)
Count coverage per gene, given the bed that defines each gene (as 100bp5prime+500bpCDS) as the coverage every 100bp intervals bed.
#+begin_src python :tangle join_coverage.py
import pybedtools as pb
import numpy as np
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/'
os.chdir(wd)

def cross_beds(genes_bed, coverage_bed):
    str_bed = ''
    for gene in genes_bed:

        subset = coverage_bed.filter(lambda x: x.chrom == gene.chrom and
                                     x.start >= gene.start and
                                     x.stop <= gene.stop)
        # print(gene)
        # print('...')
        # for x in subset:
        #     print(x)
        cov = [float(x.name) for x in subset]
        mean_cov = np.mean(cov)
        newline = '\t'.join(gene.fields+[str(mean_cov)])+'\n'
        str_bed += newline

    out_bed = pb.BedTool(str_bed, from_string=True)
    return(out_bed)

#genes_bed = pb.BedTool('./final_binned_1000tss_500cds_strains.bed')
genes_bed = pb.BedTool('./binned_5prime1000_ORF_3prime1000_test.bed')
#genes_bed = pb.BedTool('./binned_5prime500_1000_1500_2000_ORF_3prime500_1000_1500.bed')

cov_path = '../../Chip_Seq_Data_2021/RPKMs_normInput/'

cov_tracks = ['E5K9_me_sort_q5_RPKMs_normInput.bdg']#,
              # '3D7_me_sort_q5_RPKMs_normInput.bdg',
              # 'A7K9_me_sort_q5_RPKMs_normInput.bdg',
              # '1.2B_me_sort_q5_RPKMs_normInput.bdg',
              # '10G_me_sort_q5_RPKMs_normInput.bdg',
              # 'B11_me_sort_q5_RPKMs_normInput.bdg'
              # ]

for track in cov_tracks:
    coverage = pb.BedTool(cov_path+track)
    name = track.split('_')[0]
    print(f'Joining {name} coverage...')
    cov = cross_beds(genes_bed, coverage)
    cov.saveas(f'./Genewise_Coverages/coverage_3ORF5_{name}_genewise_oldmethod.bed')

#+end_src
**** Parse crossing
Parse the gene-wise coverage bed to convert it to csv format (annotations come out malformated in the previous bed).
#+begin_src python
import os

def parse_genewise_bed(genewise_bed, indir, outdir):
    output = genewise_bed.replace('.bed', '_parsed.csv')
    with open(indir+genewise_bed, 'r+') as infile:
        with  open(outdir+output, 'w+') as outfile:
            for line in infile:
                linelist = line.strip().split('\t')
                score = linelist[-1]
                chrom, start, stop = linelist[0:3]
                info = linelist[3:-1]
                #print(info)
                anotfield = ' '.join(info).split(';')
                #print(anotfield)
                gid = anotfield[0].replace('ID=', '')
                anot = anotfield[1].replace('description=', '')
                newline = '\t'.join([chrom, start, stop, score, gid, anot])+'\n'
                outfile.write(newline)

indir = '/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/Genewise_Coverages/'
outdir = indir
beds = [f for f in os.listdir(indir) if f.endswith('.bed')]

for bed in beds:
    parse_genewise_bed(bed, indir, outdir)

#+end_src
**** Get 5'/ ORF /3' coverage
#+begin_src python
import pybedtools as pb
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/'
os.chdir(wd)

def get_5prime_ORF_3prime(gff, genome_file, excep_file, fiveP=1000, threeP=1000, orf=[0,500], allowoverlap = False):

    if not allowoverlap:
    ## Get a list of genes that fall inside another gene
        with open(excep_file, 'r+') as f:
            exceptions = [g.strip() for g in f.readlines()]

    ## Create dict with lenght of each chromosome
    genome={}
    with open(genome_file, 'r+') as infile:
        for line in infile:
            if line.startswith('>'):
                linelist = line.strip().split(' | ')
                chrom = linelist[0].replace('>', '')
                seize = linelist[3].replace('length=', '')
                genome[chrom] = (0, int(seize))

    ## Set some variables and start!
    ref = pb.BedTool(gff)
    current_chrom = ''
    ngenes = len(ref)
    str_bed = ''
    first_in_chrom = False
    last_in_chrom = False

    for idx, gene in enumerate(ref):

        ## Get gene id
        gid = gene.fields[8].split(';')[0].replace('ID=', '')

        ## Check Orientation:
        strand = gene.fields[6]

        ## Check if first/last in chromosome
        chrom = gene.chrom

        if current_chrom != chrom:
            first_in_chrom = True

        if idx == ngenes-1:
            ## First check if we are in the last gene!
            last_in_chrom = True
        else:
            if ref[idx+1].chrom != chrom:
                last_in_chrom = True

        ## Set new start5, stop5 and star3, stop3 depending on strand:

        if strand == '+':

            prestart = gene.start-fiveP
            prestop = gene.start
            poststart = gene.stop
            poststop = gene.stop+threeP

        else:
            prestart = gene.start-threeP
            prestop = gene.start
            poststart = gene.stop
            poststop = gene.stop+fiveP

        ## Set ORF start-stop
        if strand == '+':
            orf_start = gene.start + orf[0]
            if orf_start > gene.stop: orf_start = orf_stop -1
            orf_stop = gene.start + orf[1]
            if orf_stop > gene.stop : orf_stop = gene.stop
        else:
            orf_start = gene.stop - orf[1]
            if orf_start < gene.start: orf_start = gene.start
            orf_stop = gene.stop - orf[0]
            if orf_stop < gene.start: orf_stop = gene.start + 1

        if not allowoverlap:
        ## Check overlapp previous gene if +strand or next gene if -strand
        ## Except for genes in exception list

            if gid not in exceptions:
                if first_in_chrom:
                    pass
                else:
                    if prestart < ref[idx-1].stop:
                        prestart = ref[idx-1].stop

                if last_in_chrom:
                    pass
                else:
                    if poststop > ref[idx+1].start:
                        poststop = ref[idx+1].start

        ## Check we dont go < 0
        if prestart < 0: prestart = 0
        if orf_start < 0: orf_start = 0

        ## Check we don't go > chrom length
        if poststop > genome[chrom][1]: poststop = genome[chrom][1]
        if orf_stop > genome[chrom][1]: orf_stop = genome[chrom][1]

        ## Check start always start < stop
        if prestart >= prestop:
            prestop = prestart+1
            print(f'Pre region error! In gene :{gid}')
            print(prestart, prestop)
        if orf_start >= orf_stop:
            print(f'ORF region error! In gene :{gid}')
            print(orf_start, orf_stop)
            orf_stop = orf_start+1
        if poststart >= poststop:
            poststop = poststart+1
            print(f'Post region error! In gene :{gid}')
            print(poststart, poststop)


        ## Reset variables
        first_in_chrom = False
        last_in_chrom = False
        current_chrom = chrom

        ## Prepare output
        presuffix = '_5prime' if strand == '+' else '_3prime'
        postsuffix = '_3prime' if strand == '+' else '_5prime'

        preline = '\t'.join([gene.chrom,
                             str(prestart),
                             str(prestop),
                             gid+presuffix, '.', strand])

        ORFline = '\t'.join([gene.chrom,
                             str(orf_start),
                             str(orf_stop),
                             gid, '.', strand])

        postline = '\t'.join([gene.chrom,
                              str(poststart),
                              str(poststop),
                              gid+postsuffix,'.', strand])

        str_bed += ('\n'.join([preline, ORFline, postline])+'\n')

    ## Convert strig output into bedtools object and return
    out_bed = pb.BedTool(str_bed, from_string=True)
    #out_bed.saveas(f'binned_5prime{fiveP}_ORF_{orf[0]}_{orf[1]}_3prime{threeP}.bed')
    return(out_bed)

ref = './filtered_only_genes_sorted.gff'
excep_file = './gene_exceptions.txt'
genome_file = './PlasmoDB-46_Pfalciparum3D7_Genome.fasta'

fiveP = 1000
threeP = 1000
orf = [0,500]
allowoverlap = True

binned_bed = get_5prime_ORF_3prime(ref, genome_file, excep_file, fiveP, threeP, orf, allowoverlap)
binned_bed.saveas(f'binned_5prime{fiveP}_ORF_{orf[0]}_{orf[1]}_3prime{threeP}_allowoverlap{allowoverlap}.bed')
#+end_src
**** Get Many Bins
#+begin_src python
import pybedtools as pb
import os
from itertools import compress

wd = '/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/'
os.chdir(wd)

def get_5prime_ORF_3prime(gff, genome_file, excep_file, fPbins=[], tPbins=[], allowoverlap=False):

    ## Get a list of genes that fall inside another gene
    with open(excep_file, 'r+') as f:
        exceptions = [g.strip() for g in f.readlines()]

    ## Create dict with lenght of each chromosome
    genome={}
    with open(genome_file, 'r+') as infile:
        for line in infile:
            if line.startswith('>'):
                linelist = line.strip().split(' | ')
                chrom = linelist[0].replace('>', '')
                seize = linelist[3].replace('length=', '')
                genome[chrom] = (0, int(seize))

    ## Set some variables and start!
    ref = pb.BedTool(gff)
    current_chrom = ''
    ngenes = len(ref)
    str_bed = ''
    first_in_chrom = False
    last_in_chrom = False

    for idx, gene in enumerate(ref):
        print(idx)

        #idx = 4
        #gene = ref[idx]

        ## Get gene id
        gid = gene.fields[8].split(';')[0].replace('ID=', '')

        ## Check Orientation:
        strand = gene.fields[6]

        ## Check if first/last in chromosome
        chrom = gene.chrom

        if current_chrom != chrom:
            first_in_chrom = True

        if idx == ngenes-1:
            ## First check if we are in the last gene!
            last_in_chrom = True
        else:
            if ref[idx+1].chrom != chrom:
                last_in_chrom = True

        ## Set default pre and post dist
        if strand == '+':
            predist = gene.start - max(fPbins)
            postdist = gene.stop + max(tPbins)
        else:
            predist = gene.start - max(tPbins)
            postdist = gene.stop + max(fPbins)

        ## Check distances to neighboring genes
        if first_in_chrom:
            predist = gene.start
        else:
            if not allowoverlap:
                predist = gene.start - ref[idx-1].stop

        if last_in_chrom:
            postdist = genome[chrom][1] - gene.stop
        else:
            if not allowoverlap:
                postdist = ref[idx+1].start - gene.stop

        if not allowoverlap:
            ## Rearrange pre/post dist if gene in exceptions
            if gid in exceptions:
                if strand == '+':
                    predist = gene.start - max(fPbins)
                    postdist = gene.stop + max(tPbins)
                else:
                    predist = gene.start - max(tPbins)
                    postdist = gene.stop + max(fPbins)

        ## Get regions intervals

        genlen = gene.stop-gene.start
        g14, g24, g34 = round(genlen/4), round(genlen/2), round(3*genlen/4)
        genelims = [gene.start,
                    gene.start + g14,
                    gene.start + g24,
                    gene.start + g34,
                    gene.stop]
        namesorf = ['q1', 'q2', 'q3', 'q4']

        if strand == '+':
            fits5 = [i <= predist for i in fPbins]
            fits3 = [i <= postdist for i in tPbins]
            limspre = sorted([gene.start - i for i in compress(fPbins, fits5)])
            namespre = [str(x) for x in compress(fPbins[::-1], fits5[::-1])]
            limspost = sorted([gene.stop + i for i in compress(tPbins, fits3)])
            namespost = [str(x) for x in compress(tPbins, fits3)]

            if not allowoverlap:
                ## If len 5p < 500 add region until previous gene
                if len(limspre) == 0 and not first_in_chrom and gid not in exceptions:
                    limspre = [int(ref[idx-1].stop)]
                    namespre = [str(fPbins[0])]

        else:
            fits5 = [i <= postdist for i in fPbins]
            fits3 = [i <= predist for i in tPbins]
            limspost = sorted([gene.stop + i for i in compress(fPbins, fits5)])
            namespost = [str(x) for x in fPbins]
            limspre = sorted([gene.start - i for i in compress(tPbins, fits3)])
            namespre = [str(x) for x in compress(tPbins[::-1], fits3[::-1])]
            namesorf = namesorf[::-1]

            if not allowoverlap:
                ## If len 5p < 500 add region until next gene
                if len(limspost) == 0 and not last_in_chrom and gid not in exceptions:
                    limspost = [int(ref[idx+1].start)]
                    namespost = [str(fPbins[0])]

        ## Add first/final point to lims
        limspre = limspre + [gene.start]
        limspost = [gene.stop] + limspost

        ## Reset variables
        first_in_chrom = False
        last_in_chrom = False
        current_chrom = chrom

        ## Prepare output
        presuffix = '_5prime' if strand == '+' else '_3prime'
        postsuffix = '_3prime' if strand == '+' else '_5prime'

        outlines = []
        # print(limspre, namespre)
        # print(limspost, namespost)

        def append_lines(lims, suffix, names, outlist):
            for idx, i in enumerate(lims[0:-1]):
                line = '\t'.join([gene.chrom,
                             str(i),
                             str(lims[idx+1]),
                             gid+suffix+'_'+names[idx],'.', strand])
                outlist.append(line)

        append_lines(limspre, presuffix, namespre, outlines)
        append_lines(genelims, '', namesorf, outlines)
        append_lines(limspost, postsuffix, namespost, outlines)

        str_bed += ('\n'.join(outlines)+'\n')

    str_fpbins = '_'.join([str(x) for x in fPbins])
    str_tpbins = '_'.join([str(x) for x in tPbins])

    ## Convert strig output into bedtools object and return
    out_bed = pb.BedTool(str_bed, from_string=True)
    f = [str_fpbins, str_tpbins, allowoverlap]
    out_bed.saveas(f'./Bin_Beds/binned_5prime{f[0]}_ORF_3prime{f[1]}_allowoverlap{f[2]}.bed')
    return(out_bed)

gff = './filtered_only_genes_sorted.gff'
excep_file = './gene_exceptions.txt'
genome_file = './PlasmoDB-46_Pfalciparum3D7_Genome.fasta'
fPbins = [500, 1000, 1500, 2000]
tPbins = [500, 1000, 1500]
allowoverlap = False

binned_bed = get_5prime_ORF_3prime(gff, genome_file, excep_file, fPbins, tPbins, allowoverlap=allowoverlap)

#+end_src
**** Get PlasmoDB_51 UTRs
#+begin_src python
import pybedtools as pb
import pandas as pd
import subprocess as sp
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/'
os.chdir(wd)

gff = pb.BedTool('./PlasmoDB-51_Pfalciparum3D7.gff')
types = [g.fields[2] for g in gff]
set(types)

sel = [
    #'CDS',
    #'ncRNA_gene',
    'five_prime_UTR',
    'three_prime_UTR'
]

gene_gff = gff.filter(lambda x: x.fields[2] in sel)

genes = []
for gene in gene_gff:
    gtype = gene.fields[2]
    info = gene.fields[8].split(';')
    gid = info[0].replace('ID=', '').split('.')[0]+'_'+gtype
    anot = info[1].replace('description=', '')
    genes.append([gene.chrom, gene.start, gene.stop, gid, gtype])

genes_df = pd.DataFrame(genes, columns = ['Chrom', 'Start', 'Stop', 'Gene_id', 'Type'])
genes_df.to_csv('plasmoDB_UTRs.bed', index = False, header = False, sep = '\t')

bed = pb.BedTool('plasmoDB_UTRs.bed')
bed.sort().saveas('plasmoDB_UTRs_sorted.bed')
#+end_src
**** Get PlasmoDB TSSs
We will consider as TSS a region of 400bp arround the start of the 5pUTR.
#+begin_src python
import pybedtools as pb
import pandas as pd
import subprocess as sp
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/'
os.chdir(wd)

gff = pb.BedTool('./PlasmoDB-51_Pfalciparum3D7.gff')
types = [g.fields[2] for g in gff]
set(types)

sel = [
    'five_prime_UTR'
]

gene_gff = gff.filter(lambda x: x.fields[2] in sel)

genes = []
for gene in gene_gff:

    start = gene.start-200
    stop = gene.start+200
    gtype = gene.fields[2]
    info = gene.fields[8].split(';')
    gid = info[0].replace('ID=', '').split('.')[0]+'_TSS'
    anot = info[1].replace('description=', '')
    genes.append([gene.chrom, start, stop, gid])

genes_df = pd.DataFrame(genes, columns = ['Chrom', 'Start', 'Stop', 'Gene_id'])
genes_df.to_csv('plasmoDB_TSSs.bed', index = False, header = False, sep = '\t')

bed = pb.BedTool('plasmoDB_TSSs.bed')
bed.sort().saveas('plasmoDB_TSSs_sorted.bed')
#+end_src
**** Get ATG +- 2000bp coverage
#+begin_src python
import pybedtools as pb
import pandas as pd
import subprocess as sp
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/'
os.chdir(wd)

gff = pb.BedTool('./PlasmoDB-46_Pfalciparum3D7_withGDV1_ncRNAs.gff')
types = [g.fields[2] for g in gff]
set(types)

sel = [
    'gene'
]

gene_gff = gff.filter(lambda x: x.fields[2] in sel)

genes = []
for gene in gene_gff:

    start = gene.start-2000
    if start < 0: start = 0
    stop = gene.start+2000
    gtype = gene.fields[2]
    info = gene.fields[8].split(';')
    gid = info[0].replace('ID=', '')
    anot = info[1].replace('description=', '')
    genes.append([gene.chrom, start, stop, gid])

genes_df = pd.DataFrame(genes, columns = ['Chrom', 'Start', 'Stop', 'Gene_id'])
genes_df.to_csv('ATG_+-2000bp.bed', index = False, header = False, sep = '\t')

bed = pb.BedTool('ATG_+-2000bp.bed')
bed.sort().saveas('ATG_+-2000bp.bed')
#+end_src
**** Cross Coverage with bins NEW
We get the mean coverage across the submitted bed regions.
#+begin_src python
import pybedtools as pb
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/'
os.chdir(wd)

#genes_bed = pb.BedTool('./Bin_Beds/final_binned_1000tss_500orf.bed')
#genes_bed = pb.BedTool('./Bin_Beds/binned_5prime1000_ORF_3prime1000.bed')
#genes_bed = pb.BedTool('./Bin_Beds/final_binned_0tss_500orf.bed')
#genes_bed = pb.BedTool('./Bin_Beds/final_binned_0tss_1000orf.bed')
#genes_bed = pb.BedTool('./Bin_Beds/final_binned_0tss_1500orf.bed')
#genes_bed = pb.BedTool('./Bin_Beds/plasmoDB_UTRs_sorted.bed')
#genes_bed = pb.BedTool('./Bin_Beds/plasmoDB_TSSs_sorted.bed')
#genes_bed = pb.BedTool('./Bin_Beds/binned_5prime500_1000_1500_2000_ORF_3prime500_1000_1500_withnames_small5p.bed')
#genes_bed = pb.BedTool('./Bin_Beds/binned_5prime500_ORF_1000_1500_3prime500.bed')
#genes_bed = pb.BedTool('./Bin_Beds/final_binned_1000tss_0orf_allowoverlaps_True.bed')
#genes_bed = pb.BedTool('./Bin_Beds/binned_5prime500_1000_1500_2000_ORF_3prime500_1000_1500_allowoverlapTrue.bed')
#genes_bed = pb.BedTool('./Bin_Beds/binned_5prime1000_ORF_0_500_3prime1000_allowoverlapTrue.bed')
#genes_bed = pb.BedTool('./Bin_Beds/binned_5prime1000_ORF_500_1000_3prime1000_allowoverlapTrue.bed')
#genes_bed = pb.BedTool('./Bin_Beds/binned_5prime1000_ORF_0_500_3prime1000_allowoverlapTrue.bed')

genes_bed = pb.BedTool('./Bin_Beds/final_binned_0tss_1500orf_allowoverlaps_True.bed')



#cov_path = '../../Chip_Seq_Data_2021/RPKMs_normInput/'
cov_path = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/RPKMs_normInput/'
cov_tracks = ['E5K9_me_sort_q5_RPKMs_normInput.bdg',
              '3D7_me_sort_q5_RPKMs_normInput.bdg',
              'A7K9_me_sort_q5_RPKMs_normInput.bdg',
              '1.2B_me_sort_q5_RPKMs_normInput.bdg',
              '10G_me_sort_q5_RPKMs_normInput.bdg',
              'B11_me_sort_q5_RPKMs_normInput.bdg'
              ]

for track in cov_tracks:
    coverage = pb.BedTool(cov_path+track)
    name = track.split('_')[0]
    print(f'Joining {name} coverage...')
    cov = genes_bed.sort().map(coverage, c = 4, o='mean')
    cov.saveas(f'./Genewise_Coverages/cov_1500orf_allowoverlap_{name}.bed')
#+end_src
**** Subset coverage to regions
Get the coverage over the regions of interest.
#+begin_src python
import pybedtools as pb
import os

wd = '/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/'
os.chdir(wd)

genes_bed = pb.BedTool('./ATG_+-2000bp.bed')

cov_path = '../../Chip_Seq_Data_2021/RPKMs_normInput/'

cov_tracks = ['E5K9_me_sort_q5_RPKMs_normInput.bdg',
              '3D7_me_sort_q5_RPKMs_normInput.bdg',
              'A7K9_me_sort_q5_RPKMs_normInput.bdg',
              '1.2B_me_sort_q5_RPKMs_normInput.bdg',
              '10G_me_sort_q5_RPKMs_normInput.bdg',
              'B11_me_sort_q5_RPKMs_normInput.bdg'
              ]

for track in cov_tracks:
    coverage = pb.BedTool(cov_path+track)
    name = track.split('_')[0]
    print(f'Joining {name} coverage...')
    cov = coverage.intersect(genes_bed.sort(), wb=True)
    cov.saveas(f'./Genewise_Coverages/coverage_ATG+-2000bp_GIDS_{name}.bed')


#+end_src
**** Create ATG coverage table
#+begin_src python
import pybedtools as pb
import os
from collections import defaultdict
import pandas as pd

wd = '/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/'
os.chdir(wd)

cov_file = './Genewise_Coverages/coverage_ATG+-2000bp_GIDS_1.2B.bed'
cov_bed = pb.BedTool(cov_file)

gene_cov = defaultdict(list)
for interval in cov_bed:
    gid = interval.fields[7]
    cov = interval.fields[3]
    gene_cov[gid].append(cov)


len(gene_cov.items())
full_genes = {k: v for k, v in gene_cov.items() if len(v) == 41}
df = pd.DataFrame.from_dict(full_genes, orient='index')
df.to_csv('ATG_cov_12B.csv')

#+end_src
* Variant Calling
** Define Functions
*** Imports
#+begin_src python :tangle ./Scripts/variant_calling.py
import subprocess as sp
import os

gatk = '/home/lucas/Programs/gatk-4.1.9.0/gatk'
wd = '/mnt/Disc4T/Projects/PhD_Project/Variant_Calling/'
os.chdir(wd)
#+end_src
*** Step -1: Create known sites of variation BED
Since we have no previous information on variants, we use an empty file.
#+begin_src python tangle: parse_plasmoDB_variant_sites.py :eval never
# first = True
# with open('./known_SNP.txt', 'r+') as infile:
#     with open('known_SNPs.bed', 'w+') as outfile:
#         for line in infile:
#             if first:
#                 first = False
#             else:
#                 linelist = line.strip().split('\t')
#                 chrompos = linelist[1]
#                 minorallel = linelist[3]
#                 #print(chrompos)
#                 chrom, pos = chrompos.split(': ')
#                 start = int(pos.replace(',', ''))
#                 outfile.write('\t'.join([chrom,
#                                         str(start),
#                                         str(start+1),
#                                          minorallel])+'\n')

def index_feature_file(feat_file):
    cmd = '{} IndexFeatureFile -I {}' .format(gatk, feat_file)
    sp.call(cmd, shell = True)

index_feature_file('./empty.bed')


#+end_src

#+RESULTS:

*** Step 0: Add read-groups
#+begin_src python :tangle ./Scripts/variant_calling.py
def AddOrReplaceReadGroups(bam):
    output = bam.replace('.bam', '_withRG.bam')
    name = bam.rsplit('.')[0]
    cmd = ("java -jar /home/lucas/Programs/picard.jar "
           "AddOrReplaceReadGroups "
           "-INPUT {} "
           "-OUTPUT {} "
           "-RGID group_{} "
           "-RGLB lib_{} "
           "-RGPL illumina "
           "-RGPU unit1 "
           "-RGSM {}_sample") .format(bam, output, name, name, name)
    sp.call(cmd, shell=True)
#+end_src
*** Step 1: Mark Duplicates (MarkDuplicates, samtools sort)
This second processing step is performed per-sample and consists of identifying read pairs that are likely to have originated from duplicates of the same original DNA fragments through some artifactual processes. These are considered to be non-independent observations, so the program tags all but a single read pair within each set of duplicates, causing the marked pairs to be ignored by default during the variant discovery process. At this stage the reads also need to be sorted into coordinate-order for the next step of the pre-processing. MarkDuplicatesSpark performs both the duplicate marking step and the sort step for this stage of pre-processing. This phase of the pipeline has historically been a performance bottleneck due to the large number of comparisons made between read pairs in a sample so MarkDuplicatesSpark utilizes Apache Spark in order to parallelize the process to better take advantage all available resources. This tool can be run locally even without access to a dedicated Spark cluster.
#+begin_src python :tangle ./Scripts/variant_calling.py
def mark_duplicates(bam):
    outfile = bam.replace('.bam', '_markedDuplicates.bam')
    mtrcsfile = bam.replace('.bam', '_metrics.txt')
    args = [gatk, bam, outfile, mtrcsfile]
    cmd = '{} MarkDuplicates -I {} -O {} -M {}' .format(*args)
    sp.call(cmd, shell=True)

    cmd = 'samtools sort {} -o {}' .format(outfile, outfile)
    sp.call(cmd, shell=True)

#+end_src
*** Step 2: Base Recalibration (BaseRecalibrator, ApplyRecalibration)
This third processing step is performed per-sample and consists of applying machine learning to detect and correct for patterns of systematic errors in the base quality scores, which are confidence scores emitted by the sequencer for each base. Base quality scores play an important role in weighing the evidence for or against possible variant alleles during the variant discovery process, so it's important to correct any systematic bias observed in the data. Biases can originate from biochemical processes during library preparation and sequencing, from manufacturing defects in the chips, or instrumentation defects in the sequencer. The recalibration procedure involves collecting covariate measurements from all base calls in the dataset, building a model from those statistics, and applying base quality adjustments to the dataset based on the resulting model. The initial statistics collection can be parallelized by scattering across genomic coordinates, typically by chromosome or batches of chromosomes but this can be broken down further to boost throughput if needed. Then the per-region statistics must be gathered into a single genome-wide model of covariation; this cannot be parallelized but it is computationally trivial, and therefore not a bottleneck. Finally, the recalibration rules derived from the model are applied to the original dataset to produce a recalibrated dataset. This is parallelized in the same way as the initial statistics collection, over genomic regions, then followed by a final file merge operation to produce a single analysis-ready file per sample.
#+begin_src python :tangle ./Scripts/variant_calling.py
def base_recalibration(bam):

    outfile = bam.replace('.bam', '_baserecal_table.table')
    known = './empty.bed'
    ref = './ref.fasta'
    args = [gatk, bam, ref, known, outfile]

    cmd = ('{} BaseRecalibrator '
           '-I {} -R {} '
           '--known-sites {} '
           '-O {}') .format(*args)

    sp.call(cmd, shell=True)

def applyBQSR(bam):

    outfile = bam.replace('.bam', '_BQSR.bam')
    recal_table = bam.replace('.bam', '_baserecal_table.table')
    ref = './ref.fasta'
    args = [gatk, bam, ref, recal_table, outfile]

    cmd = ('{} ApplyBQSR '
           '-I {} -R {} '
           '--bqsr-recal-file {} '
           '-O {}') .format(*args)

    sp.call(cmd, shell=True)

#+end_src

#+RESULTS:
: None

*** Step 3: Merge Bams (MergeSamFiles)
This tool is used for combining SAM and/or BAM files from different runs or read groups into a single file, similar to the \"merge\" function of Samtools (http://www.htslib.org/doc/samtools.html).

Note that to prevent errors in downstream processing, it is critical to identify/label read groups appropriately. If different samples contain identical read group IDs, this tool will avoid collisions by modifying the read group IDs to be unique. For more information about read groups, see the GATK Dictionary entry.
#+begin_src python :tangle ./Scripts/variant_calling.py
def mergeBams(*bams, out):
    nbams = len(bams)
    inputs = '-I {} '*nbams
    cmd = 'java -jar /home/lucas/Programs/picard.jar ' \
        'MergeSamFiles ' + \
        inputs .format(*bams) + \
        '-O {}.bam' .format(out)
    sp.call(cmd, shell=True)


#+end_src

#+RESULTS:
: None

*** Step 3: Call Variants (Haplotype caller)
Call germline SNPs and indels via local re-assembly of haplotypes

The HaplotypeCaller is capable of calling SNPs and indels simultaneously via local de-novo assembly of haplotypes in an active region. In other words, whenever the program encounters a region showing signs of variation, it discards the existing mapping information and completely reassembles the reads in that region. This allows the HaplotypeCaller to be more accurate when calling regions that are traditionally difficult to call, for example when they contain different types of variants close to each other. It also makes the HaplotypeCaller much better at calling indels than position-based callers like UnifiedGenotyper.

In the GVCF workflow used for scalable variant calling in DNA sequence data, HaplotypeCaller runs per-sample to generate an intermediate GVCF (not to be used in final analysis), which can then be used in GenotypeGVCFs for joint genotyping of multiple samples in a very efficient way. The GVCF workflow enables rapid incremental processing of samples as they roll off the sequencer, as well as scaling to very large cohort sizes (e.g. the 92K exomes of ExAC).

In addition, HaplotypeCaller is able to handle non-diploid organisms as well as pooled experiment data. Note however that the algorithms used to calculate variant likelihoods is not well suited to extreme allele frequencies (relative to ploidy) so its use is not recommended for somatic (cancer) variant discovery. For that purpose, use Mutect2 instead.

How HaplotypeCaller works

1. Define active regions

The program determines which regions of the genome it needs to operate on (active regions), based on the presence of evidence for variation.
2. Determine haplotypes by assembly of the active region

For each active region, the program builds a De Bruijn-like graph to reassemble the active region and identifies what are the possible haplotypes present in the data. The program then realigns each haplotype against the reference haplotype using the Smith-Waterman algorithm in order to identify potentially variant sites.

3. Determine likelihoods of the haplotypes given the read data

For each active region, the program performs a pairwise alignment of each read against each haplotype using the PairHMM algorithm. This produces a matrix of likelihoods of haplotypes given the read data. These likelihoods are then marginalized to obtain the likelihoods of alleles for each potentially variant site given the read data.

4. Assign sample genotypes

For each potentially variant site, the program applies Bayes' rule, using the likelihoods of alleles given the read data to calculate the likelihoods of each genotype per sample given the read data observed for that sample. The most likely genotype is then assigned to the sample.

Input

Input bam file(s) from which to make variant calls

Output

Either a VCF or GVCF file with raw, unfiltered SNP and indel calls. Regular VCFs must be filtered either by variant recalibration (Best Practice) or hard-filtering before use in downstream analyses. If using the GVCF workflow, the output is a GVCF file that must first be run through GenotypeGVCFs and then filtering before further analysis.

#+begin_src python :tangle ./Scripts/variant_calling.py
def call_variants(bam):
    outfile = bam.replace('.bam', '_variants.vcf')
    ref = './ref.fasta'
    args = [gatk, ref, bam, outfile]

    cmd = ('{} --java-options "-Xmx4g" HaplotypeCaller '
           '-R {} -I {} -O {} -ploidy 1') .format(*args)

    sp.call(cmd, shell=True)
#+end_src

#+RESULTS:
: None

*** Step 4: Annotate variants (VEP)
We will use ~vep~ from [[https://www.ensembl.org/info/docs/tools/vep/index.html]]
~vep~ will give us annotations on both the nearest gene to a variant and the
genetic effects of it (synonymous/missense/stop_codon...).
Since P.Falciparum is not among the available species we will have to use a
custom annotation file.
For ~vep~ to be able to use it, the GFF file must be chromosome sorted and tabix
indexed and biotype annotations must be added.
We choose vcf output to retain it's information (allele freq, read depth...).
**** Create custom GFF (for VEP)
#+begin_src python :tangle ./Scripts/create_custom_gff_for_VEP.py :eval never
import pybedtools as pb
import subprocess as sp
import os

outfld = "/mnt/Disc4T/Projects/PhD_Project/Variant_Calling/"
os.chdir(outfld)

# Filter out lines that do not correspond to genes
gff = pb.BedTool("../Data/PlasmoDB-52_Pfalciparum3D7.gff")

types = [feat.fields[2] for feat in gff]
set(types)


# Add biotype info to transcripts (it is a VEP requisite)
biotypes = {
    "mRNA": "protein_coding",
    "ncRNA": "ncRNA",
    "rRNA": "rRNA",
    "snoRNA": "snoRNA",
    "snRNA": "snRNA",
    "tRNA": "tRNA",
    "five_prime_UTR": "five_prime_UTR",
    "three_prime_UTR": "three_prime_UTR",
    "pseudogenic_transcript": "pseudogenic_transcript"
}

def add_biotype(feature):
    if feature.fields[2] in biotypes.keys():
        feature.attrs["biotype"] = biotypes[feature.fields[2]]
    return(feature)

added_biotype = gff.each(add_biotype)

# Sort GFF

added_biotype.sort().saveas("PlDB-52_Pfalciparum3D7_vep.gff")

# Change type from "protein_coding_gene" to "gene"

types = ['ncRNA_gene', 'protein_coding_gene']

with open("PlDB-52_Pfalciparum3D7_vep.gff", 'r+') as infile:
    with open("PlDB-52_Pfalciparum3D7_vep_changetypes.gff", 'w+') as outfile:
        for line in infile:
            linelist = line.strip().split('\t')
            if linelist[2] in types:
                linelist[2] = 'gene'
            outfile.write('\t'.join(linelist)+'\n')

# Compress GFF
cmd = "bgzip PlDB-52_Pfalciparum3D7_vep_changetypes.gff"
sp.call(cmd, shell=True)

# Tabix GFF
cmd = "tabix -p gff PlDB-52_Pfalciparum3D7_vep_changetypes.gff.gz"
sp.call(cmd, shell=True)
#+end_src

**** Run VEP
#+begin_src python :tangle ./Scripts/variant_calling.py
def call_VEP(vcf, gff, fasta):

    out = vcf.replace('.vcf', '_VEPannotated.txt')
    args = [vcf, out, gff, fasta]

    cmd = ("/home/lucas/Programs/ensembl-vep/vep "
           "-i {} "
           "-o {} "
           "--gff {} "
           "--fasta {} "
           "--force_overwrite "
           "--vcf") .format(*args)

    sp.call(cmd, shell=True)

#+end_src

#+RESULTS:
: None

** Calls
#+begin_src python :tangle ./Scripts/variant_calling.py
import os
import subprocess as sp

wd = '/mnt/Disc4T/Projects/PhD_Project/Variant_Calling/'
os.chdir(wd)

gatk = '/home/lucas/Programs/gatk-4.1.9.0/gatk'
indir = '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/Bams/'

os.listdir(indir)

bams = ['1.2B_in_sort_q5.bam',
        '10G_in_sort_q5.bam',
        'A7K9_in_sort_q5.bam',
        'E5K9_in_sort_q5.bam',
        'B11_in_sort_q5.bam'
        #'NF54_in_renamed_q5_sort.bam',
        ]

for bam in bams:
    bam = indir+bam

    AddOrReplaceReadGroups(bam)
    bam = bam.replace('.bam', '_withRG.bam')

    mark_duplicates(bam)
    bam = bam.replace('.bam', '_markedDuplicates.bam')

    base_recalibration(bam)
    applyBQSR(bam)
    bam = bam.replace('.bam', '_BQSR.bam')


bamlist = [f for f in os.listdir(indir) if f.endswith('_withRG_markedDuplicates_BQSR.bam')]

os.chdir(indir)
mergeBams(*bamlist, out = 'merged_12B_10G_A7_E5_B11')

bam = 'merged_12B_10G_A7_E5_B11.bam'
sp.call('samtools index {}' .format(bam), shell=True)
call_variants(bam)

os.chdir(wd)
vcf = './merged_12B_10G_A7_E5_B11_variants.vcf'
gff = './PlDB-52_Pfalciparum3D7_vep_changetypes.gff.gz'
fasta = './ref.fasta'
call_VEP(vcf, gff, fasta)

#+end_src

** Manual part
*** Step 5: Parse VEP output and annotate
#+begin_src python :tangle ./Scripts/parse_VEP.py
import pybedtools as pb
import pandas as pd
import numpy as np
import os
from itertools import chain

project_path = "/mnt/Disc4T/Projects/PhD_Project/Variant_Calling/"
os.chdir(project_path)

vep = pb.BedTool("merged_12B_10G_A7_E5_B11_variants_VEPannotated.txt")
gff = pb.BedTool("PlDB-52_Pfalciparum3D7_vep_changetypes.gff.gz")

# Create dict for annotation (from GFF)
gff_gene = gff.filter(lambda x: x[2] in ["gene", "pseudogene"])

def getAnnot(gffentry):

    info = gffentry.fields[8].split(";")
    dinfo = {x.split('=')[0]:x.split('=')[1] for x in info}
    gid = dinfo['ID']
    anot = dinfo['description']
    return([gid, anot])

annot = {}
for entry in gff_gene:
    ga = getAnnot(entry)
    annot[ga[0]] = ga[1]

def getRatioDepth(GF):
    if len(GF) <2:
        rf = np.nan
        alt = np.nan
        ratio = np.nan
        dp = 0
    else:
        rf = int(GF[1].split(",")[0])
        alt = int(GF[1].split(",")[1])
        dp = rf+alt

        if dp == 0:
            ratio = np.nan
        else:
            ratio = round(rf / dp, 1)

    return(rf, alt, ratio, dp)

# Create parsed output

def parse_variant(variant):

    # Parse vcf info
    ref = variant.fields[3]
    alt = variant.fields[4]
    pos = variant.start
    chrom = variant.chrom

    v10G = variant.fields[9].split(":")
    v12B = variant.fields[10].split(":")
    vA7 = variant.fields[11].split(":")
    vB11 = variant.fields[12].split(":")
    vE5 = variant.fields[13].split(":")

    ref_count1, alt_count1, r1, d1 = getRatioDepth(v10G)
    ref_count2, alt_count2, r2, d2 = getRatioDepth(v12B)
    ref_count3, alt_count3, r3, d3 = getRatioDepth(vA7)
    ref_count4, alt_count4, r4, d4 = getRatioDepth(vB11)
    ref_count5, alt_count5, r5, d5 = getRatioDepth(vE5)

    parsed_vcf = [chrom, pos, ref, alt,
                  ref_count1, alt_count1, r1, d1,
                  ref_count2, alt_count2, r2, d2,
                  ref_count3, alt_count3, r3, d3,
                  ref_count4, alt_count4, r4, d4,
                  ref_count5, alt_count5, r5, d5,
                  ]

    # Parse vep info
    info = {}
    for x in variant.fields[7].split(";"):
        feat = x.split("=")
        if len(feat) == 2:
            info[feat[0]] = feat[1]
        else:
            info[feat[0]] = ""

    vep_out = info["CSQ"].split(",")
    effects = [effect.split("|") for effect in vep_out]

    # Add annotation (from GFF)
    for effect in effects:
        gene = effect[4]
        if gene != "":
            gannot = annot[gene]
        else:
            gannot = ""
        effect.append(gannot)

    parsed_variant = [parsed_vcf + effect for effect in effects]

    return(parsed_variant)

# Create DF
colnames = ["Chrom", "Pos", "Ref", "Alt",
            "RefCount_10G", "AltCount_10G", "RefRatio_10G", "depth_10G",
            "RefCount_12B", "AltCount_12B", "RefRatio_12B", "depth_12B",
            "RefCount_A7", "AltCount_A7", "RefRatio_A7", "depth_A7",
            "RefCount_B11", "AltCount_B11", "RefRatio_B11", "depth_B11",
            "RefCount_E5", "AltCount_E5", "RefRatio_E5", "depth_E5",

            "Allele",
            "Consequence",
            "IMPACT",
            "SYMBOL",
            "Gene",
            "Feature_type",
            "Feature",
            "BIOTYPE",
            "EXON",
            "INTRON",
            "HGVSc",
            "HGVSp",
            "cDNA_position",
            "CDS_position",
            "Protein_position",
            "Amino_acids",
            "Codons",
            "Existing_variation",
            "DISTANCE",
            "STRAND",
            "FLAGS",
            "SYMBOL_SOURCE",
            "HGNC_ID",
            "SOURCE",
            "PlDB-52_Pfalciparum3D7_vep.gff.gz",

            "Annot"]


parsed = [parse_variant(var) for var in vep]
flat = list(chain.from_iterable(parsed))
var_df = pd.DataFrame.from_records(flat, columns=colnames)

var_df.to_csv("parsed_variants.csv")


#+end_src
*** Step 6: Subset VariantsDF
#+begin_src python :session subsetDF :tangle ./Scripts/parse_Vep.py
import os
import pandas as pd

wd = "/mnt/Disc4T/Projects/PhD_Project/Variant_Calling/"
os.chdir(wd)

var_df = pd.read_csv("parsed_variants.csv", index_col=0)
var_df.head()

# Drop empty columns
empty = var_df.columns[var_df.isna().all(axis=0)].tolist()
var_df = var_df.drop(columns=empty)
var_df.columns

# Set ratio difference and read depth thresholds
r_thld = 0.5
d_thld = 20

# Subset DF
NF54_p18 = abs(var_df["RefRatio_NF54"] - var_df["RefRatio_P18"]) >= r_thld
NF54_p63 = abs(var_df["RefRatio_NF54"] - var_df["RefRatio_P63"]) >= r_thld
p18_p63 = abs(var_df["RefRatio_P63"] - var_df["RefRatio_P18"]) >= r_thld

d_NF54 = var_df["depth_NF54"] >= d_thld
d_p18 = var_df["depth_P18"] >= d_thld
d_p63 = var_df["depth_P63"] >= d_thld

# df = var_df[(NF54_p18 | NF54_p63 | p18_p63) &
#                    (d_NF54 & d_p18 & d_p63)]

df = var_df[(NF54_p18 & d_NF54 & d_p18) |
            (NF54_p63 & d_NF54 & d_p63) |
            (p18_p63 & d_p18 & d_p63)]

vep_cols = ['Consequence',
            'IMPACT',
            'Feature_type',
            'Feature',
            'BIOTYPE',
            'EXON',
            'INTRON',
            'cDNA_position',
            'CDS_position',
            'Protein_position',
            'Amino_acids',
            'Codons',
            'DISTANCE',
            'STRAND']

df = df[['Ref', 'Alt', 'Chrom', 'Pos',
         'RefRatio_NF54', 'RefRatio_P18', 'RefRatio_P63',
         'depth_NF54', 'depth_P18', 'depth_P63',
         'Gene', 'Annot']+vep_cols]

df.to_csv("parsed_epireset_annotated_newfilter.csv")
#+end_src
*** Step6': Subset Variants DF (dplyr)
#+begin_src R :session parse_variants :tangle ./Scripts/parse_variantsR
library(tidyverse)

variants <- read_csv('./Variant_Calling/parsed_variants.csv') %>%
  mutate(Var_id = paste0('Variant_', X1)) %>%
  select(Var_id, everything(), -X1)

variants %>%
  filter(!complete.cases(.)) %>%
  print(width = 400)

variants %>%
  select(contains('depth')) %>%
  summary()


variants %>%
  filter(IMPACT == 'HIGH') %>%
  filter(depth_12B >= 20 & RefRatio_12B <= 0.2) %>%
  select(Var_id, contains('12B'), Gene, Annot) %>%
  print(width = 400)


parse_variants_bystrain <- function(strain, depth_filter, refratio_filter){
  depthcol <- paste0('depth_', strain)
  ratiocol <- paste0('RefRatio_', strain)
  outname <- paste0('./Variant_Calling/Parsed_by_Strain/',
                    strain,
                    '_variants_depth_', depth_filter,
                    '_refratio_', refratio_filter,
                    '.csv')

  variants %>%
    filter(IMPACT == 'HIGH') %>%
    filter(get(depthcol) >= depth_filter &
           get(ratiocol) <= refratio_filter) %>%
    select(Var_id, contains(strain), Gene, Annot, Consequence, Chrom, Pos, Ref, Alt) %>%
    write_csv(outname)
}

depth_filter <- 20
refratio_filter <- 0.2

strains <- c('12B', '10G', 'A7', 'E5', 'B11')
for (strain in strains){parse_variants_bystrain(strain, depth_filter, refratio_filter)}



#+end_src

* Microarray Data
** 1.2B, 10G and 3D7B (Old_Arrays)
:PROPERTIES:
:header-args:R: :session old_arrays :tangle ./Scripts/microarray_analysis_12B_10G_3D7B_variantome.R :results none
:END:
*** Import libraries
#+begin_src R
#### Import libraries ####

print("Importing Libraries...")
list.of.packages <- c("reshape2", "ggfortify", "tidyverse", "RColorBrewer", "sp")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

library(reshape2)
library(ggfortify)
library(tidyverse)
library(RColorBrewer)
library(sp)
library(readxl)

if (!("Biobase" %in% installed.packages()[,"Package"])){
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install()
}

library(Biobase)
#+end_src
*** Experimental Setup (modifiable part)
#+begin_src R
#### Experiment Setup: MODIFY THIS PART #################################
##*********************************************************************##
##*********************************************************************##

wd <- ('/mnt/Disc4T/Projects/PhD_Project/Microarrays/New_Old_separate_approach/Old_Arrays/')
setwd(wd)
datadir <- "./Variantome_Original/"
outdir <- "./R_results_OldArrays_Variantome/"
annot <- read.csv("./Files/array_anotation.csv", sep="\t", header = F)
infiles <- "./Files/"

sample_names <- c('12B_tp10', '12B_tp20', '12B_tp30', '12B_tp34', '12B_tp37', '12B_tp40', '12B_tp43',
                  '10G_tp10', '10G_tp20', '10G_tp30', '10G_tp34', '10G_tp37', '10G_tp40', '10G_tp43',
                  '3D7B_tp10', '3D7B_tp20', '3D7B_tp30', '3D7B_tp34', '3D7B_tp37', '3D7B_tp40', '3D7B_tp43')

nsamples <- length(sample_names)

times <- as.integer(sub("^.+_tp", "", sample_names))
types <- sub("_tp.+", "", sample_names)


## Load Annotation
print("Loading Array Annotation...")
gene_list <- readLines(paste0(infiles, "gene_list.txt"))
annot_df <- read_csv(paste0(infiles, 'info_df.csv')) %>%
  select(Gene_id, Name, Variant, Annot) %>%
  dplyr::filter(!is.na(Gene_id))

## Add Annotation
gene_rosetta <- read_tsv(paste0(infiles, 'gene_ids_rosetta.txt'), col_names = F)
colnames(gene_rosetta) <- c('Old_id', 'Gene_id')

## Set to NA rows with double ID (to be changed)

blasted <- read_csv('./Blast_Old_Primers/blasted_oligos.csv')
blasted <- blasted %>%
  mutate(Old_id = gsub('a(.*)_[0-9]', '\\1', blasted$Oligo_id))

unique_hit <- blasted %>%
  filter(Score >= 70 & Score_2 <= 70 ) %>%
  select(Old_id, Gene_id) %>%
  group_by(Old_id) %>%
  summarize(N_hits = n_distinct(Gene_id)) %>%
  filter(N_hits == 1) %>%
  select(Old_id) %>% pull()

unique_oligos <- blasted %>%
  filter(Old_id %in% unique_hit) %>%
  select(Old_id, Gene_id) %>%
  distinct()

gene_rosetta[gene_rosetta$Old_id %in% unique_oligos$Old_id,]$Gene_id <- unique_oligos$Gene_id

double_new_ids <- gene_rosetta %>%
  filter(grepl(',', Gene_id))

write_csv(double_new_ids, './genes_with_double_GeneID.csv')

gene_rosetta <- gene_rosetta %>%
  mutate(Gene_id = replace(Gene_id, grepl(',', Gene_id), NA))

## Load Gene-Level data

gene_level <- read_csv('./Variantome_Original/normalizedData_geneLevel.csv')
gene_level_noratio <- read_csv('./Variantome_Original/normalizedData_geneLevel_noRatio.csv')

gene_level <- gene_level %>%
  select(-contains('X3d7a'), -contains('w41')) %>%
  rename(Old_id = geneID, Old_name = Name) %>%
  left_join(gene_rosetta, by='Old_id') %>%
  left_join(annot_df, by='Gene_id') %>%
  filter(!is.na(Gene_id))

gene_level_noratio <- gene_level_noratio %>%
  select(-contains('X3d7a'), -contains('w41')) %>%
  rename(Old_id = geneID, Old_name = Name) %>%
  left_join(gene_rosetta, by='Old_id') %>%
  left_join(annot_df, by='Gene_id')

#write_csv(gene_level, 'gene_level_raw_table.csv')

## Summarize genes with duplicated new IDs

collapse_ids <- function(df) {
  non_num <- df %>%
    select(Gene_id, Name, Variant, Annot) %>%
    distinct()
  #print(dim(non_num))

  num <- df %>%
    select(Gene_id, contains('X')) %>%
    group_by(Gene_id) %>%
    summarise_each(funs(mean))

  #print(dim(num))
  df <- num %>%
    left_join(non_num, by = 'Gene_id') %>%
    filter(!is.na(Gene_id))


  return(df)
}

# y <- gene_level %>% select(-contains('X')) %>% distinct()
gene_level %>% group_by(Gene_id) %>% filter(n() > 1) %>%
  select(Gene_id, Name, Annot)

gene_level <- collapse_ids(gene_level)
gene_level_noratio <- collapse_ids(gene_level_noratio)

## Load Areas
areasDF <- read_csv('Variantome_Original/areas_subclons.csv')
areasDF <- areasDF %>%
  select(-contains('X3d7a'), -contains('w41')) %>%
  rename(Old_id = ...1, Old_name = Name) %>%
  left_join(gene_rosetta, by='Old_id') %>%
  filter(!is.na(Gene_id)) %>%
  select(Gene_id, contains('left'), contains('right'), contains('mid'), contains('sides'), -Old_id, -Old_name) %>%
  select(Gene_id, contains('1.2b'), contains('10g'), contains('3d7b')) %>%
  group_by(Gene_id) %>% filter(n() == 1) %>% ungroup()

colnames(areasDF) <- c("Gene_id",
                       "12B_Left", "12B_Right", "12B_Middle", "12B_Sides",
                       "10G_Left", "10G_Right", "10G_Middle", "10G_Sides",
                       "3D7B_Left","3D7B_Right", "3D7B_Middle", "3D7B_Sides")

areasDF <- as.data.frame(areasDF)
rownames(areasDF) <- areasDF$Gene_id
areasDF <-areasDF %>% select(-Gene_id)


##*********************************************************************##
##********************* END OF MODIFIABLE PART ************************##
##*********************************************************************##
#+end_src
*** Create folders for output
#+begin_src R
#### Create folders for output ####

print("Creating folders for Output...")
dir.create(paste0(outdir))
dir.create(paste0(outdir, "/Plots"))
dir.create(paste0(outdir, "/Plots/Array_Plots"))
dir.create(paste0(outdir, "/Plots/MA_Plots"))
dir.create(paste0(outdir, "/Plots/Time_estim/"))
dir.create(paste0(outdir, "/Plots/Ratio"))
dir.create(paste0(outdir, "/Plots/Ratio/Gene_Level"))
dir.create(paste0(outdir, "/Plots/Ratio/Probe_Level"))
dir.create(paste0(outdir, "/Plots/Red_Signal"))
dir.create(paste0(outdir, "/Plots/Red_Signal/Gene_Level"))
dir.create(paste0(outdir, "/Plots/Red_Signal/Probe_Level"))
figPath <- paste0(outdir, "/Plots/")
#+end_src
*** Create Eset: xgene
#+begin_src R
#### Create Eset: xgene ####

exprsx <- as.matrix(gene_level %>% select(contains('X')))
colnames(exprsx) <- sample_names
rownames(exprsx) <- gene_level$Gene_id
fdata <- new("AnnotatedDataFrame", gene_level %>% select(Gene_id, Name, Variant, Annot))
rownames(fdata) <- gene_level$Gene_id
teor_time <- times
type <- types
pdata <- data.frame(type=type, teor_time=teor_time); rownames(pdata) <- sample_names
pdata <- new("AnnotatedDataFrame", pdata)
xgene <- new("ExpressionSet", exprs=exprsx, featureData=fdata, phenoData=pdata)
save(xgene, file=paste0(outdir, '/geneLevel.RData'))

exprsx <- as.matrix(gene_level_noratio %>% select(contains('X')) %>% select(contains('F635')))
rownames(exprsx) <- gene_level_noratio$Gene_id
colnames(exprsx) <- sample_names
xgene_red <- new("ExpressionSet", exprs=exprsx, featureData=fdata, phenoData=pdata)

write.csv(cbind(fdata@data, exprs(xgene)), paste0(outdir, "/geneLevel_exp.csv"), row.names=F)
write.csv(cbind(fdata@data, exprs(xgene_red)), paste0(outdir, "/geneLevel_redSignalexp.csv"), row.names=F)
#+end_src
*** Estimate times
#+begin_src R
#### Estimate times ####

ascendingTime <- function(x){
  current <- 0
  ncycle <- 0
  for (i in 1:length(x)){
    val  <- x[i]+(48*ncycle)
    if (val < current){
      current <- val
      val <- val+48
      ncycle <- ncycle+1
    }
    current <- val
    x[i] <- val
  }
  return(x)
}

estimatedTimes <- read_excel('Variantome_Original/Estimated_Times_3D7.xls')
estimatedTimes <- estimatedTimes %>%
  rename(Sample = `...1`, HPI = x) %>%
  filter(grepl('X1.2b', fixed = T, Sample) |
           grepl('X10g', fixed = T, Sample) |
           grepl('X3d7b', fixed = T, Sample)) %>%
  select(HPI) %>% pull()

#estimatedTimes <- getTimeEstimation(xgene,bozdechPath,LemieuxFunctionsPath,file.path(figPath),B=100)
estimatedTimes[estimatedTimes < 0] <- 0
hpi <- estimatedTimes

for (type in pData(xgene)$type){
  sel <- pData(xgene)$type == type
  typetime <- estimatedTimes[sel]
  time <- ascendingTime(typetime)
  estimatedTimes[sel] <- time
}

write.csv(estimatedTimes, paste0(outdir, "/Estimated_Times.csv"))
pData(xgene)$time <- estimatedTimes
pData(xgene_red)$time <- estimatedTimes
pData(xgene)$hpi <- hpi
pData(xgene_red)$hpi <- hpi
#+end_src
*** Areas functions
#+begin_src R
#### Areas: Functions ####

# imputePoint <- function(xs, ys, tp){
#
#   ## "xs" and "ys" must be two vectors of equal length
#   ## with the corresponding y(expression) and x(timepoint)
#   ## values that form the expression plot of interest (one gene).
#   ## "tp" must be the timepoint to impute.
#   ## If the timepoint to be imputed is already present, leave it as is.
#   ## Returns NA if missing the previous or next tp
#
#   if (tp %in% xs){
#
#     idx <- which(xs == tp)
#     imputed <- list(x=xs[idx], y=ys[idx])
#
#   } else {
#
#     before <- which(xs == max(xs[xs < tp]))
#     after <- which(xs == min(xs[xs > tp]))
#
#     if (is.na(ys[before]) | is.na(ys[after])){
#
#       imputed <- list(x=tp, y=NA)
#
#     } else {
#
#       x <- c(xs[c(before, after)])
#       y <- c(ys[c(before, after)])
#
#       imputed <- approx(x, y, xout=tp)
#     }
#   }
#   return(imputed)
# }
# computeArea <- function(eset){
#
#   ## Takes an eset and computes areas.
#   ## pData(eset) must contain a field named "time" with the time-points.
#   ## pData(eset) must have a field named "type" with the grouping variable.
#
#   ## Set needed variables
#   types <- unique(phenoData(eset)$type)
#   type <- phenoData(eset)$type
#   times <- phenoData(eset)$time
#
#   maxminTP <- max(sapply(types,function(x) min(times[type==x])))
#   minmaxTP <- min(sapply(types,function(x) max(times[type==x])))
#   mybreaks <- seq(maxminTP, minmaxTP, length.out=5)
#   tp1 <- mybreaks[2]
#   tp2 <- mybreaks[3]
#   tp3 <- mybreaks[4]
#
#   xsList <- c()
#   for (type in types){
#     xsList <- c(xsList, list(pData(eset)$time[phenoData(eset)$type == type]))
#   }
#
#   ## Main loop
#   all_areas <- c()
#   for (i in 1:dim(eset)[1]){
#
#     gene <- fData(eset)$geneID[i]
#
#     ysList <- c()
#     for (type in types){
#       ysList <- c(ysList, list(exprs(eset)[i, phenoData(eset)$type == type]))
#     }
#
#     ## Estimate points where needed
#     dfs <- list()
#     for (i in 1:length(xsList)){
#
#       x <- unlist(xsList[[i]])
#       y <- unlist(ysList[[i]])
#
#       points <- as.data.frame(cbind(x, y))
#       midpoints <- points[points$x > maxminTP &
#                             points$x < minmaxTP, ]
#
#       first <- imputePoint(x, y, maxminTP)
#       last <- imputePoint(x, y, minmaxTP)
#       p1 <- imputePoint(x, y, tp1)
#       p2 <- imputePoint(x, y, tp2)
#       p3 <- imputePoint(x, y, tp3)
#
#       impPoints <- rbind(first, last, p1, p2, p3)
#       allpoints <- rbind(midpoints, impPoints)
#       allpoints$x <- as.numeric(allpoints$x)
#       allpoints$y <- as.numeric(allpoints$y)
#
#       ordered <- arrange(allpoints, allpoints$x)
#
#       dfs[[i]] <- ordered
#     }
#
#     ## Calculate minY on estimated DFs
#     minY <- min(sapply(dfs, function(df) min(df$y, na.rm = T)))
#
#     rowareas <- c()
#     for (df in dfs){
#
#       df$y <- df$y - minY
#
#       ## Whole polygon from expression data
#       polDF <- rbind(df,
#                      c(minmaxTP, 0),
#                      c(maxminTP, 0),
#                      c(df[1,]))
#
#       ## Create Polygons
#       leftHalf <- rbind(df[which(df$x <= tp2),],
#                         c(tp2, 0),
#                         c(maxminTP, 0),
#                         c(df[1,]))
#
#       rightHalf <- rbind(df[which(df$x >= tp2),],
#                          c(minmaxTP, 0),
#                          c(tp2, 0),
#                          c(df[df$x == tp2,]))
#
#       mid <- rbind(df[which(df$x >= tp1 & df$x <= tp3),],
#                    c(tp3, 0),
#                    c(tp1, 0),
#                    c(df[df$x == tp1,]))
#
#       sides <- rbind(df[which(df$x <= tp1),],
#                      c(tp1, 0),
#                      c(tp3, 0),
#                      df[which(df$x >= tp3),],
#                      c(minmaxTP, 0),
#                      c(maxminTP, 0),
#                      df[1,])
#
#       pols <- list(leftHalf, rightHalf, mid, sides)
#
#       calcArea <- function(x) {ifelse(any(is.na(x)), NA, Polygon(x)@area)}
#       areas <- unlist(lapply(pols, function(x) calcArea(x)))
#
#       rowareas <- c(rowareas, areas)
#
#       ## Plot polygons (for debugging purposes)
#       ##pol <- Polygon(polDF)
#       ##ps = Polygons(list(pol),1)
#       ##sps = SpatialPolygons(list(ps))
#       ##plot(sps)
#     }
#     all_areas <- c(all_areas, list(rowareas))
#   }
#
#   ## Set row and col names for output
#   areaDF <- do.call(rbind, all_areas)
#   titles <- c("Left", "Right", "Middle", "Sides")
#
#   cols <- c()
#   for (i in types){
#     for (t in titles){
#       name <- paste0(i, "_", t)
#       cols <- c(cols, name)
#     }
#   }
#   colnames(areaDF)  <- cols
#   rownames(areaDF) <- rownames(exprs(eset))
#   return(areaDF)
# }


#+end_src
*** Calls: Compute areas
#+begin_src R
#### Calls: Compute Areas ####

print("Computing Areas...")
# areasDF <- computeArea(xgene)
# old_areasDF <- areasDF


head(areasDF)

areas_df <- as_tibble(areasDF)
areas_df['Gene_id'] <- rownames(areasDF)
areas_df <- areas_df %>%
  select(Gene_id, everything())

#xout <- cbind(fData(xgene), areasDF)
xout <- full_join(fData(xgene), areas_df)
write.csv(xout, paste0(outdir, "/area_geneLevel.csv"), row.names=F)

#+end_src
*** Calculate aAFC (Average Area Fold-Change)
#+begin_src R
#### Calculate aAFC (average Area Fold-Change) ####

myMax <- function(x){
  y <- abs(x)
  if (all(is.na(y))){
    return(list(NA, NA))
  } else {
    pos <- which.max(y)
    times <- c("Left", "Right", "Mid", "Sides")
    return(list(maxVal = x[pos],
                maxTime = times[pos]))
  }
}

## Get number of categories.
n <- length(levels(pData(xgene)$type))

ns <- list()
i <- 1
while (i < n+1){
  ns[[i]] <- 1:4+(4*(i-1))
  i <- i+1
}

## Convert de areasDF into a list of DFs separated by types.
areas <- list()
for (i in 1:length(ns)) {
  areas[[i]] <- areasDF[,ns[[i]]]
}


## Calculate area differences

types <- unique(phenoData(xgene)$type)
type <- phenoData(xgene)$type
times <- phenoData(xgene)$time

maxminTP <- max(sapply(types,function(x) min(times[type==x])))
minmaxTP <- min(sapply(types,function(x) max(times[type==x])))
mybreaks <- seq(maxminTP, minmaxTP, length.out=5)

sets <- 1:length(areas)
combs <- combn(sets, 2)
span <- mybreaks[3] - mybreaks[1]
titles <- c("Left", "Right", "Middle", "Sides")


areaDifs <- list()
for (i in 1:dim(combs)[2]){

  one <- combs[1,i]
  two <- combs[2,i]

  dif1 <- as.data.frame((areas[[one]] - areas[[two]])/span)
  names  <- paste0(colnames(areas[[one]]),
                   "_minus_",
                   colnames(areas[[two]]))

  prefix <- paste0(strsplit(colnames(areas[[one]])[1], "_")[[1]][1],
                   "-",
                   strsplit(colnames(areas[[two]])[1], "_")[[1]][1])
  names <- sapply(titles, function(x) paste(prefix, x, sep = "_"))

  colnames(dif1) <- names

  maxval <- apply(dif1, 1, function(x) myMax(x)[[1]])
  maxtime <- apply(dif1, 1, function(x) myMax(x)[[2]])

  mv <- paste0(prefix, "_MaxVal")
  mt <- paste0(prefix, "_MaxTime")

  dif1[mv] <- maxval
  dif1[mt] <- maxtime

  #dif2 <- -dif1

  ## prefix <- paste0(strsplit(colnames(areas[[two]])[1], "_")[[1]][1],
  ##                  "-",
  ##                  strsplit(colnames(areas[[one]])[1], "_")[[1]][1])
  ## names <- sapply(titles, function(x) paste(prefix, x, sep = "_"))

  ## colnames(dif2) <- names

  areaDifs <- c(areaDifs, list(dif1))#, list(dif2))
}

allDifs <- do.call(cbind, areaDifs)
head(allDifs)


#+end_src
*** Areas: Convert partitions into life-stages
#+begin_src R
#### Areas: Convert Partitions into life stages ####

timetostage <- function(tp){
  while(tp > 48){
    tp = tp-48
  }
  return(tp)
}

getStage <- function(tp) {
  if ((tp >= 0) & (tp < 26)) {stg = "ring"}
  else if ((tp >= 26) & (tp < 38)) {stg = "troph"}
  else if ((tp >= 38) & (tp <= 48)) {stg = "schizont"}
  return(stg)
}

fracToStage <- function(frac, tps){
  if (is.na(frac)){
    return(NA)
  } else if (frac == "Left"){
    tp = tps[2]
    getStage(tp)
  } else if (frac == "Right"){
    tp = tps[4]
    getStage(tp)
  } else if (frac == "Mid"){
    tp = tps[3]
    getStage(tp)
  } else if (frac == "Sides"){
    tp1 = tps[1]+(span/4)
    tp2 = tps[4]+(span/4)
    stg1 <- getStage(tp1)
    stg2 <- getStage(tp2)
    return(paste0(stg1,"-",stg2))
  }
}


ncombs <- dim(combs)[2]

maxValCols <- seq(5, ncombs*6, 6)
maxTimeCols <- seq(6, ncombs*6, 6)

aMAFC <- cbind(allDifs[,c(maxValCols, maxTimeCols)])

timeCols <- (ncombs+1):(ncombs*2)

tps <- sapply(mybreaks, function(x) timetostage(x))

for (i in timeCols){
  aMAFC[,i] <- sapply(aMAFC[,i], function(x) fracToStage(x, tps))
}

write.csv(allDifs, paste0(outdir, "/areaDiferences_geneLevel.csv"))
write.csv(aMAFC, paste0(outdir, "/aMAFC_geneLevel.csv"))
#+end_src
*** Create Max Differences table
#+begin_src R
#### Create Max differences table ####

anot_table <- annot %>%
  select(V2, V4, V5) %>%
  rename(Gene_id=V2, Name=V4, Annot=V5) %>%
  dplyr::filter(!is.na(Gene_id)) %>%
  distinct()

head(anot_table)
head(allDifs)

max_df <- allDifs %>%
  mutate(Gene_id = rownames(allDifs)) %>%
  left_join(anot_table, by='Gene_id') %>%
  mutate(MaxMax = pmax(abs(`12B-10G_MaxVal`), abs(`12B-3D7B_MaxVal`), abs(`10G-3D7B_MaxVal`))) %>%
  arrange(desc(abs(MaxMax))) %>%
  select(Gene_id, Name, Annot, contains('MaxVal'), contains('MaxTime'), contains('-'))

max_df_top <- max_df %>% dplyr::filter(abs(`12B-10G_MaxVal`) > 4 | abs(`12B-3D7B_MaxVal`) > 4 | abs(`10G-3D7B_MaxVal`) > 4)

write.csv(max_df, paste0(outdir, "/all_aMAFC.csv"))
write.csv(max_df_top, paste0(outdir, "/top_aMAFC.csv"))
#+end_src
*** PCA Plots
#+begin_src R
#### PCA Plots ####

print("Plotting PCA..")
noNA <- xgene[complete.cases(exprs(xgene))]
df <- t(exprs(noNA))
df <- as.data.frame(df)

pca <- prcomp(df)
cmp1 <- format(round(summary(pca)$importance[2,1]*100, 2), nsmall = 2)
cmp2 <- format(round(summary(pca)$importance[2,2]*100, 2), nsmall = 2)

df_pca <- as.data.frame(pca$x)
df_pca$Type <- noNA@phenoData@data$type
df_pca$Time <- noNA@phenoData@data$time

p <- ggplot(df_pca, aes(x=PC1,y=PC2, col = Type, group = Type))
p <- p + geom_point(aes(size= Time))
p <- p + geom_path()
p <- p + scale_x_continuous(name=paste0("PC1: ", cmp1, "%"))
p <- p + scale_y_continuous(name=paste0("PC2: ", cmp2, "%"))

p <- p + theme_classic()
p <- p + theme(text = element_text(size=20))
p

ggsave(p, filename = paste0(figPath, "PCA.svg"), device = "svg")
#+end_src
*** Add Gametocyte genes info
#+begin_src R
#### Add gametocyte genes info ####
library(readxl)
gene_lists <- read_excel('../All gene lists_160719.xlsx', sheet = 2)

gam_genes <- gene_lists %>%
  select(`Lopez-Barragan`, Lasonder, Gametocites_Young, contains('gam'))

gam_list <- unique(gam_genes %>% pull())
gam_list[gam_list == 'NA'] <- NA
gam_list <- gam_list[!is.na(gam_list)]

finalDF <- max_df %>%
  select(Gene_id, Name, Annot, contains('MaxVal'), contains('MaxTime'))

finalDF['GamGene'] <- finalDF$Gene_id %in% gam_list

write.csv(finalDF, paste0(outdir, "/final_summary_table.csv"), row.names = F)


fData(xgene)

tibble(finalDF) %>%
  left_join(fData(xgene) %>% select(Gene_id, Variant), by = 'Gene_id') %>%
  filter(abs(`12B-10G_MaxVal`) > 1 |
         abs(`12B-3D7B_MaxVal`) > 1 |
         abs(`10G-3D7B_MaxVal`) > 1) %>%
  filter(is.na(Variant))


#+end_src
*** VAR genes plot
#+begin_src R
#### Var genes plot ####

gene_fam <- read_excel('/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/cvgfamilylist/Supplementary_table_2_CVG_list_161120_ap.xlsx', sheet = 2)
gene_fam <- gene_fam %>%
  rename(Gene_id = `Gene ID`,
         Gene_name = `Gene Name or Symbol`,
         SubFamily = `Family Detail`) %>%
  # mutate(SubFamily = case_when(SubFamily == 'var pseudo,truncated or -like.' ~ 'var-like',
  #                              TRUE ~ SubFamily)) %>%
  select(Gene_id, Gene_name, Family, SubFamily)

red_df <- as.data.frame(exprs(xgene_red))
red_df <- red_df %>%
  mutate(Gene_id = rownames(red_df)) %>%
  left_join(gene_fam, by='Gene_id')

varPlot <- function(strain){
  plot_df <- red_df %>%
    mutate(Max = select(., contains(strain)) %>% do.call(pmax, .)) %>%
    select(Gene_id, Max, Family, SubFamily) %>%
    dplyr::filter(Family == 'VAR' & SubFamily != 'var pseudo,truncated or -like.')

  vars_plot <- ggplot(plot_df, aes(x = Gene_id, y = Max)) +
    geom_bar(stat = 'identity') +
    ggtitle(paste0('VAR gene expression ', strain)) +
    ylab(paste0('Max(across timepoints) Red Chanel Signal')) +
    theme_classic() +
    theme(axis.text.x=element_text(angle = -90, hjust = 0))
    ,#+ coord_cartesian(ylim = c(0,2000))

  print(vars_plot)

  ggsave(paste0(figPath, strain, '_var_genes_red.pdf'), vars_plot, device = 'pdf')
}

strains <- c('12B', '10G', '3D7B')
for (strain in strains) {varPlot(strain)}
#+end_src
*** Single Gene Plot
#+begin_src R
#### Single Gene Plot ####
plot_gene <- function(type, gid, out){
  ## Set df and lims depending on what we are plotting.
  if (type == "gene"){
    df = xgene
    path = "/Ratio/Gene_Level/"

  } else if (type == "gene_red"){
    df = xgene_red
    path = "/Red_Signal/Gene_Level/"

  } else if (type == "probe"){
    df = xprobe
    path = "/Ratio/Probe_Level/"

  } else if (type == "probe_red"){
    df = xprobe_red
    path = "/Red_Signal/Probe_Level/"

  }

  ## Set ylims
  ylim = c(min(exprs(df), na.rm = T), max(exprs(df), na.rm = T))


  ## Plot
  ## Set gene for title or gene and probe for probe-level plots.
  gn <- gsub("[/:;.]", "_", gid)
  if (type %in% c("probe", "probe_red")){
    prb <- paste0("_", gsub("[/:;.]", "_" , gid))
  } else {
    prb <- ""
  }
  title <- paste0(gn, prb)

  ## Set y-axis title depending on ratio/red_signal
  ytitle <- ifelse(type %in% c("gene_red", "probe_red"), 'log2(Cy5)', 'log2(Cy3/Cy5)')

  ## Plot
  graf <- melt(df[fData(df)$Gene_id == gid,])
  graf["Type"] <- xgene@phenoData@data$type
  graf["Time"] <- xgene@phenoData@data$time
  p <- ggplot(graf, aes(x = Time, y = value, col = Type, group = Type))
  p <- p + geom_point(aes(color = Type, size = 2))
  p <- p + geom_line(aes(size = 2))
  p <- p + coord_cartesian(ylim = ylim)
  p <- p + theme_classic()
  # p <- p + ggtitle(title)
  # p <- p + ylab(ytitle)
  p <- p + theme(text = element_text(size = 36))
  p <- p + theme(axis.title.x = element_blank())
  p <- p + theme(axis.title.y = element_blank())
  p <- p + theme(legend.position = 'none')
  ggsave(p, file=out, device = "svg")
  print(p)
}

type <- 'gene'
gid <- 'PF3D7_0302200'
outpath <- '/home/lucas/Documents/BioMalPar_2021/Microarrays/Gene_plots/'
outname <- 'PF3D7_0302200_12b10g.svg'

plot_gene(type, gid, paste0(outpath, outname))

#+end_src
*** Filter aFCs
**** Red Filter
#+begin_src R
xgene_red_tibble <- as.data.frame(exprs(xgene_red)) %>%
  tibble() %>%
  mutate(Gene_id = rownames(exprs(xgene_red))) %>%
  select(Gene_id, everything())


## First get maxcol then percentile (OLD)
## get_red_percent <- function(strain){

##   ## Subset to strain
##   red_strain <- xgene_red_tibble %>%
##     select(Gene_id, contains(strain))

##   ## Calculate Max col
##   maxred <- red_strain %>%
##     dplyr::select(-Gene_id) %>%
##     mutate(Max_Red = do.call(pmax, (.))) %>%
##     select(Max_Red)

##   ## Create "percentile" function from Max col
##   percentile <- ecdf(maxred$Max_Red)
##   red_pcnt <- percentile(maxred$Max_Red)

##   return(red_pcnt)
## }

## perc_12B <- get_red_percent('12B')
## perc_10G <- get_red_percent('10G')

## red_percent <- tibble('Gene_id' = xgene_red_tibble$Gene_id,
##                       '12B' = perc_12B,
##                       '10G' = perc_10G)


## First percentile per col -> max percentile (NEW)

my_percentile <- function(vector){
  ecdf(vector)(vector)*100
}

xgene_red_tibble <- xgene_red_tibble %>%
  mutate(across(.cols = -Gene_id, .fns = my_percentile, .names = "Perc_{.col}"))

get_max_percent <- function(strain){

  ## Subset to strain
  red_strain <- xgene_red_tibble %>%
    select(Gene_id, contains('Perc') & contains(strain))

  ## Calculate Max col
  maxperc <- red_strain %>%
    dplyr::select(-Gene_id) %>%
    mutate(Max_Perc = do.call(pmax, c(., na.rm = T))) %>%
    select(Max_Perc) %>%
    pull()
  return(maxperc)
}

perc_12B <- get_max_percent('12B')
perc_10G <- get_max_percent('10G')
perc_3D7B <- get_max_percent('3D7B')

red_percent <- tibble('Gene_id' = xgene_red_tibble$Gene_id,
                      '12B' = perc_12B,
                      '10G' = perc_10G,
                      '3D7B' = perc_3D7B)

##hist(red_percent$`12B`)

write_csv(red_percent, paste0(outdir, "/red_percentiles.csv"))
names(red_percent)[2:4] <- paste0('Red_Pcnt_', names(red_percent)[2:4])

max_tibble <- as_tibble(max_df)
max_tibble <- max_tibble %>%
  left_join(red_percent, by='Gene_id', suffix = c('', '_Pcnt'))

maxFC_passe_red <- max_tibble %>%
  filter((`12B-10G_MaxVal` >= 2 & Red_Pcnt_12B > 15) |
         (`12B-10G_MaxVal` <= -2 & Red_Pcnt_10G > 15) |
         (`12B-3D7B_MaxVal` >= 2 & Red_Pcnt_12B > 15) |
         (`12B-3D7B_MaxVal` <= -2 & Red_Pcnt_3D7B > 15) |
         (`10G-3D7B_MaxVal` >= 2 & Red_Pcnt_10G > 15) |
         (`10G-3D7B_MaxVal` <= -2 & Red_Pcnt_3D7B > 15))

#+end_src
**** Get Max-Time for each gene
#+begin_src R
#### Get MaxTime for each gene ####

myWhichMax <- function(vect){
  if (all(is.na(vect))){
    return(NA)
  } else {
    return(which.max(vect))
  }
}

exp <- as.data.frame(exprs(xgene))


maxcol <- exp %>%
  apply(1, myWhichMax) %>%
  unlist()

times <- pData(xgene) %>%
  select(time) %>%
  pull()

maxtime <- sapply(maxcol, function(x) times[x])
head(maxtime)

max_time <- tibble(Gene_id = names(maxtime), Max_Time = maxtime)
breaks_df <- tibble(Areas_Breaks = mybreaks)

tibble(Gene_id = names(maxtime), Max_Time = maxtime) %>%
  write_csv(paste0(outdir, 'old_arrays_maxtime.csv'))

tibble(Areas_Breaks = mybreaks) %>%
  write_csv(paste0(outdir, 'old_area_breaks.csv'))
#+end_src
**** Filter Genes by timepoint
#+begin_src R
## #### Filter by Max-Time ####

## New approach
## Check which areas does maxtimepoint overlapp -> check if aAFC > th at this areas

point_overlap <- function(point, interval){
  point >= interval[1] & point <= interval[2]
}

areas_df <- as_tibble(allDifs) %>%
  mutate(Gene_id = rownames(allDifs)) %>%
  select(Gene_id, everything())

maxtimes_12B_10G <- c()
maxtimes_12B_3D7B <- c()
maxtimes_10G_3D7B <- c()
gids <- c()
th <- 2
for (gid in max_tibble$Gene_id){

  #gid <- 'PF3D7_0324600'
  ## Create time-regions
  breaks <- breaks_df$Areas_Breaks
  left <- c(breaks[1], breaks[3])
  right <- c(breaks[3], breaks[5])
  mid <- c(breaks[2], breaks[4])
  sides_l <- c(breaks[1], breaks[2])
  sides_r <- c(breaks[4], breaks[5])

  ## Get maxtime
  maxtime <- max_time %>%
    filter(Gene_id == gid) %>%
    pull()
  if (is.na(maxtime)){
    maxtimes_12B_10G <- c(maxtimes_12B_10G, NA)
    maxtimes_12B_3D7B <- c(maxtimes_12B_3D7B, NA)
    maxtimes_10G_3D7B <- c(maxtimes_10G_3D7B, NA)
    gids <- c(gids, gid)
  } else {
    ## Ensure maxtime is in the areas intervals
    if (maxtime < breaks[1]) {maxtime <- breaks[1]}
    if (maxtime > breaks[5]) {maxtime <- breaks[5]}

    ## Get overlappped areas
    areas <- list('left' = left, 'right' = right, 'mid' = mid,
                  'sides' = sides_l, 'sides' = sides_r)
    overlaps <- sapply(areas, function(x) point_overlap(maxtime, x))

    ## Get aAFC in overlapping areas by comparison
    aFCs <- areas_df %>%
      filter(Gene_id == gid) %>%
      select(contains(names(areas[overlaps])))

    fc_12B_10G <- aFCs %>%
      select(contains('12B-10G')) %>%
      replace(is.na(.), 0) %>%
      as.numeric()
    maxtime_FC_12B_10G <- any(abs(fc_12B_10G) > th)

    fc_12B_3D7B <- aFCs %>%
      select(contains('12B-3D7B')) %>%
      replace(is.na(.), 0) %>%
      as.numeric()
    maxtime_FC_12B_3D7B <- any(abs(fc_12B_3D7B) > th)

    fc_10G_3D7B <- aFCs %>%
      select(contains('10G-3D7B')) %>%
      replace(is.na(.), 0) %>%
      as.numeric()
    maxtime_FC_10G_3D7B <- any(abs(fc_10G_3D7B) > th)

    maxtimes_12B_10G <- c(maxtimes_12B_10G, maxtime_FC_12B_10G)
    maxtimes_12B_3D7B <- c(maxtimes_12B_3D7B, maxtime_FC_12B_3D7B)
    maxtimes_10G_3D7B <- c(maxtimes_10G_3D7B, maxtime_FC_10G_3D7B)
    gids <- c(gids, gid)
  }
}
maxtime_aAFC_df <- tibble(
  Gene_id = gids,
  MaxTime_Filter_12B_10G = maxtimes_12B_10G,
  MaxTime_Filter_12B_3D7B = maxtimes_12B_3D7B,
  MaxTime_Filter_10G_3D7B = maxtimes_10G_3D7B
  )

maxtime_aAFC_df %>%
  count(MaxTime_Filter_12B_10G)

max_tibble <- max_tibble %>%
  left_join(maxtime_aAFC_df)


## final_llcm['MaxTime'] <- maxtime
## final_ll0['MaxTime'] <- maxtime
## final_lls['MaxTime'] <- maxtime

## tibble(finalDF)[,1:4]

## trans_df <- tibble(allDifs) %>%
##   mutate(Gene_id = rownames(allDifs)) %>%
##   select(Gene_id, everything())

## trans_df


## ## Define intervals
## left <- c(mybreaks[1], mybreaks[2])
## right <- c(mybreaks[3], mybreaks[5])
## mid <- c(mybreaks[2], mybreaks[4])
## sides1 <- c(mybreaks[1], mybreaks[2])
## sides2 <- c(mybreaks[4], mybreaks[5])

## checkOverap <- function(v1, v2){
##   v1[1] <= v2[2] & v2[1] <= v1[2]
## }

## getInterval <- function(x, width){
##   ## Will break if interval spans > 48h ("circular interval")
##   x_low <- ifelse(x-width >= mybreaks[1], x-width, mybreaks[1])
##   x_high <- ifelse(x+width <= mybreaks[5], x+width, mybreaks[5])
##   max_interval <- c(x_low, x_high)
##   return(max_interval)
## }

## ## Set width arround maxtime
## width <- 10

## ## Check wether each interval overlaps with MaxTime
## trans_df['Left_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), left))

## final_llcm['Left_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), left))
## final_llcm['Right_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), right))
## final_llcm['Mid_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), mid))
## final_llcm['Sides_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), sides1) | checkOverap(getInterval(x, width), sides2))

## final_ll0['Left_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), left))
## final_ll0['Right_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), right))
## final_ll0['Mid_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), mid))
## final_ll0['Sides_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), sides1) | checkOverap(getInterval(x, width), sides2))

## final_lls['Left_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), left))
## final_lls['Right_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), right))
## final_lls['Mid_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), mid))
## final_lls['Sides_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), sides1) | checkOverap(getInterval(x, width), sides2))

## head(final_llcm)

## ## Check wether max falls in MaxTime (contrast by contrast)
## final_llcm <- final_llcm %>%
##   mutate(Max_in_MaxTime = case_when(MaxFC_Interval == "left" & Left_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "right" & Right_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "mid" & Mid_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "sides" & Sides_in_MaxTime ~ TRUE,
##                                     TRUE ~ FALSE))

## final_ll0 <- final_ll0 %>%
##   mutate(Max_in_MaxTime = case_when(MaxFC_Interval == "left" & Left_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "right" & Right_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "mid" & Mid_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "sides" & Sides_in_MaxTime ~ TRUE,
##                                     TRUE ~ FALSE))

## final_lls <- final_lls %>%
##   mutate(Max_in_MaxTime = case_when(MaxFC_Interval == "left" & Left_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "right" & Right_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "mid" & Mid_in_MaxTime ~ TRUE,
##                                     MaxFC_Interval == "sides" & Sides_in_MaxTime ~ TRUE,
##                                     TRUE ~ FALSE))
#+end_src
**** Filter Genes by Deletions/Duplications
#+begin_src R
## f_path <- '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/Duplication_Deletion_Regions/Crossed_with_genes/'
## file_list <- c(
##   "12B_minus_10G_100bp_500smth_RPKM_cov_norm_pdf_0999999_minlen500_genes.tsv",
##   "12B_minus_3D7_100bp_500smth_RPKM_cov_norm_pdf_0999999_minlen500_genes.tsv",
##   "10G_minus_3D7_100bp_500smth_RPKM_cov_norm_pdf_0999999_minlen500_genes.tsv"
## )

## dupl_dl_12B_10G <- read_tsv(paste0(f_path, file_list[1]), col_names = F) %>%
##   select(X1) %>% pull()

## dupl_dl_12B_3D7B <- read_tsv(paste0(f_path, file_list[2]), col_names = F) %>%
##   select(X1) %>% pull()

## dupl_dl_10G_3D7B <- read_tsv(paste0(f_path, file_list[3]), col_names = F) %>%
##   select(X1) %>% pull()

f_path <- '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/Duplication_Deletion_Regions_Mean/Crossed_with_genes/'

file_list <- c(
  "1.2B_in_sort_q5_RPKMs_bymean_fact_1.75_0.1_minlen500_mergelen_200_filtered_genes.tsv",
  "10G_in_sort_q5_RPKMs_bymean_fact_1.75_0.1_minlen500_mergelen_200_filtered_genes.tsv"
)

dupl_dl_12B <- read_tsv(paste0(f_path, file_list[1]), col_names = F) %>%
  select(X1) %>% pull()

dupl_dl_10G <- read_tsv(paste0(f_path, file_list[2]), col_names = F) %>%
  select(X1) %>% pull()


#+end_src
*** Get Final List of Genes
#+begin_src R
## Load Latest Annot
info_df <- read_csv(paste0(infiles, 'info_df.csv')) %>%
  dplyr::filter(!is.na(Gene_id))

final_df <- max_tibble %>%
  mutate(Gene_id = ifelse(Gene_id == 'PF3D7_0935400_as', 'PF3D7_0935390', Gene_id)) %>%
  mutate(Not_Plasmodium = !Gene_id %in% info_df$Gene_id)

final_df <- final_df %>%
  select(-Name, -Annot) %>%
  left_join(info_df, by='Gene_id')

colnames(final_df)

all_df <- final_df %>%
  select(
    Gene_id,
    contains('MaxVal'),
    contains('MaxTime'),
    contains('Red'),
    contains('Filter'),
  )

## Set thresholds
red_th <- 15

## 12B vs 10G

final_df %>%
  select(
    Gene_id,
    `12B-10G_MaxVal`,
    `12B-10G_MaxTime`,
    Red_Pcnt_12B,
    Red_Pcnt_10G,
    MaxTime_Filter_12B_10G
  ) %>%
  mutate(PassRed = ifelse(
           `12B-10G_MaxVal` >= 0,
           Red_Pcnt_12B >= red_th,
           Red_Pcnt_10G >= red_th
         )) %>%
  rename(PassMaxtime = MaxTime_Filter_12B_10G) %>%
  mutate(PassDuplDel = !Gene_id %in% dupl_dl_12B & !Gene_id %in% dupl_dl_10G) %>%
  rowwise() %>%
  mutate(PassAll = all(c(PassRed, PassMaxtime, PassDuplDel))) %>%
  write_tsv(paste0(outdir, '12B_10G_final_df.tsv'))

## 12B vs 3D7B

final_df %>%
  select(
    Gene_id,
    `12B-3D7B_MaxVal`,
    `12B-3D7B_MaxTime`,
    Red_Pcnt_12B,
    Red_Pcnt_3D7B,
    MaxTime_Filter_12B_3D7B
  ) %>%
  mutate(PassRed = ifelse(
           `12B-3D7B_MaxVal` >= 0,
           Red_Pcnt_12B >= red_th,
           Red_Pcnt_3D7B >= red_th
         )) %>%
  rename(PassMaxtime = MaxTime_Filter_12B_3D7B) %>%
  mutate(PassDuplDel = !Gene_id %in% dupl_dl_12B) %>%
  rowwise() %>%
  mutate(PassAll = all(c(PassRed, PassMaxtime, PassDuplDel))) %>%
  write_tsv(paste0(outdir, '12B_3D7B_final_df.tsv'))

## 10G vs 3D7B

final_df %>%
  select(
    Gene_id,
    `10G-3D7B_MaxVal`,
    `10G-3D7B_MaxTime`,
    Red_Pcnt_10G,
    Red_Pcnt_3D7B,
    MaxTime_Filter_10G_3D7B
  ) %>%
  mutate(PassRed = ifelse(
           `10G-3D7B_MaxVal` >= 0,
           Red_Pcnt_10G >= red_th,
           Red_Pcnt_3D7B >= red_th
         )) %>%
  rename(PassMaxtime = MaxTime_Filter_10G_3D7B) %>%
  mutate(PassDuplDel = !Gene_id %in% dupl_dl_10G) %>%
  rowwise() %>%
  mutate(PassAll = all(c(PassRed, PassMaxtime, PassDuplDel))) %>%
  write_tsv(paste0(outdir, '10G_3D7B_final_df.tsv'))


###################################################3


maxFC_pass_red <- final_df %>%
  filter((`12B-10G_MaxVal` >= 2 & Red_Pcnt_12B > 15) |
         (`12B-10G_MaxVal` <= -2 & Red_Pcnt_10G > 15) |
         (`12B-3D7B_MaxVal` >= 2 & Red_Pcnt_12B > 15) |
         (`12B-3D7B_MaxVal` <= -2 & Red_Pcnt_3D7B > 15) |
         (`10G-3D7B_MaxVal` >= 2 & Red_Pcnt_10G > 15) |
         (`10G-3D7B_MaxVal` <= -2 & Red_Pcnt_3D7B > 15))

## 12B vs 10G

difs_12B_10G <- final_df %>%
  filter(
  ((`12B-10G_MaxVal` >= 2 & Red_Pcnt_12B > 15) |
   (`12B-10G_MaxVal` <= -2 & Red_Pcnt_10G > 15)) &
  MaxTime_Filter_12B_10G
  ) %>%
  mutate(Dupl_Del = Gene_id %in% dupl_dl_12B | Gene_id %in% dupl_dl_10G) %>%
    dplyr::filter(!Not_Plasmodium & !Is_tRNA) %>%
  select(Gene_id, Name, Annot,
         `12B-10G_MaxVal`,
         Red_Pcnt_12B, Red_Pcnt_10G,
         MaxTime_Filter_12B_10G,
         Variant, Gam_specific, Dupl_Del)

write_csv(difs_12B_10G, paste0(outdir, '12B_vs_10G_log2FC2_red15_maxtime.csv'))


## 12B vs 3D7B

difs_12B_3D7B <- final_df %>%
  filter(
  ((`12B-3D7B_MaxVal` >= 2 & Red_Pcnt_12B > 15) |
   (`12B-3D7B_MaxVal` <= -2 & Red_Pcnt_3D7B > 15)) &
  MaxTime_Filter_12B_3D7B
  ) %>%
  mutate(Dupl_Del = Gene_id %in% dupl_dl_12B) %>%
  select(Gene_id, Name, Annot,
         `12B-3D7B_MaxVal`,
         Red_Pcnt_12B, Red_Pcnt_3D7B,
         MaxTime_Filter_12B_3D7B,
         Variant, Gam_specific, Dupl_Del)

write_csv(difs_12B_3D7B, paste0(outdir, '12B_vs_3D7B_log2FC2_red15_maxtime.csv'))


## 10G vs 3D7B

difs_10G_3D7B <- final_df %>%
  filter(
  ((`10G-3D7B_MaxVal` >= 2 & Red_Pcnt_10G > 15) |
   (`10G-3D7B_MaxVal` <= -2 & Red_Pcnt_3D7B > 15)) &
  MaxTime_Filter_10G_3D7B
  ) %>%
  mutate(Dupl_Del = Gene_id %in% dupl_dl_10G) %>%
  select(Gene_id, Name, Annot,
         `10G-3D7B_MaxVal`,
         Red_Pcnt_10G, Red_Pcnt_3D7B,
         MaxTime_Filter_10G_3D7B,
         Variant, Gam_specific, Dupl_Del)


write_csv(difs_10G_3D7B, paste0(outdir, '10G_vs_3D7B_log2FC2_red15_maxtime.csv'))

write_csv(final_df, paste0(outdir, 'old_arrays_final_df.csv'))

#+end_src
*** Make Venn Diagram
#+begin_src R
library(eulerr)

A <- difs_12B_10G$Gene_id
B <- difs_12B_3D7B$Gene_id
C <- difs_10G_3D7B$Gene_id

AB <- intersect(A, B)
AC <- intersect(A, C)
BC <- intersect(B, C)

ABC <- intersect(AB, C)

abc <- length(ABC)
ab <- length(AB[!AB %in% ABC])
ac <- length(AC[!AC %in% ABC])
bc <- length(BC[!BC %in% ABC])

a <- length(A) -ab -ac -abc
b <- length(B) -ab -bc -abc
c <- length(C) -ac -bc -abc

fit <- euler(c(A=a, B=b, C=c, "A&B"=ab, "A&C"=ac, "B&C"=bc, "A&B&C" = abc))

scales::viridis_pal()(3)

d <- plot(fit, fills = list(fill = c('#440154FF', "#21908CFF", "#FDE725FF"), alpha = 0.5),
          edges = list(lwd = 0.1),
          quantities = list(quantities = T),
          labels = list(labels=c("1.2B vs 10G", "1.2B vs 3D7B", "10G vs 3D7B")))

ggsave(d, filename = paste0(figPath, "Difs_Venn.pdf"), device = "pdf",
       width = 15, height = 15, units = 'cm')

plot(d)
print(fit)
#+end_src
*** Save/Load environtment
#+begin_src R
#### Save environtment ####
#save.image(file = "array_12B10G3D7B_VariantomeData_work_space.RData")
setwd('/mnt/Disc4T/Projects/PhD_Project/Microarrays/New_Old_separate_approach/Old_Arrays/')
#load('array_12B10G3D7B_VariantomeData_work_space.RData')
head(finalDF)
#+end_src

** A7, E5 and B11 (New_Arrays)
:PROPERTIES:
:header-args:R: :session new_arrays :tangle ./Scripts/microarray_analysis_A7_E5_B11.R :results none
:END:
*** Import libraries
#+begin_src R
#### Import libraries ####

print("Importing Libraries...")
list.of.packages <- c("reshape2", "ggfortify", "tidyverse", "RColorBrewer", "sp")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)

library(reshape2)
library(ggfortify)
library(tidyverse)
library(RColorBrewer)
library(sp)
library(readxl)

if (!("Biobase" %in% installed.packages()[,"Package"])){
  if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
  BiocManager::install()
}

library(Biobase)
#+end_src
*** Experiment Setup (modifiable part)
#+begin_src R
############## Experiment Setup: MODIFY THIS PART #######################
##*********************************************************************##
##*********************************************************************##

setwd('/mnt/Disc4T/Projects/PhD_Project/Microarrays/New_Old_separate_approach/New_Arrays/')
datadir <- "./RawData/"
outdir <- "./R_results_NewArray/"
annot <- read.csv("./Files/array_anotation.csv", sep="\t", header = F)
infiles <- "./Files/"

sample_names <- sub("\\.txt$", "", list.files(datadir, pattern="\\.txt$"))
nsamples <- length(sample_names)

times <- as.integer(factor(sub("^.+_tp", "", sample_names)))
types <- sub("_tp.+", "", sample_names)

array_list <- lapply(list.files(datadir, pattern="\\.txt$", full.names=TRUE), read.table, sep="\t", stringsAsFactors=FALSE, skip=9, header=TRUE)
names(array_list) <- sample_names

run_all_plots <- "no"
#+end_src
*** Create folders for output
#+begin_src R
#### Create folders for output ####

print("Creating folders for Output...")
dir.create(paste0(outdir))
dir.create(paste0(outdir, "/Plots"))
dir.create(paste0(outdir, "/Plots/Array_Plots"))
dir.create(paste0(outdir, "/Plots/MA_Plots"))
dir.create(paste0(outdir, "/Plots/Time_estim/"))
dir.create(paste0(outdir, "/Plots/Ratio"))
dir.create(paste0(outdir, "/Plots/Ratio/Gene_Level"))
dir.create(paste0(outdir, "/Plots/Ratio/Probe_Level"))
dir.create(paste0(outdir, "/Plots/Ratio/Gene_Level"))
dir.create(paste0(outdir, "/Plots/Red_Signal"))
dir.create(paste0(outdir, "/Plots/Red_Signal/Gene_Level"))
dir.create(paste0(outdir, "/Plots/Red_Signal/Probe_Level"))
figPath <- paste0(outdir, "/Plots/")
#+end_src
*** Load Array Annotation
#+begin_src R
#### Load Array annotation, Gene-list and Variant Genes ####

print("Loading Array Annotation...")
gene_list <- readLines(paste0(infiles, "gene_list.txt"))

cvgs <- read.csv2(paste0(infiles, 'taula_CVG_final.csv'), stringsAsFactors = F)
cvgs <- cvgs %>%
  select(Gene_id = Gene.ID, Variant = Final.Customized) %>%
  mutate(Variant = ifelse(Variant == 'YES', TRUE, FALSE))

annot_df <- read_csv(paste0(infiles, 'info_df.csv')) %>%
  select(Gene_id, Name, Variant, Annot) %>%
  dplyr::filter(!is.na(Gene_id))
#+end_src
*** Create probe_df
#+begin_src R
#### Create Probe-DF ####

print("Creating Probe DF...")
probe_df <- array_list[[1]][,c(7,11,14,15)]

getCols <- function(df){
  return(df[,c(11,14,15)])
}

goodCols <- lapply(array_list[2:nsamples], function(x) getCols(x))
df <- do.call("cbind", goodCols)

probe_df <- cbind(probe_df, df)
dim(probe_df)

probe_df["Gene_id"] <- annot$V2
probe_df <- probe_df %>%
  left_join(annot_df, by = 'Gene_id')

## probe_df["name"] <- annot$V4
## probe_df["Annot"] <- annot$V5

probe_df["Annot"] <- gsub("Plasmodium", "Pl.", probe_df$Annot)
probe_df["Annot"] <- gsub("protein", "prot.", probe_df$Annot)
probe_df["Annot"] <- gsub("membrane", "memb.", probe_df$Annot)
probe_df["Annot"] <- gsub("conserved", "cvd.", probe_df$Annot)
probe_df["Annot"] <- gsub("function", "func.", probe_df$Annot)
probe_df["Annot"] <- gsub("unknown", "ukwn.", probe_df$Annot)
probe_df["Annot"] <- gsub("exported", "xptd.", probe_df$Annot)
probe_df["Annot"] <- gsub("pseudogene", "pseudo", probe_df$Annot)
probe_df["Annot"] <- gsub("putative", "put.", probe_df$Annot)
probe_df["Annot"] <- gsub("%2C", "", probe_df$Annot)

## Remove probes that map tu multiple genes.
probe_df <- probe_df[annot$V3 != "drop" | is.na(annot$V3),]

## ## Add Variant Genes information
## varlist <- dplyr::filter(cvgs, Variant) %>% select(Gene_id)
## probe_df["Variant"] <- probe_df$Gene_id %in% varlist
#+end_src
*** Group Columns
#+begin_src R
#### Group Columns ####

signalCols <- nsamples*3+1
allcols <- dim(probe_df)[2]

ratioCols <- seq(2, signalCols, 3)
redCols <- seq(4, signalCols, 3)
greCols <- seq(3, signalCols, 3)

infoCols <- c(1, (signalCols+1):allcols)
#+end_src
*** Remove Low-expression Probes
#+begin_src R
#### Remove low expression probes ####

print("Removing low expression probes...")
medians <- list()
for (i in 1:nsamples){
  redm <- median(sort(probe_df[probe_df$Gene_id %in% gene_list, redCols][,i])[1:100])
  grenm <- median(sort(probe_df[probe_df$Gene_id %in% gene_list, greCols][,i])[1:100])
  medians[[i]] <- c(grenm, redm)
}

passTest <- list()
for(i in 1:nsamples){
  g <- probe_df[,greCols][i] < 3*medians[[i]][1]
  r <- probe_df[,redCols][i] < 3*medians[[i]][2]
  all <- g & r
  passTest[[i]] <- !all
}

testDF <- as.data.frame(passTest)
pass <- rowSums(testDF) > 0
write.csv(table(!pass), paste0(outdir, "/NA_probes.csv"))
probe_df[!pass,c(ratioCols)] <- NA
#+end_src
*** Array Plots
#+begin_src R
#### Array Plots ####

print("Plotting Arrays...")
cols <- rev(brewer.pal(11, 'Spectral'))

arrayPlot <- function(df) {
  df_name <- sample_names[i]
  p1 <- qplot(Col, Row, data=df, color=log2(rMedianSignal)<7) + scale_color_manual(values=c("aliceblue", "black")) + ggtitle(df_name)
  ggsave(p1, filename = paste0(figPath, "Array_Plots/sample_", df_name, "_boolean.jpeg"), device = "jpeg")

  p2 <- qplot(Col, Row, data=df, color=log2(rMedianSignal)) + scale_colour_gradientn(colours = cols) + ggtitle(df_name)
  ggsave(p2, filename = paste0(figPath, "Array_Plots/sample_", df_name, ".jpeg"), device = "jpeg")

  p3 <- qplot(Col, Row, data=df, color=is.na(LogRatio)) + scale_color_manual(values=c("aliceblue", "red")) + ggtitle(df_name)
  ggsave(p3, filename = paste0(figPath, "Array_Plots/sample_", df_name, "_NAs.jpeg"), device = "jpeg")
}

for (i in 1:length(array_list)) {arrayPlot(array_list[[i]])}
#+end_src
*** MA Plots
#+begin_src R
#### MA Plots ####

print("Plotting MA Plots...")
myMAplot  <- function(mray){
  df_name <- sample_names[i]
  m_vals <- log2(mray$gProcessedSignal) - log2(mray$rProcessedSignal)
  a_vals <- (log2(mray$gProcessedSignal) + log2(mray$rProcessedSignal))/2
  ma_df <- cbind(a_vals, m_vals)
  p <- ggplot(ma_df, aes(x=a_vals, y=m_vals))
  p <- p + geom_point()
  p <- p + geom_smooth(method = "lm", se=F, color= "red")
  p <- p + geom_hline(yintercept=0, color = "blue", size = 1)
  ggsave(p, filename = paste0(figPath, "MA_Plots/sample_", df_name, "_MA.jpeg"), device = "jpeg")
}

for (i in 1:length(array_list)) {myMAplot(array_list[[i]])}

#+end_src
*** Change to Log2 (Log-Ratio Cols, originally log10)
#+begin_src R
#### Change to Log2 (Log Ratio cols, originally log10) ####

print("Creating Eset...")
probe_df[,ratioCols] <- log2(10**probe_df[,ratioCols])
#+end_src
*** Change to Log2 (Raw data Cols, originally unlogged)
#+begin_src R
#### Change to Log2 (Raw signal Cols, originally unlogged) ####

probe_df[,redCols]  <- log2(probe_df[,redCols])
#+end_src
*** Create Eset: xprobe
#+begin_src R
#### Create eSet: xprobe ####

exprsx <- as.matrix(probe_df[,ratioCols])
colnames(exprsx) <- sample_names
fdata <- new("AnnotatedDataFrame", probe_df[,infoCols])
teor_time <- times
type <- types
pdata <- data.frame(type=type, teor_time=teor_time); rownames(pdata) <- sample_names
pdata <- new("AnnotatedDataFrame", pdata)
xprobe <- new("ExpressionSet", exprs=exprsx, featureData=fdata, phenoData=pdata)
save(xprobe,file=paste0(outdir, '/probeLevel.RData'))

exprsx <- as.matrix(probe_df[,redCols])
colnames(exprsx) <- sample_names
xprobe_red <- new("ExpressionSet", exprs=exprsx, featureData=fdata, phenoData=pdata)

write.csv(cbind(fdata@data, exprs(xprobe)), paste0(outdir, "/probeLevel_exp.csv"), row.names=F)
write.csv(cbind(fdata@data, exprs(xprobe_red)), paste0(outdir, "/probeLevel_redSignalexp.csv"), row.names=F)
#+end_src
*** Rename and Summarize
#+begin_src R
#### Rename and Summarize ####

myRma <- function(x) {
  if (class(x)=='numeric') {
    ans <- x
  } else {
    ans <- medpolish(x,trace.iter=FALSE,na.rm=TRUE)
    ans <- ans$overall + ans$col
  }
  return(ans)
}

renameGenesAndSummarize <- function(genesToRename.sd,exprsx,geneid,summaryMethod=myRma,type) {

  if (type == "ratio"){
    xgene <- by(exprsx[,ratioCols],geneid,myRma)
  } else if (type == "red"){
    xgene <- by(exprsx[,redCols],geneid,myRma)
  }

  xgene <- do.call('rbind',xgene)

  mysd <- function(x) { ans <- ifelse(sum(!is.na(x))==1,0,sd(x,na.rm=TRUE)); return(ans) }
  sdgene <- aggregate(exprsx[, ratioCols],by=list(geneid),FUN=mysd)

  names(sdgene)[1] <- 'geneid'
  xgene <- data.frame(geneid=rownames(xgene),xgene); rownames(xgene) <- NULL

  fdata <- by(exprsx[,(signalCols+1):allcols],geneid,unique)

  genenames <- names(fdata)
  fdata <- do.call('rbind',fdata)

  fdata <- new("AnnotatedDataFrame", data.frame(fdata))
  rownames(fdata) <- as.character(xgene$geneid)

  exprsxgene <- as.matrix(xgene[,-1])
  rownames(exprsxgene) <- as.character(xgene$geneid);
  colnames(exprsxgene) <- sample_names
  eset <- new("ExpressionSet",exprs=exprsxgene, featureData=fdata, phenoData=pdata)
  return(list(eset=eset,sdgene=sdgene,fdata=fdata,geneid=geneid))
}

geneid <- probe_df$Gene_id
geneid <- as.character(geneid)
genesToRename.sd <- NA

tmp <- renameGenesAndSummarize(genesToRename.sd=genesToRename.sd,exprsx=probe_df,geneid=geneid,summaryMethod=myRma, type="ratio")
xgene <- tmp[['eset']]; sdgene <- tmp[['sdgene']]; fdata <- tmp[['fdata']]; geneid <- tmp[['geneid']]

tmp2 <- renameGenesAndSummarize(genesToRename.sd=genesToRename.sd,exprsx=probe_df,geneid=geneid,summaryMethod=myRma, type="red")
xgene_red <- tmp2[['eset']]; sdgene <- tmp2[['sdgene']]; fdata <- tmp2[['fdata']]; geneid <- tmp2[['geneid']]
#+end_src
*** Estimate Times
#+begin_src R
#### Estimate times ####

print("Estimating times...")
bozdechPath <- paste0(infiles, 'bozdech_Hb3_clean2.csv')
LemieuxFunctionsPath <- paste0(infiles, 'lemieux_et_al_pipeline_functions.r')

getTimeEstimation <- function(x,dataPath,functionsPath,figuresPath,B=100) {
                                        #  x: the expressionSet for which we want to estimate times (our data).
                                        #  dataPath: path to data that will be used to estimate timepoints (from Bozdech et al)
                                        #  functionsPath: path to the script containing the functions from Lemieux's paper.
                                        #  figuresPath: where we want to save the output plots.
  source(functionsPath)
                                        #  z <- read.csv(dataPath, as.is = T,sep='\t')
  z <- read.csv(dataPath, as.is = T)
                                        #  colnames(z)[1] <- 'Name'
                                        #  oldTime <- as.numeric(as.character(pData(x)$time))
  oldTime <- as.numeric(teor_time)
  x <- exprs(x)
  x <- data.frame(Name=as.character(rownames(x)),x,stringsAsFactors=FALSE); rownames(x) <- NULL
  data <- sync_data(x, z)
  x <- data[[1]]
  z <- data[[2]]
  x <- ordinal(x, use.name = T)
  z <- ordinal(z, use.name = T)
                                        #  z.na <- cbind(z[,1:22], rep(NA, nrow(z)), z[,23:27], rep(NA, nrow(z)), z[,28:56])
  z.na <- cbind(z[,1:22], rep(NA, nrow(z)), z[,23:27], rep(NA, nrow(z)), z[,28:46])
  z <- t(apply(z.na, 1, smooth.missing))
  sigma.epsilon <- 789.9056
  z.smooth <- smooth.ref(z, method = "spline", spar = 0.5)
  z.smooth.hourly <- z.smooth[,ll.par$hourly]
                                        #  sigma.eta <- mean(sd(z[,11:ncol(z)] - z.smooth.hourly, na.rm = T), na.rm=T)
  sigma.eta <- mean(sd(z - z.smooth.hourly, na.rm = T), na.rm=T)
  new.sigma <- sqrt(sigma.eta^2 + sigma.epsilon^2)
  ll <- compute.ll(x = x, z = z.smooth, sigma = new.sigma, bootstrap = T, B = B, sample.rate = 0.50)
  myTimes <- mle(ll)
  png(file.path(figuresPath,'/Time_estim/defaultPlots1.png'))
  plot.ll(ll)
  dev.off()
  png(file.path(figuresPath,'/Time_estim/defaultPlots2.png'))
  plot.mle(ll)
  dev.off()
  png(file.path(figuresPath,'/Time_estim/ownPlots1.png'))
  plot(density(myTimes),main='Estimated times density')
  dev.off()
  png(file.path(figuresPath,'/Time_estim/ownPlots2.png'))
  plot(oldTime, as.numeric(myTimes),xlab='Old times',ylab='Estimated times',xlim=c(-5,50),ylim=c(-5,50))
  abline(0,1,col=2,lwd=2)
  abline(v=oldTime,lwd=0.5,lty=3)
  dev.off()
  return(myTimes)
}

ascendingTime <- function(x){
  current <- 0
  ncycle <- 0
  for (i in 1:length(x)){
    val  <- x[i]+(48*ncycle)
    if (val < current){
      current <- val
      val <- val+48
      ncycle <- ncycle+1
    }
    current <- val
    x[i] <- val
  }
  return(x)
}


estimatedTimes <- getTimeEstimation(xgene,bozdechPath,LemieuxFunctionsPath,file.path(figPath),B=100)
estimatedTimes[estimatedTimes < 0] <- 0
hpi <- estimatedTimes

for (type in pData(xgene)$type){
  sel <- pData(xgene)$type == type
  typetime <- estimatedTimes[sel]
  time <- ascendingTime(typetime)
  estimatedTimes[sel] <- time
}

write.csv(estimatedTimes, paste0(outdir, "/Estimated_Times.csv"))
pData(xgene)$time <- estimatedTimes
pData(xgene_red)$time <- estimatedTimes
pData(xgene)$hpi <- hpi
pData(xgene_red)$hpi <- hpi

                                        # Save ExpressionSet at gene level
save(xgene,file=paste0(outdir, '/geneLevel.RData'))
save(xgene_red,file=paste0(outdir, '/geneLevel_redSignal.RData'))

                                        # Boxplot after summarization
pdf(file.path(figPath,'boxplot_afterSummarization.pdf'))
boxplot(exprs(xgene),main='summarization method: median poslish')
dev.off()
#+end_src
*** Save results in CSVs
#+begin_src R
#### Save results in CSVs ####

write.csv(xgene@phenoData@data, file = paste0(outdir, "/experiment_data.csv"))
write.csv(cbind(xgene@featureData@data, exprs(xgene)), paste0(outdir, "/geneLevel_exp.csv"), row.names=F)
write.csv(cbind(xgene_red@featureData@data, exprs(xgene_red)), paste0(outdir, "/geneLevel_redSignal_exp.csv"), row.names=F)
#+end_src
*** FC: Probe Level
#+begin_src R
#### FC: Probe Level ####

print("Calculating Fold-Changes...")
filter <- function(x,y) {x==y}
combs <- cross2(sample_names, sample_names, .filter = filter)

fc <- list()
for (i in combs) {
  fc[[paste0(i[[1]], "_",  i[[2]])]] <- exprs(xprobe)[,i[[1]]] - exprs(xprobe)[,i[[2]]]
}

probe_fc <- as.data.frame(fc)
probe_fc <- cbind(fData(xprobe), probe_fc)

write.csv(probe_fc, file = paste0(outdir, "/proveLevel_FC.csv"), row.names = F)
#+end_src
*** FC: Gene Level
#+begin_src R
#### FC: Gene Level ####

filter <- function(x,y) {x==y}
combs <- cross2(sample_names, sample_names, .filter = filter)

fc <- list()
for (i in combs) {
  fc[[paste0(i[[1]], "_",  i[[2]])]] <- exprs(xgene)[,i[[1]]] - exprs(xgene)[,i[[2]]]
}

gene_fc <- as.data.frame(fc)
gene_fc <- cbind(fData(xgene), gene_fc)

write.csv(gene_fc, file = paste0(outdir, "/geneLevel_FC.csv"), row.names = F)
#+end_src
*** Areas: Functions
#+begin_src R
#### Areas: Functions ####

imputePoint <- function(xs, ys, tp){

  ## "xs" and "ys" must be two vectors of equal length
  ## with the corresponding y(expression) and x(timepoint)
  ## values that form the expression plot of interest (one gene).
  ## "tp" must be the timepoint to impute.
  ## If the timepoint to be imputed is already present, leave it as is.
  ## Returns NA if missing the previous or next tp

  if (tp %in% xs){

    idx <- which(xs == tp)
    imputed <- list(x=xs[idx], y=ys[idx])

  } else {

    before <- which(xs == max(xs[xs < tp]))
    after <- which(xs == min(xs[xs > tp]))

    if (is.na(ys[before]) | is.na(ys[after])){

      imputed <- list(x=tp, y=NA)

    } else {

      x <- c(xs[c(before, after)])
      y <- c(ys[c(before, after)])

      imputed <- approx(x, y, xout=tp)
    }
  }
  return(imputed)
}

computeArea <- function(eset){

  ## Takes an eset and computes areas.
  ## pData(eset) must contain a field named "time" with the time-points.
  ## pData(eset) must have a field named "type" with the grouping variable.

  ## Set needed variables
  types <- unique(phenoData(eset)$type)
  type <- phenoData(eset)$type
  times <- phenoData(eset)$time

  maxminTP <- max(sapply(types,function(x) min(times[type==x])))
  minmaxTP <- min(sapply(types,function(x) max(times[type==x])))
  mybreaks <- seq(maxminTP, minmaxTP, length.out=5)
  tp1 <- mybreaks[2]
  tp2 <- mybreaks[3]
  tp3 <- mybreaks[4]

  xsList <- c()
  for (type in types){
    xsList <- c(xsList, list(pData(eset)$time[phenoData(eset)$type == type]))
  }

  ## Main loop
  all_areas <- c()
  for (i in 1:dim(eset)[1]){

    gene <- fData(eset)$geneID[i]

    ysList <- c()
    for (type in types){
      ysList <- c(ysList, list(exprs(eset)[i, phenoData(eset)$type == type]))
    }

    ## Estimate points where needed
    dfs <- list()
    for (i in 1:length(xsList)){

      x <- unlist(xsList[[i]])
      y <- unlist(ysList[[i]])

      points <- as.data.frame(cbind(x, y))
      midpoints <- points[points$x > maxminTP &
                          points$x < minmaxTP, ]

      first <- imputePoint(x, y, maxminTP)
      last <- imputePoint(x, y, minmaxTP)
      p1 <- imputePoint(x, y, tp1)
      p2 <- imputePoint(x, y, tp2)
      p3 <- imputePoint(x, y, tp3)

      impPoints <- rbind(first, last, p1, p2, p3)
      allpoints <- rbind(midpoints, impPoints)
      allpoints$x <- as.numeric(allpoints$x)
      allpoints$y <- as.numeric(allpoints$y)

      ordered <- arrange(allpoints, allpoints$x)

      dfs[[i]] <- ordered
    }

    ## Calculate minY on estimated DFs
    minY <- min(sapply(dfs, function(df) min(df$y, na.rm = T)))

    rowareas <- c()
    for (df in dfs){

      df$y <- df$y - minY

      ## Whole polygon from expression data
      polDF <- rbind(df,
                     c(minmaxTP, 0),
                     c(maxminTP, 0),
                     c(df[1,]))

      ## Create Polygons
      leftHalf <- rbind(df[which(df$x <= tp2),],
                        c(tp2, 0),
                        c(maxminTP, 0),
                        c(df[1,]))

      rightHalf <- rbind(df[which(df$x >= tp2),],
                         c(minmaxTP, 0),
                         c(tp2, 0),
                         c(df[df$x == tp2,]))

      mid <- rbind(df[which(df$x >= tp1 & df$x <= tp3),],
                   c(tp3, 0),
                   c(tp1, 0),
                   c(df[df$x == tp1,]))

      sides <- rbind(df[which(df$x <= tp1),],
                     c(tp1, 0),
                     c(tp3, 0),
                     df[which(df$x >= tp3),],
                     c(minmaxTP, 0),
                     c(maxminTP, 0),
                     df[1,])

      pols <- list(leftHalf, rightHalf, mid, sides)

      calcArea <- function(x) {ifelse(any(is.na(x)), NA, Polygon(x)@area)}
      areas <- unlist(lapply(pols, function(x) calcArea(x)))

      rowareas <- c(rowareas, areas)

      ## Plot polygons (for debugging purposes)
      ##pol <- Polygon(polDF)
      ##ps = Polygons(list(pol),1)
      ##sps = SpatialPolygons(list(ps))
      ##plot(sps)
    }
    all_areas <- c(all_areas, list(rowareas))
  }

  ## Set row and col names for output
  areaDF <- do.call(rbind, all_areas)
  titles <- c("Left", "Right", "Middle", "Sides")

  cols <- c()
  for (i in types){
    for (t in titles){
      name <- paste0(i, "_", t)
      cols <- c(cols, name)
    }
  }
  colnames(areaDF)  <- cols
  rownames(areaDF) <- rownames(exprs(eset))
  return(areaDF)
}
#+end_src
*** Areas: Calls
#+begin_src R
#### Calls: Compute Areas ####

print("Computing Areas...")
areasDF <- computeArea(xgene)
xout <- cbind(fData(xgene), areasDF)

write.csv(xout, paste0(outdir, "/area_geneLevel.csv"), row.names=F)
#+end_src
*** Compute aAFC (average Area Fold Change)
#+begin_src R
#### Calculate aAFC (average Area Fold-Change) ####

myMax <- function(x){
  y <- abs(x)
  if (all(is.na(y))){
    return(list(NA, NA))
  } else {
    pos <- which.max(y)
    times <- c("Left", "Right", "Mid", "Sides")
    return(list(maxVal = x[pos],
                maxTime = times[pos]))
  }
}

## Get number of categories.
n <- length(levels(pData(xgene)$type))

ns <- list()
i <- 1
while (i < n+1){
  ns[[i]] <- 1:4+(4*(i-1))
  i <- i+1
}

## Convert de areasDF into a list of DFs separated by types.
areas <- list()
for (i in 1:length(ns)) {
  areas[[i]] <- areasDF[,ns[[i]]]
}


## Calculate area differences

types <- unique(phenoData(xgene)$type)
type <- phenoData(xgene)$type
times <- phenoData(xgene)$time

maxminTP <- max(sapply(types,function(x) min(times[type==x])))
minmaxTP <- min(sapply(types,function(x) max(times[type==x])))
mybreaks <- seq(maxminTP, minmaxTP, length.out=5)

sets <- 1:length(areas)
combs <- combn(sets, 2)
span <- mybreaks[3] - mybreaks[1]
titles <- c("Left", "Right", "Middle", "Sides")


areaDifs <- list()
for (i in 1:dim(combs)[2]){

  one <- combs[1,i]
  two <- combs[2,i]

  dif1 <- as.data.frame((areas[[one]] - areas[[two]])/span)
  names  <- paste0(colnames(areas[[one]]),
                   "_minus_",
                   colnames(areas[[two]]))

  prefix <- paste0(strsplit(colnames(areas[[one]])[1], "_")[[1]][1],
                   "-",
                   strsplit(colnames(areas[[two]])[1], "_")[[1]][1])
  names <- sapply(titles, function(x) paste(prefix, x, sep = "_"))

  colnames(dif1) <- names

  maxval <- apply(dif1, 1, function(x) myMax(x)[[1]])
  maxtime <- apply(dif1, 1, function(x) myMax(x)[[2]])

  mv <- paste0(prefix, "_MaxVal")
  mt <- paste0(prefix, "_MaxTime")

  dif1[mv] <- maxval
  dif1[mt] <- maxtime

                                        #dif2 <- -dif1

  ## prefix <- paste0(strsplit(colnames(areas[[two]])[1], "_")[[1]][1],
  ##                  "-",
  ##                  strsplit(colnames(areas[[one]])[1], "_")[[1]][1])
  ## names <- sapply(titles, function(x) paste(prefix, x, sep = "_"))

  ## colnames(dif2) <- names

  areaDifs <- c(areaDifs, list(dif1))#, list(dif2))
}

allDifs <- do.call(cbind, areaDifs)
head(allDifs)
#+end_src
*** Convert Partitions into Life-stages
#+begin_src R
#### Areas: Convert Partitions into life stages ####

timetostage <- function(tp){
  while(tp > 48){
    tp = tp-48
  }
  return(tp)
}

getStage <- function(tp) {
  if ((tp >= 0) & (tp < 26)) {stg = "ring"}
  else if ((tp >= 26) & (tp < 38)) {stg = "troph"}
  else if ((tp >= 38) & (tp <= 48)) {stg = "schizont"}
  return(stg)
}

fracToStage <- function(frac, tps){
  if (is.na(frac)){
    return(NA)
  } else if (frac == "Left"){
    tp = tps[2]
    getStage(tp)
  } else if (frac == "Right"){
    tp = tps[4]
    getStage(tp)
  } else if (frac == "Mid"){
    tp = tps[3]
    getStage(tp)
  } else if (frac == "Sides"){
    tp1 = tps[1]+(span/4)
    tp2 = tps[4]+(span/4)
    stg1 <- getStage(tp1)
    stg2 <- getStage(tp2)
    return(paste0(stg1,"-",stg2))
  }
}


ncombs <- dim(combs)[2]

maxValCols <- seq(5, ncombs*6, 6)
maxTimeCols <- seq(6, ncombs*6, 6)

aMAFC <- cbind(allDifs[,c(maxValCols, maxTimeCols)])

timeCols <- (ncombs+1):(ncombs*2)

tps <- sapply(mybreaks, function(x) timetostage(x))

for (i in timeCols){
  aMAFC[,i] <- sapply(aMAFC[,i], function(x) fracToStage(x, tps))
}

write.csv(allDifs, paste0(outdir, "/areaDiferences_geneLevel.csv"))
write.csv(aMAFC, paste0(outdir, "/aMAFC_geneLevel.csv"))
#+end_src
*** Create Max diferences table
#+begin_src R
#### Create Max differences table ####

library(dplyr)

anot_table <- annot %>%
  select(V2, V4, V5) %>%
  rename(Gene_id=V2, Name=V4, Annot=V5) %>%
    dplyr::filter(!is.na(Gene_id)) %>%
  distinct()

head(anot_table)
head(allDifs)

max_df <- allDifs %>%
  mutate(Gene_id = rownames(allDifs)) %>%
  left_join(anot_table, by='Gene_id') %>%
  mutate(MaxMax = pmax(abs(`A7-B11_MaxVal`), abs(`A7-E5_MaxVal`), abs(`B11-E5_MaxVal`))) %>%
  arrange(desc(abs(MaxMax))) %>%
  select(Gene_id, Name, Annot, contains('MaxVal'), contains('MaxTime'), contains('-'))

max_df_top <- max_df %>% dplyr::filter(abs(`A7-B11_MaxVal`) > 4 | abs(`A7-E5_MaxVal`) > 4 | abs(`B11-E5_MaxVal`) > 4)

write.csv(max_df, paste0(outdir, "/all_aMAFC.csv"))
write.csv(max_df_top, paste0(outdir, "/top_aMAFC.csv"))
#+end_src
*** PCA Plots
#+begin_src R
#### PCA Plots ####

print("Plotting PCA..")
noNA <- xgene[complete.cases(exprs(xgene))]
df <- t(exprs(noNA))
df <- as.data.frame(df)

pca <- prcomp(df)
cmp1 <- format(round(summary(pca)$importance[2,1]*100, 2), nsmall = 2)
cmp2 <- format(round(summary(pca)$importance[2,2]*100, 2), nsmall = 2)

df_pca <- as.data.frame(pca$x)
df_pca$Type <- noNA@phenoData@data$type
df_pca$Time <- noNA@phenoData@data$time

p <- ggplot(df_pca, aes(x=PC1,y=PC2, col = Type, group = Type))
p <- p + geom_point(aes(size= Time))
p <- p + geom_path()
p <- p + scale_x_continuous(name=paste0("PC1: ", cmp1, "%"))
p <- p + scale_y_continuous(name=paste0("PC2: ", cmp2, "%"))

ggsave(p, filename = paste0(figPath, "PCA.png"), device = "png", dpi = "retina")

p <- p + theme_classic()
p <- p + theme(text = element_text(size=20))
p

ggsave(p, filename = paste0(figPath, "PCA.svg"), device = "svg")
#+end_src
*** Expression Plots
#+begin_src R
#### Expression Plots ####

print("Plotting Expression Plots...")
expressionPlot <- function(type){

  ## Set df and lims depending on what we are plotting.
  if (type == "gene"){
    df = xgene
    path = "/Ratio/Gene_Level/"

  } else if (type == "gene_red"){
    df = xgene_red
    path = "/Red_Signal/Gene_Level/"

  } else if (type == "probe"){
    df = xprobe
    path = "/Ratio/Probe_Level/"

  } else if (type == "probe_red"){
    df = xprobe_red
    path = "/Red_Signal/Probe_Level/"

  }

  ## Set ylims
  ylim = c(min(exprs(df), na.rm = T), max(exprs(df), na.rm = T))

  ## Set number of plots
  if (run_all_plots == "yes"){
    nplots = dim(df)[1]
  } else {
    nplots = 20
  }

  ## Main Loop
  for (i in 1:nplots){

    ## Set gene for title or gene and probe for probe-level plots.
    gn <- gsub("[/:;.]", "_", fData(df)$Gene_id[i])
    if (type %in% c("probe", "probe_red")){
      prb <- paste0("_", gsub("[/:;.]", "_" , fData(xprobe)$ProbeName[i]))
    } else {
      prb <- ""
    }
    title <- paste0(gn, prb)

    ## Set y-axis title depending on ratio/red_signal
    ytitle <- ifelse(type %in% c("gene_red", "probe_red"), 'log2(Cy5)', 'log2(Cy3/Cy5)')

    ## Plot
    graf <- melt(df[i,])
    graf["Type"] <- xgene@phenoData@data$type
    graf["Time"] <- xgene@phenoData@data$time
    p <- ggplot(graf, aes(x = Time, y = value, col = Type, group = Type))
    p <- p + geom_point(aes(color = Type, shape = Type)) + geom_line()
    p <- p + coord_cartesian(ylim = ylim)
    p <- p + ggtitle(title)
    p <- p + ylab(ytitle)
    ggsave(p, file=paste0(figPath, path, gn, prb, ".jpeg"),
           device = "jpeg", width = 14, height = 10, units = "cm")

  }

}

expressionPlot("gene")
expressionPlot("gene_red")
expressionPlot("probe")
expressionPlot("probe_red")
#+end_src
*** Single Gene Plot
#+begin_src R
#### Single Gene Plot ####

plot_gene <- function(type, gid, out){
  ## Set df and lims depending on what we are plotting.
  if (type == "gene"){
    df = xgene
    path = "/Ratio/Gene_Level/"

  } else if (type == "gene_red"){
    df = xgene_red
    path = "/Red_Signal/Gene_Level/"

  } else if (type == "probe"){
    df = xprobe
    path = "/Ratio/Probe_Level/"

  } else if (type == "probe_red"){
    df = xprobe_red
    path = "/Red_Signal/Probe_Level/"

  }

  ## Set ylims
  ylim = c(min(exprs(df), na.rm = T), max(exprs(df), na.rm = T))


  ## Plot
  ## Set gene for title or gene and probe for probe-level plots.
  gn <- gsub("[/:;.]", "_", gid)
  if (type %in% c("probe", "probe_red")){
    prb <- paste0("_", gsub("[/:;.]", "_" , gid))
  } else {
    prb <- ""
  }
  title <- paste0(gn, prb)

  ## Set y-axis title depending on ratio/red_signal
  ytitle <- ifelse(type %in% c("gene_red", "probe_red"), 'log2(Cy5)', 'log2(Cy3/Cy5)')

  ## Plot
  graf <- melt(df[fData(df)$Gene_id == gid,])
  graf["Type"] <- xgene@phenoData@data$type
  graf["Time"] <- xgene@phenoData@data$time
  p <- ggplot(graf, aes(x = Time, y = value, col = Type, group = Type))
  p <- p + geom_point(aes(color = Type, size = 2))
  p <- p + geom_line(aes(size = 2))
  p <- p + coord_cartesian(ylim = ylim)
  p <- p + theme_classic()
  # p <- p + ggtitle(title)
  # p <- p + ylab(ytitle)
  p <- p + theme(text = element_text(size = 36))
  p <- p + theme(axis.title.x = element_blank())
  p <- p + theme(axis.title.y = element_blank())
  p <- p + theme(legend.position = 'none')
  ggsave(p, file=out, device = "svg")
  print(p)
}

type <- 'gene'
gid <- 'PF3D7_0302200'
outpath <- '/home/lucas/Documents/BioMalPar_2021/Microarrays/Gene_plots/'
outname <- 'PF3D7_0302200_12b10g.svg'

plot_gene(type, gid, paste0(outpath, outname))

#+end_src
*** Add Gametocyte genes info
#+begin_src R
#### Add gametocyte genes info ####
library(readxl)
gene_lists <- read_excel('../All gene lists_160719.xlsx', sheet = 2)

gam_genes <- gene_lists %>%
  select(`Lopez-Barragan`, Lasonder, Gametocites_Young, contains('gam'))

gam_list <- unique(gam_genes %>% pull())
gam_list[gam_list == 'NA'] <- NA
gam_list <- gam_list[!is.na(gam_list)]

finalDF <- max_df %>%
  select(Gene_id, Name, Annot, contains('MaxVal'), contains('MaxTime'))

finalDF['GamGene'] <- finalDF$Gene_id %in% gam_list

write.csv(finalDF, paste0(outdir, "/final_summary_table.csv"), row.names = F)
#+end_src
*** VAR genes plot
#+begin_src R
#### Var genes plot ####
gene_fam <- read_excel('/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/cvgfamilylist/Supplementary_table_2_CVG_list_161120_ap.xlsx', sheet = 2)
gene_fam <- gene_fam %>%
  rename(Gene_id = `Gene ID`,
         Gene_name = `Gene Name or Symbol`,
         SubFamily = `Family Detail`) %>%
  # mutate(SubFamily = case_when(SubFamily == 'var pseudo,truncated or -like.' ~ 'var-like',
  #                              TRUE ~ SubFamily)) %>%
  select(Gene_id, Gene_name, Family, SubFamily)

red_df <- as.data.frame(exprs(xgene_red))
red_df <- 2**(red_df)
red_df <- red_df %>%
  mutate(Gene_id = rownames(red_df)) %>%
  left_join(gene_fam, by='Gene_id')

varPlot <- function(strain){
  plot_df <- red_df %>%
    mutate(Max = select(., contains(strain)) %>% do.call(pmax, .)) %>%
    select(Gene_id, Max, Family, SubFamily) %>%
    dplyr::filter(Family == 'VAR' & SubFamily != 'var pseudo,truncated or -like.')

  vars_plot <- ggplot(plot_df, aes(x = Gene_id, y = Max)) +
    geom_bar(stat = 'identity') +
    ggtitle(paste0('VAR gene expression ', strain)) +
    ylab(paste0('Max(across timepoints) Red Chanel Signal')) +
    theme_classic() +
    theme(axis.text.x=element_text(angle = -90, hjust = 0)) +
    ylim(0, 60000)

  print(vars_plot)

  ggsave(paste0(figPath, strain, '_var_genes_red.pdf'), vars_plot, device = 'pdf')
}

strains <- c('A7', 'E5', 'B11')
for (strain in strains) {varPlot(strain)}
#+end_src
*** Red Filter
#+begin_src R
xgene_red_tibble <- as.data.frame(exprs(xgene_red)) %>%
  tibble() %>%
  mutate(Gene_id = rownames(exprs(xgene_red))) %>%
  select(Gene_id, everything())

## By max col -> then percentile (old)
## get_red_percent <- function(strain){

##   ## Subset to strain
##   red_strain <- xgene_red_tibble %>%
##     select(Gene_id, contains(strain))

##   ## Calculate Max col
##   maxred <- red_strain %>%
##     dplyr::select(-Gene_id) %>%
##     mutate(Max_Red = do.call(pmax, (.))) %>%
##     select(Max_Red)

##   ## Create "percentile" function from Max col
##   percentile <- ecdf(maxred$Max_Red)
##   red_pcnt <- percentile(maxred$Max_Red)

##   return(red_pcnt)
## }

## perc_A7 <- get_red_percent('A7')
## perc_E5 <- get_red_percent('E5')
## perc_B11 <- get_red_percent('B11')

## red_percent <- tibble('Gene_id' = xgene_red_tibble$Gene_id,
##                       'A7' = perc_A7,
##                       'E5' = perc_E5,
##                       'B11' = perc_B11)


## First percentile per col -> max percentile (NEW)

my_percentile <- function(vector){
  ecdf(vector)(vector)*100
}

xgene_red_tibble <- xgene_red_tibble %>%
  mutate(across(.cols = -Gene_id, .fns = my_percentile, .names = "Perc_{.col}"))

get_max_percent <- function(strain){

  ## Subset to strain
  red_strain <- xgene_red_tibble %>%
    select(Gene_id, contains('Perc') & contains(strain))

  ## Calculate Max col
  maxperc <- red_strain %>%
    dplyr::select(-Gene_id) %>%
    mutate(Max_Perc = do.call(pmax, c(., na.rm = T))) %>%
    select(Max_Perc) %>%
    pull()
  return(maxperc)
}

perc_A7 <- get_max_percent('A7')
perc_E5 <- get_max_percent('E5')
perc_B11 <- get_max_percent('B11')

red_percent <- tibble('Gene_id' = xgene_red_tibble$Gene_id,
                      'A7' = perc_A7,
                      'E5' = perc_E5,
                      'B11' = perc_B11)


#hist(red_percent$A7)
write_csv(red_percent, paste0(outdir, "/red_percentiles.csv"))

names(red_percent)[2:4] <- paste0('Red_Pcnt_', names(red_percent)[2:4])

max_tibble <- as_tibble(max_df)
max_tibble <- max_tibble %>%
  left_join(red_percent, by='Gene_id', suffix = c('', '_Pcnt'))

maxFC_pass_red <- max_tibble %>%
  dplyr::filter((`A7-B11_MaxVal` >= 2 & Red_Pcnt_A7 > 15) |
         (`A7-B11_MaxVal` <= -2 & Red_Pcnt_B11 > 15) |
         (`A7-E5_MaxVal` >= 2 & Red_Pcnt_A7 > 15) |
         (`A7-E5_MaxVal` <= -2 & Red_Pcnt_E5 > 15) |
         (`B11-E5_MaxVal` >= 2 & Red_Pcnt_B11 > 15) |
         (`B11-E5_MaxVal` <= -2 & Red_Pcnt_E5 > 15))
#+end_src
*** Get Max-Time for each gene
#+begin_src R
#### Get MaxTime for each gene ####

myWhichMax <- function(vect){
  if (all(is.na(vect))){
    return(NA)
  } else {
    return(which.max(vect))
  }
}

exp <- as.data.frame(exprs(xgene))

maxcol <- exp %>%
  apply(1, myWhichMax) %>%
  unlist()

times <- pData(xgene) %>%
  select(time) %>%
  pull()

maxtime <- sapply(maxcol, function(x) times[x])

max_time <- tibble(Gene_id = names(maxtime), Max_Time = maxtime)
breaks_df <- tibble(Areas_Breaks = mybreaks)

tibble(Gene_id = names(maxtime), Max_Time = maxtime) %>%
  write_csv(paste0(outdir, 'new_arrays_maxtime.csv'))

tibble(Areas_Breaks = mybreaks) %>%
  write_csv(paste0(outdir, 'new_area_breaks.csv'))

## xgene_tibble <- as.data.frame(exprs(xgene)) %>%
##   tibble() %>%
##   mutate(Gene_id = rownames(exprs(xgene)))

## xgene_tibble %>%
##   select(contains('12B'))

## trans_df['Left_in_MaxTime'] <- sapply(maxtime, function(x) checkOverap(getInterval(x, width), left))
#+end_src
*** Filter Genes by Timepoint
#+begin_src R
## #### Filter by Max-Time ####

## New approach
## Check which areas does maxtimepoint overlapp -> check if aAFC > th at this areas

point_overlap <- function(point, interval){
  point >= interval[1] & point <= interval[2]
}

areas_df <- as_tibble(allDifs) %>%
  mutate(Gene_id = rownames(allDifs)) %>%
  select(Gene_id, everything())

maxtimes_A7_B11 <- c()
maxtimes_A7_E5 <- c()
maxtimes_B11_E5 <- c()
gids <- c()
th <- 2
for (gid in max_tibble$Gene_id){

  ## Create time-regions
  breaks <- breaks_df$Areas_Breaks
  left <- c(breaks[1], breaks[3])
  right <- c(breaks[3], breaks[5])
  mid <- c(breaks[2], breaks[4])
  sides_l <- c(breaks[1], breaks[2])
  sides_r <- c(breaks[4], breaks[5])

  ## Get maxtime
  maxtime <- max_time %>%
    dplyr::filter(Gene_id == gid) %>%
    pull()
  if (is.na(maxtime)){
    maxtimes_A7_B11 <- c(maxtimes_A7_B11, NA)
    maxtimes_A7_E5 <- c(maxtimes_A7_E5, NA)
    maxtimes_B11_E5 <- c(maxtimes_B11_E5, NA)
    gids <- c(gids, gid)
  } else {
    ## Ensure maxtime is in the areas intervals
    if (maxtime < breaks[1]) {maxtime <- breaks[1]}
    if (maxtime > breaks[5]) {maxtime <- breaks[5]}

    ## Get overlappped areas
    areas <- list('left' = left, 'right' = right, 'mid' = mid,
                  'sides' = sides_l, 'sides' = sides_r)
    overlaps <- sapply(areas, function(x) point_overlap(maxtime, x))

    ## Get aAFC in overlapping areas by comparison
    aFCs <- areas_df %>%
      dplyr::filter(Gene_id == gid) %>%
      select(contains(names(areas[overlaps])))

    fc_A7_B11 <- aFCs %>%
      select(contains('A7-B11')) %>%
      replace(is.na(.), 0) %>%
      as.numeric()
    maxtime_FC_A7_B11 <- any(abs(fc_A7_B11) > th)

    fc_A7_E5 <- aFCs %>%
      select(contains('A7-E5')) %>%
      replace(is.na(.), 0) %>%
      as.numeric()
    maxtime_FC_A7_E5 <- any(abs(fc_A7_E5) > th)

    fc_B11_E5 <- aFCs %>%
      select(contains('B11-E5')) %>%
      replace(is.na(.), 0) %>%
      as.numeric()
    maxtime_FC_B11_E5 <- any(abs(fc_B11_E5) > th)

    maxtimes_A7_B11 <- c(maxtimes_A7_B11, maxtime_FC_A7_B11)
    maxtimes_A7_E5 <- c(maxtimes_A7_E5, maxtime_FC_A7_E5)
    maxtimes_B11_E5 <- c(maxtimes_B11_E5, maxtime_FC_B11_E5)
    gids <- c(gids, gid)
  }
}
maxtime_aAFC_df <- tibble(
  Gene_id = gids,
  MaxTime_Filter_A7_B11 = maxtimes_A7_B11,
  MaxTime_Filter_A7_E5 = maxtimes_A7_E5,
  MaxTime_Filter_B11_E5 = maxtimes_B11_E5
  )

max_tibble <- max_tibble %>%
  left_join(maxtime_aAFC_df)


#+end_src
*** Filter genes by Deletions/Duplications
#+begin_src R
## f_path <- '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/Duplication_Deletion_Regions/Crossed_with_genes/'

## list.files(f_path)

## file_list <- c(
##   "A7K9_minus_E5K9_100bp_500smth_RPKM_cov_norm_pdf_0999999_minlen500_genes.tsv",
##   "A7K9_minus_B11_100bp_500smth_RPKM_cov_norm_pdf_0999999_minlen500_genes.tsv",
##   "B11_minus_E5K9_100bp_500smth_RPKM_cov_norm_pdf_0999999_minlen500_genes.tsv"
## )

## dupl_dl_A7_E5 <- read_tsv(paste0(f_path, file_list[1]), col_names = F) %>%
##   select(X1) %>% pull()

## dupl_dl_A7_B11 <- read_tsv(paste0(f_path, file_list[2]), col_names = F) %>%
##   select(X1) %>% pull()

## dupl_dl_B11_E5 <- read_tsv(paste0(f_path, file_list[3]), col_names = F) %>%
##   select(X1) %>% pull()

f_path <- '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/Duplication_Deletion_Regions_Mean/Crossed_with_genes/'

file_list <- c(
  "A7K9_in_sort_q5_RPKMs_bymean_fact_1.75_0.1_minlen500_mergelen_200_filtered_genes.tsv",
  "E5K9_in_sort_q5_RPKMs_bymean_fact_1.75_0.1_minlen500_mergelen_200_filtered_genes.tsv",
  "B11_in_sort_q5_RPKMs_bymean_fact_1.75_0.1_minlen500_mergelen_200_filtered_genes.tsv"
)

dupl_dl_A7 <- read_tsv(paste0(f_path, file_list[1]), col_names = F) %>%
  select(X1) %>% pull()

dupl_dl_E5 <- read_tsv(paste0(f_path, file_list[2]), col_names = F) %>%
  select(X1) %>% pull()

dupl_dl_B11 <- read_tsv(paste0(f_path, file_list[3]), col_names = F) %>%
  select(X1) %>% pull()


#+end_src
*** Get Final List of Genes
#+begin_src R
## Load Latest Annot
info_df <- read_csv(paste0(infiles, 'info_df.csv')) %>%
  dplyr::filter(!is.na(Gene_id))

final_df <- max_tibble %>%
  mutate(Gene_id = ifelse(Gene_id == 'PF3D7_0935400_as', 'PF3D7_0935390', Gene_id)) %>%
  mutate(Not_Plasmodium = !Gene_id %in% info_df$Gene_id)

final_df <- final_df %>%
  select(-Name, -Annot) %>%
  left_join(info_df, by='Gene_id')

## Set thresholds
red_th <- 15

## A7 vs B11

final_df %>%
  select(
    Gene_id,
    `A7-B11_MaxVal`,
    `A7-B11_MaxTime`,
    Red_Pcnt_A7,
    Red_Pcnt_B11,
    MaxTime_Filter_A7_B11
  ) %>%
  mutate(PassRed = ifelse(
           `A7-B11_MaxVal` >= 0,
           Red_Pcnt_A7 >= red_th,
           Red_Pcnt_B11 >= red_th
         )) %>%
  rename(PassMaxtime = MaxTime_Filter_A7_B11) %>%
  mutate(PassDuplDel = !Gene_id %in% dupl_dl_A7 & !Gene_id %in% dupl_dl_B11) %>%
  rowwise() %>%
  mutate(PassAll = all(c(PassRed, PassMaxtime, PassDuplDel))) %>%
  write_tsv(paste0(outdir, 'A7_B11_final_df.tsv'))

## A7 vs E5

final_df %>%
  select(
    Gene_id,
    `A7-E5_MaxVal`,
    `A7-E5_MaxTime`,
    Red_Pcnt_A7,
    Red_Pcnt_E5,
    MaxTime_Filter_A7_E5
  ) %>%
  mutate(PassRed = ifelse(
           `A7-E5_MaxVal` >= 0,
           Red_Pcnt_A7 >= red_th,
           Red_Pcnt_E5 >= red_th
         )) %>%
  rename(PassMaxtime = MaxTime_Filter_A7_E5) %>%
  mutate(PassDuplDel = !Gene_id %in% dupl_dl_A7 & !Gene_id %in% dupl_dl_E5) %>%
  rowwise() %>%
  mutate(PassAll = all(c(PassRed, PassMaxtime, PassDuplDel))) %>%
  write_tsv(paste0(outdir, 'A7_E5_final_df.tsv'))

## B11 vs E5

final_df %>%
  select(
    Gene_id,
    `B11-E5_MaxVal`,
    `B11-E5_MaxTime`,
    Red_Pcnt_B11,
    Red_Pcnt_E5,
    MaxTime_Filter_B11_E5
  ) %>%
  mutate(PassRed = ifelse(
           `B11-E5_MaxVal` >= 0,
           Red_Pcnt_B11 >= red_th,
           Red_Pcnt_E5 >= red_th
         )) %>%
  rename(PassMaxtime = MaxTime_Filter_B11_E5) %>%
  mutate(PassDuplDel = !Gene_id %in% dupl_dl_B11 & !Gene_id %in% dupl_dl_E5) %>%
  rowwise() %>%
  mutate(PassAll = all(c(PassRed, PassMaxtime, PassDuplDel))) %>%
  write_tsv(paste0(outdir, 'B11_E5_final_df.tsv'))


###################################################


## A7 vs B11

difs_A7_B11 <- final_df %>%
  dplyr::filter(
  ((`A7-B11_MaxVal` >= 2 & Red_Pcnt_A7 > 15) |
   (`A7-B11_MaxVal` <= -2 & Red_Pcnt_B11 > 15)) &
  MaxTime_Filter_A7_B11
  ) %>%
  mutate(Dupl_Del = Gene_id %in% dupl_dl_A7 | Gene_id %in% dupl_dl_B11) %>%
  dplyr::filter(!Not_Plasmodium & !Is_tRNA) %>%
  select(Gene_id, Name, Annot,
         `A7-B11_MaxVal`,
         Red_Pcnt_A7, Red_Pcnt_B11,
         MaxTime_Filter_A7_B11,
         Variant, Gam_specific, Dupl_Del)

write_csv(difs_A7_B11, paste0(outdir, 'A7_vs_B11_log2FC2_red15_maxtime.csv'))


## A7 vs E5

difs_A7_E5 <- final_df %>%
  dplyr::filter(
  ((`A7-E5_MaxVal` >= 2 & Red_Pcnt_A7 > 15) |
   (`A7-E5_MaxVal` <= -2 & Red_Pcnt_E5 > 15)) &
  MaxTime_Filter_A7_E5
  ) %>%
  mutate(Dupl_Del = Gene_id %in% dupl_dl_A7 | Gene_id %in% dupl_dl_E5) %>%
  dplyr::filter(!Not_Plasmodium & !Is_tRNA) %>%
  select(Gene_id, Name, Annot,
         `A7-E5_MaxVal`,
         Red_Pcnt_A7, Red_Pcnt_E5,
         MaxTime_Filter_A7_E5,
         Variant, Gam_specific, Dupl_Del)

write_csv(difs_A7_E5, paste0(outdir, 'A7_vs_E5_log2FC2_red15_maxtime.csv'))


## B11 vs E5

difs_B11_E5 <- final_df %>%
  dplyr::filter(
  ((`B11-E5_MaxVal` >= 2 & Red_Pcnt_B11 > 15) |
   (`B11-E5_MaxVal` <= -2 & Red_Pcnt_E5 > 15)) &
  MaxTime_Filter_B11_E5
  ) %>%
  dplyr::filter(!Not_Plasmodium & !Is_tRNA) %>%
  mutate(Dupl_Del = Gene_id %in% dupl_dl_B11 | Gene_id %in% dupl_dl_E5) %>%
  select(Gene_id, Name, Annot,
         `B11-E5_MaxVal`,
         Red_Pcnt_B11, Red_Pcnt_E5,
         MaxTime_Filter_B11_E5,
         Variant, Gam_specific, Dupl_Del)

write_csv(difs_B11_E5, paste0(outdir, 'B11_vs_E5_log2FC2_red15_maxtime.csv'))

write_csv(final_df, paste0(outdir, 'new_arrays_final_df.csv'))
#+end_src
*** Make Venn Diagram
#+begin_src R
library(eulerr)

A <- difs_A7_E5$Gene_id
B <- difs_A7_B11$Gene_id
C <- difs_B11_E5$Gene_id

AB <- intersect(A, B)
AC <- intersect(A, C)
BC <- intersect(B, C)

ABC <- intersect(AB, C)

abc <- length(ABC)
ab <- length(AB[!AB %in% ABC])
ac <- length(AC[!AC %in% ABC])
bc <- length(BC[!BC %in% ABC])

a <- length(A) -ab -ac -abc
b <- length(B) -ab -bc -abc
c <- length(C) -ac -bc -abc

fit <- euler(c(A=a, B=b, C=c, "A&B"=ab, "A&C"=ac, "B&C"=bc, "A&B&C" = abc))

scales::viridis_pal()(3)

d <- plot(fit, fills = list(fill = c('#440154FF', "#21908CFF", "#FDE725FF"), alpha = 0.5),
          edges = list(lwd = 0.1),
          quantities = list(quantities = T),
          labels = list(labels=c("A7 vs E5", "A7 vs B11", "B11 vs E5"), fontsize = 7))

ggsave(d, filename = paste0(figPath, "Difs_Venn.pdf"), device = "pdf")

plot(d)
print(fit)
#+end_src
*** Save/Load environtment
#+begin_src R
#### Save environtment ####
#save.image(file = "array_A7E5B11_work_space.RData")
setwd('/mnt/Disc4T/Projects/PhD_Project/Microarrays/New_Old_separate_approach/New_Arrays/')
#load('array_A7E5B11_work_space.RData')
head(final_df)
#+end_src
** Join Analysis
:PROPERTIES:
:header-args:R: :session join_analysis :tangle ./Scripts/microarray_analysis_joinAnalysis.R :results none
:END:
*** WD and libraries
#+begin_src R
wd <- '/mnt/Disc4T/Projects/PhD_Project/Microarrays/New_Old_separate_approach/Join_Analysis/'
setwd(wd)

library(tidyverse)
library(eulerr)
library(readxl)
library(viridis)
library(ggdendro)
library(gridExtra)
#+end_src
*** Join Venns
#+begin_src R
## Load Old Dif Genes
old_fld <- '../Old_Arrays/R_results_OldArrays_Variantome/'
suffix <- '_log2FC2_red15_maxtime2.csv'

v12B_10G <- read_csv(paste0(old_fld, '12B_vs_10G', suffix)) %>%
         select(Gene_id) %>%
         pull()

v12B_3D7B <- read_csv(paste0(old_fld, '12B_vs_3D7B', suffix)) %>%
  select(Gene_id) %>%
  pull()

v10G_3D7B <- read_csv(paste0(old_fld, '10G_vs_3D7B', suffix)) %>%
  select(Gene_id) %>%
  pull()

old_gids <- unique(c(v12B_10G, v12B_3D7B, v10G_3D7B))


## Load New Dif Genes
new_fld <- '../New_Arrays/R_results_NewArray/'
suffix <- '_log2FC2_red15_maxtime2.csv'

vA7_B11 <- read_csv(paste0(new_fld, 'A7_vs_B11', suffix)) %>%
  select(Gene_id) %>%
  pull()

vA7_E5 <- read_csv(paste0(new_fld, 'A7_vs_E5', suffix)) %>%
  select(Gene_id) %>%
  pull()

vB11_E5 <- read_csv(paste0(new_fld, 'B11_vs_E5', suffix)) %>%
  select(Gene_id) %>%
  pull()

new_gids <- unique(c(vA7_B11, vA7_E5, vB11_E5))


## Plot
A <- old_gids
B <- new_gids
AB <- intersect(A, B)

ab <- length(AB)
a <- length(A[!A %in% AB])
b <- length(B[!B %in% AB])


fit <- euler(c(A=a, B=b, "A&B"=ab))

scales::viridis_pal()(2)

d <- plot(fit, fills = list(fill = c('#440154FF', "#FDE725FF"), alpha = 0.5),
          edges = list(lwd = 0.1),
          quantities = list(quantities = T),
          labels = list(labels=c("Old Arrays", "New Arrays")))

ggsave(d, filename = './join_Difs_Venn.pdf', device = "pdf")

plot(d)
print(fit)

#+end_src
*** Join PCAs
**** Load Data
#+begin_src R
library(viridis)

## Load Areas
exp_old <- read_csv('../Old_Arrays/R_results_OldArrays_Variantome/geneLevel_exp.csv') %>%
  select(-Name, -Variant, -Annot)

exp_new <- read_csv('../New_Arrays/R_results_NewArray/geneLevel_exp.csv') %>%
  select(-name, -Variant, -Annot)

exp_df <- full_join(exp_old, exp_new)
exp_df[exp_df$Gene_id == 'PF3D7_0935400_as',]$Gene_id <- 'PF3D7_0935390'

## Load Red Signal
red_old <- read_csv('../Old_Arrays/R_results_OldArrays_Variantome/geneLevel_redSignalexp.csv') %>%
  select(-Name, -Variant, -Annot)

red_new <- read_csv('../New_Arrays/R_results_NewArray/geneLevel_redSignal_exp.csv') %>%
  select(-name, -Variant, -Annot)

red_df <- full_join(red_old, red_new)
red_df[red_df$Gene_id == 'PF3D7_0935400_as',]$Gene_id <- 'PF3D7_0935390'

## Load info_df
info_df <- read_csv('../../../Binned_Coverage/info_df.csv')

## Load dif_genes
dif_df <- read_csv('../../../Binned_Coverage/max_log2FC2_filters_passed.csv')


#+end_src
**** Dif Genes
#+begin_src R
## PCA Dif Genes

pca_df <- exp_df %>%
  filter(Gene_id %in% dif_df$Gene_id) %>%
  filter(complete.cases(.)) %>%
  pivot_longer(-Gene_id) %>%
  pivot_wider(names_from = Gene_id, values_from = value)

pca <- prcomp(pca_df %>% select(-name))
cmp1 <- format(round(summary(pca)$importance[2,1]*100, 2), nsmall = 2)
cmp2 <- format(round(summary(pca)$importance[2,2]*100, 2), nsmall = 2)

df_pca <- as.data.frame(pca$x)
head(df_pca)

strains <- sapply(pca_df$name, function(x) str_split(x, fixed('_'))[[1]][1])
tps <- sapply(pca_df$name, function(x) str_split(x, fixed('_'))[[1]][2])

?str_split

df_pca$Strain <- strains
df_pca$TimePoint <- tps

p <- ggplot(df_pca, aes(x=PC1,y=PC2, col = Strain, group = Strain))
p <- p + geom_point(aes(size= TimePoint))
p <- p + geom_path()
p <- p + scale_x_continuous(name=paste0("PC1: ", cmp1, "%"))
p <- p + scale_y_continuous(name=paste0("PC2: ", cmp2, "%"))
#p <- p + scale_color_viridis(discrete=TRUE, option="viridis")
p

ggsave(p, filename = "PCA_dif_genes.pdf", device = "pdf")
#+end_src
**** Collapse genes to 1 val
#+begin_src R
## PCA colapse genes into 1 val

maxexp_df <- exp_df %>%
  rowwise() %>%
  mutate(Max12B = max(c_across(contains('12B')))) %>%
  mutate(Max10G = max(c_across(contains('10G')))) %>%
  mutate(Max3D7B = max(c_across(contains('3D7B')))) %>%
  mutate(MaxA7 = max(c_across(contains('A7')))) %>%
  mutate(MaxE5 = max(c_across(contains('E5')))) %>%
  mutate(MaxB11 = max(c_across(contains('B11')))) %>%
  ungroup() %>%
  select(Gene_id, contains('Max'))

pca_df <- maxexp_df %>%
  #filter(Gene_id %in% dif_df$Gene_id) %>%
  filter(complete.cases(.)) %>%
  pivot_longer(-Gene_id) %>%
  pivot_wider(names_from = Gene_id, values_from = value)

pca <- prcomp(pca_df %>% select(-name))
cmp1 <- format(round(summary(pca)$importance[2,1]*100, 2), nsmall = 2)
cmp2 <- format(round(summary(pca)$importance[2,2]*100, 2), nsmall = 2)

df_pca <- as.data.frame(pca$x)
head(df_pca)

strains <- sapply(pca_df$name, function(x) gsub('Max', '', x, fixed = T))
df_pca$Strain <- strains

p <- ggplot(df_pca, aes(x=PC1,y=PC2, col = Strain, group = Strain))
p <- p + geom_point()
p <- p + geom_path()
p <- p + scale_x_continuous(name=paste0("PC1: ", cmp1, "%"))
p <- p + scale_y_continuous(name=paste0("PC2: ", cmp2, "%"))
##p <- p + scale_color_viridis(discrete=TRUE, option="viridis")
p

ggsave(p, filename = "PCA_collapsed_genes.pdf", device = "pdf")

#+end_src
**** Percentiles
#+begin_src R
my_percentile <- function(vector){
  ecdf(vector)(vector)*100
}

red_perc_df <- red_df %>%
  mutate(across(.cols = -Gene_id, .fns = my_percentile, .names = "Perc_{.col}")) %>%
  select(Gene_id, contains('Perc'))


## PCA Red Signal Perc

pca_df <- red_perc_df %>%
  #filter(Gene_id %in% dif_df$Gene_id) %>%
  filter(complete.cases(.)) %>%
  pivot_longer(-Gene_id) %>%
  pivot_wider(names_from = Gene_id, values_from = value)

pca <- prcomp(pca_df %>% select(-name))
cmp1 <- format(round(summary(pca)$importance[2,1]*100, 2), nsmall = 2)
cmp2 <- format(round(summary(pca)$importance[2,2]*100, 2), nsmall = 2)

df_pca <- as.data.frame(pca$x)

strains <- sapply(pca_df$name, function(x) str_split(x, fixed('_'))[[1]][2])
tps <- sapply(pca_df$name, function(x) str_split(x, fixed('_'))[[1]][3])

df_pca$Strain <- strains
df_pca$TimePoint <- tps

p <- ggplot(df_pca, aes(x=PC1,y=PC2, col = Strain, group = Strain))
p <- p + geom_point(aes(size= TimePoint))
p <- p + geom_path()
p <- p + scale_x_continuous(name=paste0("PC1: ", cmp1, "%"))
p <- p + scale_y_continuous(name=paste0("PC2: ", cmp2, "%"))
#p <- p + scale_color_viridis(discrete=TRUE, option="viridis")
p

ggsave(p, filename = "PCA_redperc_genes.pdf", device = "pdf")

## Collapse into 1 val

maxperc_df <- red_perc_df %>%
  rowwise() %>%
  mutate(Max12B = max(c_across(contains('12B')))) %>%
  mutate(Max10G = max(c_across(contains('10G')))) %>%
  mutate(Max3D7B = max(c_across(contains('3D7B')))) %>%
  mutate(MaxA7 = max(c_across(contains('A7')))) %>%
  mutate(MaxE5 = max(c_across(contains('E5')))) %>%
  mutate(MaxB11 = max(c_across(contains('B11')))) %>%
  ungroup() %>%
  select(Gene_id, contains('Max'))

pca_df <- maxexp_df %>%
  #filter(Gene_id %in% dif_df$Gene_id) %>%
  filter(complete.cases(.)) %>%
  pivot_longer(-Gene_id) %>%
  pivot_wider(names_from = Gene_id, values_from = value)

pca <- prcomp(pca_df %>% select(-name))
cmp1 <- format(round(summary(pca)$importance[2,1]*100, 2), nsmall = 2)
cmp2 <- format(round(summary(pca)$importance[2,2]*100, 2), nsmall = 2)

df_pca <- as.data.frame(pca$x)
head(df_pca)

strains <- sapply(pca_df$name, function(x) gsub('Max', '', x, fixed = T))
df_pca$Strain <- strains

p <- ggplot(df_pca, aes(x=PC1,y=PC2, col = Strain, group = Strain))
p <- p + geom_point()
p <- p + geom_path()
p <- p + scale_x_continuous(name=paste0("PC1: ", cmp1, "%"))
p <- p + scale_y_continuous(name=paste0("PC2: ", cmp2, "%"))
##p <- p + scale_color_viridis(discrete=TRUE, option="viridis")
p

ggsave(p, filename = "PCA_redperc_collapsed_genes.pdf", device = "pdf")
#+end_src
*** Heatmaps
**** Load Data
#+begin_src R
old_path <-'../Old_Arrays/R_results_OldArrays_Variantome/'
new_path <-'../New_Arrays/R_results_NewArray/'

old_df <- read_csv(paste0(old_path, 'old_arrays_final_df.csv'))
new_df <- read_csv(paste0(new_path, 'new_arrays_final_df.csv'))

old_areas <- read_csv(paste0(old_path, 'area_geneLevel.csv'))
new_areas <- read_csv(paste0(new_path, 'area_geneLevel.csv'))
new_areas[new_areas$Gene_id == 'PF3D7_0935400_as',]$Gene_id <- 'PF3D7_0935390'

old_max <- read_csv(paste0(old_path, 'all_aMAFC.csv'))
new_max <- read_csv(paste0(new_path, 'all_aMAFC.csv'))
new_max[new_max$Gene_id == 'PF3D7_0935400_as',]$Gene_id <- 'PF3D7_0935390'

## Load info_df
info_df <- read_csv('../../../Binned_Coverage/info_df.csv')
#+end_src
**** Create old maxFC DF
#+begin_src R
## OLD TOP DIFERENCES
## Quin timepoint agafem? El de mÃ xima diferÃ¨ncia. Entre quines soques?
## QuÃ¨ passa si un mateix gen tÃ© diferÃ¨ncies a TPs diferents en contrastos diferents?

## Agafem per a cada gen el timepoint de mÃ xima diferÃ¨ncia del contrast amb mÃ xima diferÃ¨ncia.

dif_12B_10G <- read_csv(paste0(old_path, '12B_vs_10G_log2FC2_red15_maxtime.csv'))
dif_12B_3D7B <- read_csv(paste0(old_path, '12B_vs_3D7B_log2FC2_red15_maxtime.csv'))
dif_10G_3D7B <- read_csv(paste0(old_path, '10G_vs_3D7B_log2FC2_red15_maxtime.csv'))

table(dif_12B_10G$Dupl_Del)
table(dif_12B_3D7B$Dupl_Del)
table(dif_10G_3D7B$Dupl_Del)

tp_12B_10G <- old_max %>%
  select(Gene_id, `12B-10G_MaxTime`) %>%
  filter(Gene_id %in% dif_12B_10G$Gene_id)

tp_12B_3D7B <- old_max %>%
  select(Gene_id, `12B-3D7B_MaxTime`) %>%
  filter(Gene_id %in% dif_12B_3D7B$Gene_id)

tp_10G_3D7B <- old_max %>%
  select(Gene_id, `10G-3D7B_MaxTime`) %>%
  filter(Gene_id %in% dif_10G_3D7B$Gene_id)

x <- dif_12B_10G %>%
  select(Gene_id, `12B-10G_MaxVal`, Variant, Gam_specific, Dupl_Del) %>%
  rename(MaxVal = `12B-10G_MaxVal`) %>%
  mutate(Contrast = '12B_10G') %>%
  left_join(tp_12B_10G) %>%
  rename(MaxTime = `12B-10G_MaxTime`)

y <- dif_12B_3D7B %>%
  select(Gene_id, `12B-3D7B_MaxVal`, Variant, Gam_specific, Dupl_Del) %>%
  rename(MaxVal = `12B-3D7B_MaxVal`) %>%
  mutate(Contrast = '12B_3D7B') %>%
  left_join(tp_12B_3D7B) %>%
  rename(MaxTime = `12B-3D7B_MaxTime`)

z <- dif_10G_3D7B %>%
  select(Gene_id, `10G-3D7B_MaxVal`, Variant, Gam_specific, Dupl_Del) %>%
  rename(MaxVal = `10G-3D7B_MaxVal`) %>%
  mutate(Contrast = '10G_3D7B') %>%
  left_join(tp_10G_3D7B) %>%
  rename(MaxTime = `10G-3D7B_MaxTime`)

old_maxdifs <- bind_rows(x, y, z) %>%
  arrange(-abs(MaxVal)) %>%
  distinct(Gene_id, .keep_all = TRUE)

old_heat_areas <- NULL
new_heat_areas <- NULL
for (gid in old_maxdifs$Gene_id) {
  tp <- old_maxdifs %>%
    filter(Gene_id == gid) %>%
    select(MaxTime) %>%
    pull()

  old_a <- old_areas %>%
    filter(Gene_id == gid) %>%
    select(contains(tp))

  new_a <- new_areas %>%
    filter(Gene_id == gid) %>%
    select(contains(tp))

  if (dim(new_a)[1] == 0){
    new_a = tibble(
      c1 = as.numeric(NA),
      c2 = as.numeric(NA),
      c3 = as.numeric(NA)
    )
    }
  names(old_a) <- c('1.2B', '10G', '3D7-B')
  names(new_a) <- c('A7', 'B11', 'E5')

  old_heat_areas <- bind_rows(old_heat_areas, old_a)
  new_heat_areas <- bind_rows(new_heat_areas, new_a)
}
old_heat_df <- bind_cols(old_maxdifs, old_heat_areas)
new_heat_df <- bind_cols(old_maxdifs %>% select(Gene_id, Variant, Gam_specific, Dupl_Del), new_heat_areas)

old_heat_df <- old_heat_df %>%
  rowwise() %>%
  mutate(rwmean_centered_12B = `1.2B` - mean(c(`1.2B`, `10G`, `3D7-B`))) %>%
  mutate(rwmean_centered_10G = `10G` - mean(c(`1.2B`, `10G`, `3D7-B`))) %>%
  mutate(rwmean_centered_3D7B = `3D7-B` - mean(c(`1.2B`, `10G`, `3D7-B`)))

new_heat_df <- new_heat_df %>%
  rowwise() %>%
  mutate(rwmean_centered_A7 = A7 - mean(c(A7, E5, B11))) %>%
  mutate(rwmean_centered_E5 = E5 - mean(c(A7, E5, B11))) %>%
  mutate(rwmean_centered_B11 = B11 - mean(c(A7, E5, B11)))

old_pre_dupl_filtering <- old_heat_df
new_pre_dupl_filtering <- new_heat_df

old_heat_df <- old_heat_df %>%
  filter(!Dupl_Del)

new_heat_df <- new_heat_df %>%
  filter(!Dupl_Del)

## Ordering
mtx <- old_heat_df %>%
  select(contains('rwmean'))

##Make hierarquical Clustering
dmtx <- dist(scale(mtx), method = "euclidean")
cl <- hclust(dmtx, method = 'average')
old_heat_df$Gene_id <- factor(old_heat_df$Gene_id, levels = old_heat_df$Gene_id[cl$order])
new_heat_df$Gene_id <- factor(new_heat_df$Gene_id, levels = new_heat_df$Gene_id[cl$order])

old_tree <- ggdendrogram(cl, rotate = T)

old_m_infodf <- old_heat_df %>%
  select(Gene_id, Variant, Gam_specific) %>%
  gather(variable, value, -Gene_id)

mold_df <- old_heat_df %>%
  select(Gene_id, contains('rwmean')) %>%
  gather(variable, value, -Gene_id)

mnew_df <- new_heat_df %>%
  select(Gene_id, contains('rwmean')) %>%
  gather(variable, value, -Gene_id)

## old_heat_df %>%
##   left_join(info_df, by = 'Gene_id') %>%
##   select(
##     Gene_id,
##     Variant,
##     Gam_specific,
##     contains('rwmean')
##     ) %>%
##   write_tsv('old_arrays_maxFC_heatmap_df.tsv')


#+end_src
**** Create new maxFC DF
#+begin_src R
## NEW TOP DIFERENCES
## Quin timepoint agafem? El de mÃ xima diferÃ¨ncia. Entre quines soques?
## QuÃ¨ passa si un mateix gen tÃ© diferÃ¨ncies a TPs diferents en contrastos diferents?

## Agafem per a cada gen el timepoint de mÃ xima diferÃ¨ncia del contrast amb mÃ xima diferÃ¨ncia.

dif_A7_E5 <- read_csv(paste0(new_path, 'A7_vs_E5_log2FC2_red15_maxtime.csv'))
dif_A7_B11 <- read_csv(paste0(new_path, 'A7_vs_B11_log2FC2_red15_maxtime.csv'))
dif_B11_E5 <- read_csv(paste0(new_path, 'B11_vs_E5_log2FC2_red15_maxtime.csv'))

tp_A7_E5 <- new_max %>%
  select(Gene_id, `A7-E5_MaxTime`) %>%
  filter(Gene_id %in% dif_A7_E5$Gene_id)

tp_A7_B11 <- new_max %>%
  select(Gene_id, `A7-B11_MaxTime`) %>%
  filter(Gene_id %in% dif_A7_B11$Gene_id)

tp_B11_E5 <- new_max %>%
  select(Gene_id, `B11-E5_MaxTime`) %>%
  filter(Gene_id %in% dif_B11_E5$Gene_id)

x <- dif_A7_E5 %>%
  select(Gene_id, `A7-E5_MaxVal`, Variant, Gam_specific, Dupl_Del) %>%
  rename(MaxVal = `A7-E5_MaxVal`) %>%
  mutate(Contrast = 'A7_E5') %>%
  left_join(tp_A7_E5) %>%
  rename(MaxTime = `A7-E5_MaxTime`)

y <- dif_A7_B11 %>%
  select(Gene_id, `A7-B11_MaxVal`, Variant, Gam_specific, Dupl_Del) %>%
  rename(MaxVal = `A7-B11_MaxVal`) %>%
  mutate(Contrast = 'A7_B11') %>%
  left_join(tp_A7_B11) %>%
  rename(MaxTime = `A7-B11_MaxTime`)

z <- dif_B11_E5 %>%
  select(Gene_id, `B11-E5_MaxVal`, Variant, Gam_specific, Dupl_Del) %>%
  rename(MaxVal = `B11-E5_MaxVal`) %>%
  mutate(Contrast = 'B11_E5') %>%
  left_join(tp_B11_E5) %>%
  rename(MaxTime = `B11-E5_MaxTime`)

new_maxdifs <- bind_rows(x, y, z) %>%
  arrange(-abs(MaxVal)) %>%
  distinct(Gene_id, .keep_all = TRUE)

new_old_heat_areas <- NULL
new_new_heat_areas <- NULL
for (gid in new_maxdifs$Gene_id) {

  tp <- new_maxdifs %>%
    filter(Gene_id == gid) %>%
    select(MaxTime) %>%
    pull()

  old_a <- old_areas %>%
    filter(Gene_id == gid) %>%
    select(contains(tp))

  new_a <- new_areas %>%
    filter(Gene_id == gid) %>%
    select(contains(tp))

  if (dim(old_a)[1] == 0){
    old_a = tibble(
      c1 = as.numeric(NA),
      c2 = as.numeric(NA),
      c3 = as.numeric(NA)
    )
    }
  names(old_a) <- c('1.2B', '10G', '3D7-B')
  names(new_a) <- c('A7', 'B11', 'E5')

  new_old_heat_areas <- bind_rows(new_old_heat_areas, old_a)
  new_new_heat_areas <- bind_rows(new_new_heat_areas, new_a)
}
new_old_heat_df <- bind_cols(new_maxdifs %>% select(Gene_id, Variant, Gam_specific, Dupl_Del), new_old_heat_areas)
new_new_heat_df <- bind_cols(new_maxdifs, new_new_heat_areas)

new_old_heat_df <- new_old_heat_df %>%
  rowwise() %>%
  mutate(rwmean_centered_12B = `1.2B` - mean(c(`1.2B`, `10G`, `3D7-B`))) %>%
  mutate(rwmean_centered_10G = `10G` - mean(c(`1.2B`, `10G`, `3D7-B`))) %>%
  mutate(rwmean_centered_3D7B = `3D7-B` - mean(c(`1.2B`, `10G`, `3D7-B`)))

new_new_heat_df <- new_new_heat_df %>%
  rowwise() %>%
  mutate(rwmean_centered_A7 = A7 - mean(c(A7, E5, B11))) %>%
  mutate(rwmean_centered_E5 = E5 - mean(c(A7, E5, B11))) %>%
  mutate(rwmean_centered_B11 = B11 - mean(c(A7, E5, B11)))


new_old_pre_dupl_filtering <- new_old_heat_df
new_new_pre_dupl_filtering <- new_new_heat_df

new_old_heat_df <- new_old_heat_df %>%
  filter(!Dupl_Del)

new_new_heat_df <- new_new_heat_df %>%
  filter(!Dupl_Del)



## Ordering
mtx <- new_new_heat_df %>%
  select(contains('rwmean'))

##Make hierarquical Clustering
dmtx <- dist(scale(mtx), method = "euclidean")
cl <- hclust(dmtx, method = 'average')
new_old_heat_df$Gene_id <- factor(new_old_heat_df$Gene_id, levels = new_old_heat_df$Gene_id[cl$order])
new_new_heat_df$Gene_id <- factor(new_new_heat_df$Gene_id, levels = new_new_heat_df$Gene_id[cl$order])

new_tree <- ggdendrogram(cl, rotate = T)

new_m_infodf <- new_new_heat_df %>%
  select(Gene_id, Variant, Gam_specific) %>%
  gather(variable, value, -Gene_id)

mnew_old_df <- new_old_heat_df %>%
  select(Gene_id, contains('rwmean')) %>%
  gather(variable, value, -Gene_id)

mnew_new_df <- new_new_heat_df %>%
  select(Gene_id, contains('rwmean')) %>%
  gather(variable, value, -Gene_id)

#+end_src
**** Heatmaps
#+begin_src R
## Heatmap function
my_heatmap <- function(m_df){
  p <- ggplot(m_df, aes(x = variable, y = Gene_id, fill = value))
  p <- p + geom_tile(colour="snow3")
  p <- p + theme(
             ##text=element_text(size=24, family="Roboto"),
             legend.position='bottom',
             legend.title = element_blank(),

             panel.background=element_blank(),
             panel.grid.minor=element_blank(),
             plot.background=element_blank(),

             axis.title = element_blank(),
             axis.line.x = element_blank(),
             axis.ticks.x = element_blank(),
             axis.title.x = element_blank()
           )
  return(p)
}

my_areas_heatmap <- function(m_df){
  p <- my_heatmap(m_df)
  p <- p + scale_fill_gradient2(
             low = "#3da4ab",
             high = "#f6cd61",
             mid = 'black',
             na.value="grey",
             )
  return(p)
}

my_info_heatmap <- function(m_df){
  p <- my_heatmap(m_df)
  p <- p + scale_fill_manual(
             values = c('white', '#fe8a71')
           )
  p <- p + theme(
               axis.text.y = element_blank(),
               axis.ticks.y = element_blank(),

               panel.border=element_blank(),
               panel.grid.major=element_blank(),

               strip.background = element_blank(),
               strip.text.x = element_blank(),
               strip.text.y = element_blank(),
             )
  return(p)
}

library(Cairo)
install.packages('Cairo')

## Old maxFC
p_old <- my_areas_heatmap(mold_df)
p_new <- my_areas_heatmap(mnew_df)
i <- my_info_heatmap(old_m_infodf)
whole_plot <- arrangeGrob(p_old, p_new, i, old_tree, nrow = 1, widths = c(2, 2, 1, 1))
plot(whole_plot)
ggsave('./Heatmaps/old_topdif_whole_new.pdf', whole_plot, device = 'pdf')

## New maxFC
p_new <- my_areas_heatmap(mnew_new_df)
p_old <- my_areas_heatmap(mnew_old_df)
i <- my_info_heatmap(new_m_infodf)
whole_plot <- arrangeGrob(p_new, p_old, i, new_tree, nrow = 1, widths = c(2, 2, 1, 1))
plot(whole_plot)
ggsave('./Heatmaps/new_topdif_whole_new.pdf', whole_plot, device = 'pdf')

#+end_src
*** Compare FC genes with B11
#+begin_src R
## Load Old Dif genes
old_fld <- '../Old_Arrays/R_results_OldArrays_Variantome/'
suffix <- '_log2FC2_red15_maxtime.csv'

v12B_10G <- read_csv(paste0(old_fld, '12B_vs_10G', suffix))
v12B_3D7B <- read_csv(paste0(old_fld, '12B_vs_3D7B', suffix))
v10G_3D7B <- read_csv(paste0(old_fld, '10G_vs_3D7B', suffix))

## Load New Dif Genes
new_fld <- '../New_Arrays/R_results_NewArray/'
suffix <- '_log2FC2_red15_maxtime.csv'

vA7_B11 <- read_csv(paste0(new_fld, 'A7_vs_B11', suffix))
vA7_E5 <- read_csv(paste0(new_fld, 'A7_vs_E5', suffix))
vB11_E5 <- read_csv(paste0(new_fld, 'B11_vs_E5', suffix))

## Mix
n <- unique(c(vA7_B11$Gene_id, vB11_E5$Gene_id))
o <- unique(c(v12B_3D7B$Gene_id, v10G_3D7B$Gene_id))
intersect(n,o)


x <- v12B_3D7B %>%
  select(Gene_id, contains('MaxVal')) %>%
  full_join(v10G_3D7B %>% select(Gene_id, contains('MaxVal'))) %>%
  full_join(vA7_B11 %>% select(Gene_id, contains('MaxVal'))) %>%
  full_join(vB11_E5 %>% select(Gene_id, contains('MaxVal')))

x %>%
  filter(Gene_id %in% intersect(n,o)) %>%
  print(n = 100)


info_df %>%
  filter(Gene_id %in% intersect(n,o)) %>%
  select(Gene_id, Name, Annot, Variant, Gam_specific, Family, SubFamily) %>%
  write_csv('similarities_3D7A_B11.csv')
#+end_src
*** 1.2B+10G and B11 commonalities
Since both 1.2B/10G and B11 have truncations in GDV1 we want to analyze those genes differentially expressed in these subclones that go in a same direction.
#+begin_src R
library(tidyverse)

getwd()

## Annot
info_df <- read_csv('./info_df.csv')

## Old arrays
old <- read_csv('../Microarrays/New_Old_separate_approach/Old_Arrays/R_results_OldArrays_Variantome/all_aMAFC.csv')

## New arrays
new <- read_csv('../Microarrays/New_Old_separate_approach/New_Arrays/R_results_NewArray/all_aMAFC.csv')

## Set thresholds
fc_th <- 1 ## FC considered to be a DE gene
dif_th <- 1 ## difference we alow between strains

### Get 3D7B DE genes
old
s3d7b_difs <- old %>%
  filter(abs(`12B-3D7B_MaxVal`) > fc_th | abs(`10G-3D7B_MaxVal`) > fc_th) %>%
  select(Gene_id, `12B-3D7B_MaxVal`, `10G-3D7B_MaxVal`)

s12B10G_3d7b <- s3d7b_difs %>%
  filter(sign(`12B-3D7B_MaxVal`) == sign(`10G-3D7B_MaxVal`)) %>% ## Check for different sign
  rowwise() %>%
  filter(abs(`12B-3D7B_MaxVal` - `10G-3D7B_MaxVal`) < dif_th) %>%
  mutate(Meandif_12B10G_3D7B = mean(c(`12B-3D7B_MaxVal`, `10G-3D7B_MaxVal`))) %>%
  ungroup()

### Get B11 DE genes
b11_difs <- new %>%
  filter(abs(`A7-B11_MaxVal`) > fc_th | abs(`B11-E5_MaxVal`) > fc_th) %>%
  select(Gene_id, `A7-B11_MaxVal`, `B11-E5_MaxVal`)

b11_a7e5 <- b11_difs %>%
  filter(sign(`A7-B11_MaxVal`) != sign(`B11-E5_MaxVal`)) %>% ## Check for different sign
  rowwise() %>%
  filter(abs(sum(`A7-B11_MaxVal`, `B11-E5_MaxVal`)) < dif_th) %>%
  mutate(Meandif_A7E5_B11 = mean(c(`A7-B11_MaxVal`, -`B11-E5_MaxVal`))) %>%
  ungroup()

## Join differences
join_meandifs <- b11_a7e5 %>%
  select(Gene_id, contains('Mean')) %>%
  left_join(s12B10G_3d7b %>% select(Gene_id, contains('Mean')), by = 'Gene_id') %>%
  filter(complete.cases(.))

final_df <- join_meandifs %>%
  filter(sign(Meandif_A7E5_B11) != sign(Meandif_12B10G_3D7B)) %>% ## Check for different sign
  rowwise() %>%
  filter(abs(Meandif_A7E5_B11 + Meandif_12B10G_3D7B) < 1) %>%
  #mutate(Meandif_12B10G_3D7B = mean(c(`12B-3D7B_MaxVal`, `10G-3D7B_MaxVal`))) %>%
  ungroup() %>%
  left_join(info_df, by = 'Gene_id')

final_df

final_df %>%
  write_tsv('B11_12B10G_similarities.tsv')






#+end_src
*** Comparison with GDV1 paper
#+begin_src R
library(readxl)
library(tidyverse)

gdv1_dd <- read_xlsx('./GDV1_del_effects/gdv1_DD_supptable.xlsx')

gdv1_paper <- gdv1_dd %>%
  rename(Gene_id = `Gene Id`, GDV1_paper = `sig. up or down`) %>%
  select(Gene_id, GDV1_paper) %>%
  filter(GDV1_paper %in% c('u', 'd'))

our_list <- read_tsv('./GDV1_del_effects/B11_12B10G_similarities.tsv')

cross_df <- our_list %>%
  left_join(gdv1_paper)

cross_df %>%
  count(GDV1_paper)

cross_df %>%
  filter(!is.na(GDV1_paper)) %>%
  select(Gene_id, contains('Mean'), GDV1_paper, Annot)
#+end_src
* Data Integration
:PROPERTIES:
:header-args:R: :session binned_cov :tangle ./Scripts/binned_coverage.R :results none
:END:
** Imports and dirs
#+begin_src R
#### Imports and Dirs ####

library(ggplot2)
library(tidyverse)
library(readxl)
library(reshape2)
require(gridExtra)
library(readxl)
library(ggh4x)
library(ggrepel)
library(tsne)
library(scales)
library(viridis)
library(cluster)
library(NbClust)
library(factoextra)
library(class)

wd <- '/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/'
setwd(wd)

difpeaks_dir <- '/mnt/Disc4T/Projects/Chip_Seq_Data_2021/BetaFit_DuplDel_Filtered/'

#+end_src
** Load Data
*** Load Gene info
#+begin_src R
info_df <- read_tsv('/mnt/Disc4T/Projects/PhD_Project/Data/PlasmoDB-52_Pfalciparum3D7_parsed_annotation.tsv')

## Flag tRNAs
info_df <- info_df %>%
  mutate(Is_tRNA = grepl('tRNA', Annot, fixed = T) & Type == 'ncRNA_gene')
#+end_src
*** Load Gene lists
#+begin_src R
#### Load gene lists ####
gene_lists <- read_excel('../Microarrays/New_Old_separate_approach/All gene lists_160719.xlsx', sheet = 2)
#+end_src
*** Load gene families data
#+begin_src R
#### Load gene families data ####

gene_fam <- read_excel('./cvgfamilylist/Supplementary_table_2_CVG_list_161120_ap.xlsx', sheet = 2)
gene_fam <- gene_fam %>%
  rename(Gene_id = `Gene ID`,
         Gene_name = `Gene Name or Symbol`,
         SubFamily = `Family Detail`) %>%
  mutate(SubFamily = case_when(SubFamily == 'var pseudo,truncated or -like.' ~ 'var-like',
                               TRUE ~ SubFamily)) %>%
  mutate(Gene_name = ifelse(Gene_name == 'N/A', NA, Gene_name)) %>%
  select(Gene_id, Gene_name, Family, SubFamily)

gene_fam %>%
  filter(Family == 'OTHER') %>%
  mutate(NewFam = case_when(is.na(SubFamily) ~ Gene_name,
                            !is.na(SubFamily) ~ SubFamily))

bigfams <- c(
  'VAR',
  'FIKK',
  'HYP',
  'PHIST',
  'RIFIN',
  'STEVOR',
  'PFMC-2TM'
)


info_df <- info_df %>%
  left_join(gene_fam) %>%
  mutate(Name = ifelse(is.na(Name), Gene_name, Name)) %>%
  mutate(Name = ifelse(is.na(Name) & Family != 'OTHER', Family, Name)) %>%
  mutate(Name = ifelse(Gene_id == 'PF3D7_0935390', 'GDV1as', Name)) %>%
  mutate(Label = ifelse(is.na(Name), Gene_id, paste(Gene_id, Name, sep = ': '))) %>%
  mutate(Family_Grouped = case_when(
           Family %in% bigfams ~ Family,
           !is.na(Family) & !Family %in% bigfams ~ 'Other CVGs',
           is.na(Family) ~ 'Not CVGs'))

table(info_df$Name == info_df$Gene_name)

info_df %>%
  filter(Name != Gene_name) %>%
  select(Gene_id, Name, Gene_name) %>%
  print(n = 40)
#+end_src
*** Load variant genes data
#+begin_src R
#### Load variant genes data ####
cvgs <- read.csv2('../Microarrays/New_Old_separate_approach/New_Arrays/Files/taula_CVG_final.csv', stringsAsFactors = F)
cvgs <- cvgs %>%
  select(Gene_id = Gene.ID, Variant = Final.Customized) %>%
  mutate(Variant = ifelse(Variant == 'YES', TRUE, FALSE))

varlist <- filter(cvgs, Variant) %>% select(Gene_id) %>% pull()

info_df <- info_df %>%
  mutate(Variant = Gene_id %in% varlist)

## Probably Variant
## Some genes are from variant families but we have them as non-variant
info_df %>%
  filter(!Variant & !is.na(Family)) %>%
  select(Gene_id, Annot, Family) %>%
  print(n = 100)

## Check no variant gene has NA Family
info_df %>%
  filter(Variant & is.na(Family))

#+end_src
*** Load Gam genes data
#+begin_src R
gams <- read_csv('../Microarrays/New_Old_separate_approach/Oriol_Suplementary/gam_table.csv') %>%
  select(Gene_id, Gam_specific)

info_df <- info_df %>%
  left_join(gams)
#+end_src
*** Load Dif.Peaks data
#+begin_src R
#### Load Dif.Peaks data ####

get_difpeak_gids <- function(df){
  df <- df %>%
    mutate(Gene_id = na_if(Gene_id, 'intergenic')) %>%
    select(Gene_id) %>%
    drop_na() %>%
    pull() %>%
    unique()
}
add_difpeaks_col <- function(df, strains){
  cn <- c('Chrom', 'Start', 'Stop', 'Peak_id', 'Score', 'Gene_id', 'Annot')
  file_str1 <- paste0(strains[1], '_vs_', strains[2], '_g200_l150_c1_c1.0_cond1_beta_cdf_099_IndelDup_filtered_annotated.csv')
  file_str2 <- paste0(strains[1], '_vs_', strains[2], '_g200_l150_c1_c1.0_cond2_beta_cdf_099_IndelDup_filtered_annotated.csv')
  peaks1 <- read_tsv(paste0(difpeaks_dir, file_str1), cn)
  peaks2 <- read_tsv(paste0(difpeaks_dir,file_str2), cn)
  peaks1 <- get_difpeak_gids(peaks1)
  peaks2 <- get_difpeak_gids(peaks2)
  df %>%
    mutate('Difpeaks_{strains[3]}_{strains[4]}' := Gene_id %in% peaks1 | Gene_id %in% peaks2)
}

strains_list <- list(
  c('1.2B', '10G', '12B', '10G'),
  c('A7K9', 'E5K9', 'A7', 'E5'),
  c('A7K9', 'B11', 'A7', 'B11'),
  c('B11', 'E5K9', 'B11', 'E5')
)

for (strains in strains_list) {info_df <- add_difpeaks_col(info_df, strains)}

## Change B11-E5 to E5-B11
info_df <- info_df %>%
  rename(Difpeaks_E5_B11 = Difpeaks_B11_E5)

write_csv(info_df, 'info_df.csv')

info_df %>%
  select(Gene_id, contains('Difpeaks')) %>%
  count(Difpeaks_E5_B11)
#+end_src
*** Some checks
#+begin_src R
info_df %>%
  count(Family)

novar_family <- info_df %>%
  filter((!Variant & !is.na(Family)) | (Variant & is.na(Family)))

write_csv(novar_family, 'noVariant_with_family.csv')


#+end_src
*** Load transcription data
#+begin_src R
#### Load transcription data ####
trans_df_old <- read_csv('../Microarrays/New_Old_separate_approach/Old_Arrays/R_results_OldArrays_Variantome/final_summary_table.csv')
trans_df_new <- read_csv('../Microarrays/New_Old_separate_approach/New_Arrays/R_results_NewArray/final_summary_table.csv')
trans_df <- full_join(trans_df_old, trans_df_new) %>%
  select(-Name, -Annot, -GamGene)

## Change GDV1as ID from the arrays to new id
trans_df[trans_df$Gene_id == 'PF3D7_0935400_as',]$Gene_id <- 'PF3D7_0935390'

## Subset trans_df to genes that appear on info_df
trans_df <- trans_df %>%
  filter(Gene_id %in% info_df$Gene_id)

trans_df <- trans_df %>%
  mutate(`E5-B11_MaxVal` = -`B11-E5_MaxVal`) %>%
  mutate(`E5-B11_MaxTime` = `B11-E5_MaxTime`) %>%
  select(-`B11-E5_MaxVal`, -`B11-E5_MaxTime`)


## Load Areas Data
arees_old <- read_csv('../Microarrays/New_Old_separate_approach/Old_Arrays/R_results_OldArrays_Variantome/areaDiferences_geneLevel.csv') %>%
  rename(Gene_id = ...1)

arees_new <- read_csv('../Microarrays/New_Old_separate_approach/New_Arrays/R_results_NewArray/areaDiferences_geneLevel.csv') %>%
  rename(Gene_id = ...1)

arees_df <- full_join(arees_old, arees_new)
arees_df[arees_df$Gene_id == 'PF3D7_0935400_as',]$Gene_id <- 'PF3D7_0935390'

## Load Red Percentile Data
red_percent_old <- read_csv('../Microarrays/New_Old_separate_approach/Old_Arrays/R_results_OldArrays_Variantome/red_percentiles.csv')
red_percent_new <- read_csv('../Microarrays/New_Old_separate_approach/New_Arrays/R_results_NewArray/red_percentiles.csv')

red_df <- full_join(red_percent_old, red_percent_new, by = 'Gene_id')
red_df[red_df$Gene_id == 'PF3D7_0935400_as',]$Gene_id <- 'PF3D7_0935390'

red_df

## Load Max-Time data
old_maxtime <- read_csv('/mnt/Disc4T/Projects/PhD_Project/Microarrays/New_Old_separate_approach/Old_Arrays/R_results_OldArrays_Variantome/old_arrays_maxtime.csv')

new_maxtime <- read_csv('/mnt/Disc4T/Projects/PhD_Project/Microarrays/New_Old_separate_approach/New_Arrays/R_results_NewArray/new_arrays_maxtime.csv')


maxtime_df <- full_join(old_maxtime, new_maxtime, by = 'Gene_id', suffix = c('_Old', '_New'))
maxtime_df[maxtime_df$Gene_id == 'PF3D7_0935400_as',]$Gene_id <- 'PF3D7_0935390'


old_breaks <- read_csv('/mnt/Disc4T/Projects/PhD_Project/Microarrays/New_Old_separate_approach/Old_Arrays/R_results_OldArrays_Variantome/old_area_breaks.csv')

new_breaks <- read_csv('/mnt/Disc4T/Projects/PhD_Project/Microarrays/New_Old_separate_approach/New_Arrays/R_results_NewArray/new_area_breaks.csv')

breaks_df <- bind_cols(old_breaks, new_breaks)
colnames(breaks_df) <- c('Old_Area_Breaks', 'New_Area_Breaks')

## Load DuplDel Data
f_path <- '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/Duplication_Deletion_Regions_Mean_Separate_DuplDel/Crossed_with_genes/'
suffix <- '_in_sort_q5_RPKMs_bymean_dupl_del_fact_1.75up_0.1dw_minlen500_mergelen_200_filtered_genes.tsv'
prefix <- c('1.2B', '10G', 'A7K9', 'E5K9', 'B11')

get_dupl_del <- function(prefix){
  fname <- paste0(prefix, suffix)
  df <- read_tsv(paste0(f_path, fname), col_names = F) %>%
    rename(Gene_id = X1, Name = X2, Annot = X3)
}

dupl_del <- lapply(prefix, get_dupl_del)
names(dupl_del) <- prefix
#+end_src
*** Load Coverages
**** Load Coverages: 1000bp+500CDS
#+begin_src R
#### Load heterochromatin data 1000bp+500CDS ####
cov_12b <- read_tsv('./Genewise_Coverages/cov_1000tss_500orf_1.2B.bed', col_names = F)
cov_10g <- read_tsv('./Genewise_Coverages/cov_1000tss_500orf_10G.bed', col_names = F)
#cov_3d7b <- read_tsv('./Genewise_Coverages/cov_1000tss_500orf_3D7.bed', col_names = F)
cov_a7 <- read_tsv('./Genewise_Coverages/cov_1000tss_500orf_A7K9.bed', col_names = F)
cov_e5 <- read_tsv('./Genewise_Coverages/cov_1000tss_500orf_E5K9.bed', col_names = F)
cov_b11 <- read_tsv('./Genewise_Coverages/cov_1000tss_500orf_B11.bed', col_names = F)

join_cols = c('X1', 'X2', 'X3', 'X4')

het_df <- cov_12b %>%
  full_join(cov_10g, by = join_cols) %>%
  #full_join(cov_3d7b, by = join_cols) %>%
  full_join(cov_a7, by = join_cols) %>%
  full_join(cov_e5, by = join_cols) %>%
  full_join(cov_b11, by = join_cols)

colnames(het_df) <- c('Chrom', 'Start', 'Stop', 'Gene_id',
                      'Het_12B', 'Het_10G', 'Het_A7', 'Het_E5', 'Het_B11')

het_df <- het_df %>% select(Gene_id, contains('Het'), everything())

hdf <- het_df %>% select(Gene_id, contains('Het'))
cnames <- str_replace(colnames(hdf), 'Het', 'Cov_1000fp_500orf')
hdf <- hdf %>% set_names(cnames)

#+end_src
**** Load Coverages: 5pORF3p
#+begin_src R
#### Load heterochromatin data 5pORF3p ####
## Load 3prime, ORF, 5prime Coverage

load3ORF5 <- function(cov_5ORF3_file){
  cov_5ORF3 <- read_tsv(cov_5ORF3_file, col_names = F)
  cov_5ORF3 <- cov_5ORF3 %>%
    setNames(c('Chrom', 'Start', 'Stop', 'Gene_id', 'Intensity', 'Strand', 'Cov')) %>%
    select(-Intensity)
  prime5 <- cov_5ORF3 %>% filter(grepl('5prime', fixed = T, Gene_id))
  ORF <- cov_5ORF3 %>% filter(!grepl('5prime', fixed = T, Gene_id) & !grepl('3prime', fixed = T, Gene_id))
  prime3 <- cov_5ORF3 %>% filter(grepl('3prime', fixed = T, Gene_id))
  ORF['Cov_5prime'] <- prime5$Cov
  ORF['Cov_3prime'] <- prime3$Cov
  ORF <- ORF %>% rename(Cov_ORF = Cov)
  return(ORF)
}

e5_5ORF3 <- load3ORF5('./Genewise_Coverages/cov_10005p_orf_10003p_E5K9.bed')
a7_5ORF3 <- load3ORF5('./Genewise_Coverages/cov_10005p_orf_10003p_A7K9.bed')
b11_5ORF3 <- load3ORF5('./Genewise_Coverages/cov_10005p_orf_10003p_B11.bed')
x12b_5ORF3 <- load3ORF5('./Genewise_Coverages/cov_10005p_orf_10003p_1.2B.bed')
x10g_5ORF3 <- load3ORF5('./Genewise_Coverages/cov_10005p_orf_10003p_10G.bed')
#x3d7b_5ORF3 <- load3ORF5('./Genewise_Coverages/cov_10005p_orf_10003p_3D7.bed')

join_cols = c('Chrom', 'Start', 'Stop', 'Gene_id', 'Strand')

cov_5ORF3_df <- x12b_5ORF3 %>%
  full_join(x10g_5ORF3, by = join_cols, suffix = c('_12B', '_10G')) %>%
  #full_join(x3d7b_5ORF3, by = join_cols, suffix = c('', '_3D7B')) %>%
  full_join(a7_5ORF3, by = join_cols, suffix = c('', '_A7')) %>%
  full_join(e5_5ORF3, by = join_cols, suffix = c('', '_E5')) %>%
  full_join(b11_5ORF3, by = join_cols, suffix = c('', '_B11')) %>%
  rename(Cov_ORF_A7 = Cov_ORF, Cov_5prime_A7 = Cov_5prime, Cov_3prime_A7 = Cov_3prime) %>%
  select(all_of(join_cols), contains('5prime'), contains('ORF'), contains('3prime'))

cov_5orf3 <- cov_5ORF3_df %>% select(Gene_id, contains('Cov'))
cnames <- str_replace(colnames(cov_5orf3), '5prime', '1000fp') %>%
  str_replace('ORF', 'allorf') %>%
  str_replace('3prime', '1000tp')
cov_5orf3 <- cov_5orf3 %>% set_names(cnames)
#+end_src
**** Load Coverages: ORF abs-bp
#+begin_src R
#### Load ORF abs-bp Coverages ####

read_abs_orf_cov <- function(strain, len){
  col_names <- c('Chrom', 'Start', 'Stop', 'Gene_id', 'Cov')
  path <- paste0('./Genewise_Coverages/cov_', len, 'orf_allowoverlap_', strain, '.bed')
  df <- read_tsv(path, col_names = col_names) %>%
    select(Gene_id, Cov)
  return(df)
}

cov_500_12B <- read_abs_orf_cov('1.2B', '500')
cov_500_10G <- read_abs_orf_cov('10G', '500')
cov_500_A7 <- read_abs_orf_cov('A7K9', '500')
cov_500_E5 <- read_abs_orf_cov('E5K9', '500')
cov_500_B11 <- read_abs_orf_cov('B11', '500')

cov_1000_12B <- read_abs_orf_cov('1.2B', '1000')
cov_1000_10G <- read_abs_orf_cov('10G', '1000')
cov_1000_A7 <- read_abs_orf_cov('A7K9', '1000')
cov_1000_E5 <- read_abs_orf_cov('E5K9', '1000')
cov_1000_B11 <- read_abs_orf_cov('B11', '1000')

cov_1500_12B <- read_abs_orf_cov('1.2B', '1500')
cov_1500_10G <- read_abs_orf_cov('10G', '1500')
cov_1500_A7 <- read_abs_orf_cov('A7K9', '1500')
cov_1500_E5 <- read_abs_orf_cov('E5K9', '1500')
cov_1500_B11 <- read_abs_orf_cov('B11', '1500')

cov_orf_abs_df <- cov_500_12B %>%
  full_join(cov_500_10G, by = 'Gene_id') %>%
  full_join(cov_500_A7, by = 'Gene_id') %>%
  full_join(cov_500_E5, by = 'Gene_id') %>%
  full_join(cov_500_B11, by = 'Gene_id') %>%

  full_join(cov_1000_12B, by = 'Gene_id') %>%
  full_join(cov_1000_10G, by = 'Gene_id') %>%
  full_join(cov_1000_A7, by = 'Gene_id') %>%
  full_join(cov_1000_E5, by = 'Gene_id') %>%
  full_join(cov_1000_B11, by = 'Gene_id') %>%

  full_join(cov_1500_12B, by = 'Gene_id') %>%
  full_join(cov_1500_10G, by = 'Gene_id') %>%
  full_join(cov_1500_A7, by = 'Gene_id') %>%
  full_join(cov_1500_E5, by = 'Gene_id') %>%
  full_join(cov_1500_B11, by = 'Gene_id') %>%

  set_names('Gene_id',
            'Cov_500orf_12B', 'Cov_500orf_10G', 'Cov_500orf_A7', 'Cov_500orf_E5', 'Cov_500orf_B11',
            'Cov_1000orf_12B', 'Cov_1000orf_10G', 'Cov_1000orf_A7', 'Cov_1000orf_E5', 'Cov_1000orf_B11',
            'Cov_1500orf_12B', 'Cov_1500orf_10G', 'Cov_1500orf_A7', 'Cov_1500orf_E5', 'Cov_1500orf_B11')

cov_orf_abs_df %>%
  filter(!complete.cases(.))


cov_orf_abs_df %>%
  select(contains('12B'))

cov_orf_abs_df %>%
  select(contains('10G'))
#+end_src
**** Load Coverages: Plasmo-DB 51
#+begin_src R
load_pDB <- function(cov_pDB_file){

  col_names <- c('Chrom', 'Start', 'Stop', 'Gene_id', 'Type', 'Cov')
  cov_pDB <- read_tsv(cov_pDB_file, col_names = col_names) %>%
    mutate(Gene_id = str_replace(Gene_id, '.*(PF3D7_\\d{7}).*', '\\1'))

  prime5 <- cov_pDB %>%
    filter(Type == 'five_prime_UTR') %>%
    rename(p5utr_Cov = Cov) %>%
    select(Gene_id, p5utr_Cov)

  prime3 <- cov_pDB %>%
    filter(Type == 'three_prime_UTR') %>%
    rename(p3utr_Cov = Cov) %>%
    select(Gene_id, p3utr_Cov)

  outdf <- prime5 %>%
    full_join(prime3, by = 'Gene_id') %>%
    group_by(Gene_id) %>%
    summarize(p5utr_Cov = mean(p5utr_Cov), p3utr_Cov = mean(p3utr_Cov))

  return(outdf)
}

cov_plasmoDB_12B <- load_pDB('./Genewise_Coverages/cov_plasmoDB_UTRs_1.2B.bed')
cov_plasmoDB_10G <- load_pDB('./Genewise_Coverages/cov_plasmoDB_UTRs_10G.bed')
#cov_plasmoDB_3D7B <- load_pDB('./Genewise_Coverages/cov_plasmoDB_UTRs_3D7.bed')
cov_plasmoDB_A7 <- load_pDB('./Genewise_Coverages/cov_plasmoDB_UTRs_A7K9.bed')
cov_plasmoDB_E5 <- load_pDB('./Genewise_Coverages/cov_plasmoDB_UTRs_E5K9.bed')
cov_plasmoDB_B11 <- load_pDB('./Genewise_Coverages/cov_plasmoDB_UTRs_B11.bed')

cov_pDB_df <- cov_plasmoDB_12B %>%
  full_join(cov_plasmoDB_10G, by = 'Gene_id', suffix = c('_12B', '_10G')) %>%
  #full_join(cov_plasmoDB_3D7B, by = 'Gene_id', suffix = c('', '_3D7B')) %>%
  full_join(cov_plasmoDB_A7, by = 'Gene_id', suffix = c('', '_A7')) %>%
  full_join(cov_plasmoDB_E5, by = 'Gene_id', suffix = c('', '_E5')) %>%
  full_join(cov_plasmoDB_B11, by = 'Gene_id', suffix = c('', '_B11')) %>%
  rename(p5utr_Cov_A7 = p5utr_Cov, p3utr_Cov_A7 = p3utr_Cov)


load_pDB_TSS <- function(cov_pDB_file){
  col_names <- c('Chrom', 'Start', 'Stop', 'Gene_id', 'TSS_Cov')
  cov_pDB <- read_tsv(cov_pDB_file, col_names = col_names) %>%
    mutate(Gene_id = str_replace(Gene_id, '.*(PF3D7_\\d{7}).*', '\\1')) %>%
    select(Gene_id, TSS_Cov) %>%
    group_by(Gene_id) %>%
    summarize(TSS_Cov = mean(TSS_Cov))

  return(cov_pDB)
}

cov_plasmoDB_TSS_12B <- load_pDB_TSS('./Genewise_Coverages/cov_plasmoDB_TSSs_1.2B.bed')
cov_plasmoDB_TSS_10G <- load_pDB_TSS('./Genewise_Coverages/cov_plasmoDB_TSSs_10G.bed')
#cov_plasmoDB_TSS_3D7B <- load_pDB_TSS('./Genewise_Coverages/cov_plasmoDB_TSSs_3D7.bed')
cov_plasmoDB_TSS_A7 <- load_pDB_TSS('./Genewise_Coverages/cov_plasmoDB_TSSs_A7K9.bed')
cov_plasmoDB_TSS_E5 <- load_pDB_TSS('./Genewise_Coverages/cov_plasmoDB_TSSs_E5K9.bed')
cov_plasmoDB_TSS_B11 <- load_pDB_TSS('./Genewise_Coverages/cov_plasmoDB_TSSs_B11.bed')

cov_pDB_TSS_df <- cov_plasmoDB_TSS_12B %>%
  full_join(cov_plasmoDB_TSS_10G, by = 'Gene_id', suffix = c('_12B', '_10G')) %>%
  #full_join(cov_plasmoDB_TSS_3D7B, by = 'Gene_id', suffix = c('', '_3D7B')) %>%
  full_join(cov_plasmoDB_TSS_A7, by = 'Gene_id', suffix = c('', '_A7')) %>%
  full_join(cov_plasmoDB_TSS_E5, by = 'Gene_id', suffix = c('', '_E5')) %>%
  full_join(cov_plasmoDB_TSS_B11, by = 'Gene_id', suffix = c('', '_B11')) %>%
  rename(TSS_Cov_A7 = TSS_Cov)

cov_pDB_df <- cov_pDB_df %>%
  full_join(cov_pDB_TSS_df)
#+end_src
**** Load Coverages: Many-Bin
#+begin_src R
#### Load Many-Bin coverages ####

get_bins <- function(dfin, bin_txt, outcol){
  dfout <- dfin %>% filter(grepl(bin_txt, fixed = T, Gene_id)) %>%
    mutate(Gene_id = str_replace(Gene_id, bin_txt, '')) %>%
    rename(!!outcol := Cov) %>%
    select(Gene_id, Strand, !!outcol)
}

get_manybins <- function(strain){

  fpath <- paste0('./Genewise_Coverages/cov_3ORF5_manybins_allowoverlap_', strain, '.bed')
  cov_5orf3_manybins <- read_tsv(fpath, col_names = F)%>%
    setNames(c('Chrom', 'Start', 'Stop', 'Gene_id', 'Intensity', 'Strand', 'Cov')) %>%
    select(-Intensity)

  cov_2000fp_manybins <- get_bins(cov_5orf3_manybins, '_5prime_2000', 'Cov_2000fp_manybins')
  cov_1500fp_manybins <- get_bins(cov_5orf3_manybins, '_5prime_1500', 'Cov_1500fp_manybins')
  cov_1000fp_manybins <- get_bins(cov_5orf3_manybins, '_5prime_1000', 'Cov_1000fp_manybins')
  cov_500fp_manybins <- get_bins(cov_5orf3_manybins, '_5prime_500', 'Cov_500fp_manybins')
  cov_1qorf_manybins <- get_bins(cov_5orf3_manybins, '_q1', 'Cov_1qorf_manybins')
  cov_2qorf_manybins <- get_bins(cov_5orf3_manybins, '_q2', 'Cov_2qorf_manybins')
  cov_3qorf_manybins <- get_bins(cov_5orf3_manybins, '_q3', 'Cov_3qorf_manybins')
  cov_4qorf_manybins <- get_bins(cov_5orf3_manybins, '_q4', 'Cov_4qorf_manybins')
  cov_1500tp_manybins <- get_bins(cov_5orf3_manybins, '_3prime_1500', 'Cov_1500tp_manybins')
  cov_1000tp_manybins <- get_bins(cov_5orf3_manybins, '_3prime_1000', 'Cov_1000tp_manybins')
  cov_500tp_manybins <- get_bins(cov_5orf3_manybins, '_3prime_500', 'Cov_500tp_manybins')

  join_cols <- c('Strand', 'Gene_id')
  df <- cov_2000fp_manybins %>%
    full_join(cov_1500fp_manybins, by = join_cols) %>%
    full_join(cov_1000fp_manybins, by = join_cols) %>%
    full_join(cov_500fp_manybins, by = join_cols) %>%
    full_join(cov_1qorf_manybins, by = join_cols) %>%
    full_join(cov_2qorf_manybins, by = join_cols) %>%
    full_join(cov_3qorf_manybins, by = join_cols) %>%
    full_join(cov_4qorf_manybins, by = join_cols) %>%
    full_join(cov_1500tp_manybins, by = join_cols) %>%
    full_join(cov_1000tp_manybins, by = join_cols) %>%
    full_join(cov_500tp_manybins, by = join_cols)

  return(df)
}

cov_manybins_12B <- get_manybins('1.2B')
cov_manybins_10G <- get_manybins('10G')
#cov_manybins_3D7B <- get_manybins('3D7')
cov_manybins_A7 <- get_manybins('A7K9')
cov_manybins_E5 <- get_manybins('E5K9')
cov_manybins_B11 <- get_manybins('B11')


## cov_manybins_B11 %>%
##   filter(Gene_id == 'PF3D7_1130800') %>%
##   print(width = 800)


join_cols <- c('Gene_id', 'Strand')
cov_manybins <- cov_manybins_12B %>%
  full_join(cov_manybins_10G, by = join_cols, suffix = c('_12B', '_10G')) %>%
  #full_join(cov_manybins_3D7B, by = join_cols, suffix = c('', '_3D7B')) %>%
  full_join(cov_manybins_A7, by = join_cols, suffix = c('', '_A7')) %>%
  full_join(cov_manybins_E5, by = join_cols, suffix = c('', '_E5')) %>%
  full_join(cov_manybins_B11, by = join_cols, suffix = c('', '_B11')) %>%
  rename(Cov_2000fp_manybins_A7 = Cov_2000fp_manybins,
         Cov_1500fp_manybins_A7 = Cov_1500fp_manybins,
         Cov_1000fp_manybins_A7 = Cov_1000fp_manybins,
         Cov_500fp_manybins_A7 = Cov_500fp_manybins,
         Cov_1qorf_manybins_A7 = Cov_1qorf_manybins,
         Cov_2qorf_manybins_A7 = Cov_2qorf_manybins,
         Cov_3qorf_manybins_A7 = Cov_3qorf_manybins,
         Cov_4qorf_manybins_A7 = Cov_4qorf_manybins,
         Cov_1500tp_manybins_A7 = Cov_1500tp_manybins,
         Cov_1000tp_manybins_A7 = Cov_1000tp_manybins,
         Cov_500tp_manybins_A7 = Cov_500tp_manybins,
         ) %>%
  select(-Strand)

## Convert to numeric
cov_manybins <- cov_manybins %>%
  mutate(across(contains('Cov'), as.numeric))

cov_manybins %>%
  filter(!complete.cases(.))

## get_correlations <- function(strains, trans_filter, difpeaks_filter){
##     df1 <- paste0('cov_manybins_', strains[1])
##     df2 <- paste0('cov_manybins_', strains[2])

##     dif_2000fp_manybins <- get(df1)$Cov_2000fp_manybins - get(df2)$Cov_2000fp_manybins
##     dif_1500fp_manybins <- get(df1)$Cov_1500fp_manybins - get(df2)$Cov_1500fp_manybins
##     dif_1000fp_manybins <- get(df1)$Cov_1000fp_manybins - get(df2)$Cov_1000fp_manybins
##     dif_500fp_manybins <- get(df1)$Cov_500fp_manybins - get(df2)$Cov_500fp_manybins

##     dif_1q_manybins <- get(df1)$Cov_1qorf_manybins - get(df2)$Cov_1qorf_manybins
##     dif_2q_manybins <- get(df1)$Cov_2qorf_manybins - get(df2)$Cov_2qorf_manybins
##     dif_3q_manybins <- get(df1)$Cov_3qorf_manybins - get(df2)$Cov_3qorf_manybins
##     dif_4q_manybins <- get(df1)$Cov_4qorf_manybins - get(df2)$Cov_4qorf_manybins

##     dif_1500tp_manybins <- get(df1)$Cov_1500tp_manybins - get(df2)$Cov_1500tp_manybins
##     dif_1000tp_manybins <- get(df1)$Cov_1000tp_manybins - get(df2)$Cov_1000tp_manybins
##     dif_500tp_manybins <- get(df1)$Cov_500tp_manybins - get(df2)$Cov_500tp_manybins

##     cor_cov_df <- bind_cols(list(
##       Gene_id = get(df1)$Gene_id,
##       dif_2000fp_manybins = dif_2000fp_manybins,
##       dif_1500fp_manybins = dif_1500fp_manybins,
##       dif_1000fp_manybins = dif_1000fp_manybins,
##       dif_500fp_manybins = dif_500fp_manybins,
##       dif_1q_manybins = dif_1q_manybins,
##       dif_2q_manybins = dif_2q_manybins,
##       dif_3q_manybins = dif_3q_manybins,
##       dif_4q_manybins = dif_4q_manybins,
##       dif_1500tp_manybins = dif_1500tp_manybins,
##       dif_1000tp_manybins = dif_1000tp_manybins,
##       dif_500tp_manybins = dif_500tp_manybins
##       ))


##     full_df <- inner_join(cor_cov_df, trans_df, by = 'Gene_id')  %>%
##       left_join(info_df)

##     trans_col <- paste0(strains[1], '-', strains[2], '_MaxVal')
##     difpeaks_col <- paste0('Difpeaks_', strains[1], '_', strains[2])

##     cor_df <- full_df %>%
##       filter(abs(get(trans_col)) > trans_filter) %>%
##       select(Gene_id, matches(trans_col), contains('dif_'))

##     if (difpeaks_filter){df_dif <- df_dif %>% filter(get(difpeaks_col))}

##     cormtx <- cor(cor_df %>% select(-Gene_id) %>% drop_na(), method = 'pearson')
##     print(paste0('Strains: ', strains[1], ' vs ', strains[2]))
##     print(paste0('Number of genes: ', dim(cor_df)[1]))
##     print(cormtx)
##     print('+++++++++++++++++++++++++++++++++++++++++++++++')
##     outdf <- as.data.frame(cormtx)
##     outdf['Corr_with'] <- rownames(outdf)
##     outdf <- outdf %>% select(Corr_with, everything())
##     outname = paste0('corr_', strains[1], '_', strains[2], '_transth_', trans_filter, '_difpeaks_', difpeaks_filter, '.csv')
##     write_csv(outdf, file = outname)
## }

## tf <- 1.5
## df <- FALSE

## contrasts <- list(
##   c('12B', '10G'),
##   c('A7', 'E5'),
##   c('A7', 'B11'),
##   c('B11', 'E5')
## )

## for (c in contrasts) {get_correlations(c, tf, df)}


## Don't, computer can't handle it!


#+end_src
**** Load Coverages: Abs ORF
#+begin_src R
load_abs_ORF <- function(cov_abs_orf_file){
  cov_abs_ORF <- read_tsv(cov_abs_orf_file, col_names = F)
  cov_abs_ORF <- cov_abs_ORF %>%
    setNames(c('Chrom', 'Start', 'Stop', 'Gene_id', 'Intensity', 'Strand', 'Cov')) %>%
    select(-Intensity)
  ORF <- cov_abs_ORF %>%
    filter(!grepl('5prime', fixed = T, Gene_id) & !grepl('3prime', fixed = T, Gene_id))
  ORF <- ORF %>%
    rename(Cov_ORF = Cov) %>%
    mutate(Cov_ORF = as.double(Cov_ORF)) %>%
    select(Gene_id, Cov_ORF)
  return(ORF)
}

abs_ORF_500_12B <- load_abs_ORF('./Genewise_Coverages/cov_abs_ORF_0_500_1.2B.bed')
abs_ORF_500_10G <- load_abs_ORF('./Genewise_Coverages/cov_abs_ORF_0_500_10G.bed')
abs_ORF_500_A7 <- load_abs_ORF('./Genewise_Coverages/cov_abs_ORF_0_500_A7K9.bed')
abs_ORF_500_E5 <- load_abs_ORF('./Genewise_Coverages/cov_abs_ORF_0_500_E5K9.bed')
abs_ORF_500_B11 <- load_abs_ORF('./Genewise_Coverages/cov_abs_ORF_0_500_B11.bed')

abs_ORF_1000_12B <- load_abs_ORF('./Genewise_Coverages/cov_abs_ORF_500_1000_1.2B.bed')
abs_ORF_1000_10G <- load_abs_ORF('./Genewise_Coverages/cov_abs_ORF_500_1000_10G.bed')
abs_ORF_1000_A7 <- load_abs_ORF('./Genewise_Coverages/cov_abs_ORF_500_1000_A7K9.bed')
abs_ORF_1000_E5 <- load_abs_ORF('./Genewise_Coverages/cov_abs_ORF_500_1000_E5K9.bed')
abs_ORF_1000_B11 <- load_abs_ORF('./Genewise_Coverages/cov_abs_ORF_500_1000_B11.bed')

abs_ORF_1500_12B <- load_abs_ORF('./Genewise_Coverages/cov_abs_ORF_1000_1500_1.2B.bed')
abs_ORF_1500_10G <- load_abs_ORF('./Genewise_Coverages/cov_abs_ORF_1000_1500_10G.bed')
abs_ORF_1500_A7 <- load_abs_ORF('./Genewise_Coverages/cov_abs_ORF_1000_1500_A7K9.bed')
abs_ORF_1500_E5 <- load_abs_ORF('./Genewise_Coverages/cov_abs_ORF_1000_1500_E5K9.bed')
abs_ORF_1500_B11 <- load_abs_ORF('./Genewise_Coverages/cov_abs_ORF_1000_1500_B11.bed')

join_cols = c('Gene_id')

cov_abs_ORF <- abs_ORF_500_12B %>%
  full_join(abs_ORF_500_10G, by = join_cols, suffix = c('_0_500_12B', '_0_500_10G')) %>%
  full_join(abs_ORF_500_A7, by = join_cols, suffix = c('', '_0_500_A7')) %>%
  full_join(abs_ORF_500_E5, by = join_cols, suffix = c('', '_0_500_E5')) %>%
  full_join(abs_ORF_500_B11, by = join_cols, suffix = c('', '_0_500_B11')) %>%

  full_join(abs_ORF_1000_12B, by = join_cols, suffix = c('', '_500_1000_12B')) %>%
  full_join(abs_ORF_1000_10G, by = join_cols, suffix = c('', '_500_1000_10G')) %>%
  full_join(abs_ORF_1000_A7, by = join_cols, suffix = c('', '_500_1000_A7')) %>%
  full_join(abs_ORF_1000_E5, by = join_cols, suffix = c('', '_500_1000_E5')) %>%
  full_join(abs_ORF_1000_B11, by = join_cols, suffix = c('', '_500_1000_B11')) %>%

  full_join(abs_ORF_1500_12B, by = join_cols, suffix = c('', '_1000_1500_12B')) %>%
  full_join(abs_ORF_1500_10G, by = join_cols, suffix = c('', '_1000_1500_10G')) %>%
  full_join(abs_ORF_1500_A7, by = join_cols, suffix = c('', '_1000_1500_A7')) %>%
  full_join(abs_ORF_1500_E5, by = join_cols, suffix = c('', '_1000_1500_E5')) %>%
  full_join(abs_ORF_1500_B11, by = join_cols, suffix = c('', '_1000_1500_B11')) %>%

  rename(Cov_ORF_0_500_A7 = Cov_ORF) %>%
  select(Gene_id, contains('Cov_'))
#+end_src
*** Create Custom Color Palette
#+begin_src R
## Create 'fixed' color palette
col_factor <- factor(unique(info_df$Family_Grouped),
                     levels=c('Not CVGs',
                              'Other CVGs',
                              'FIKK',
                              'HYP',
                              'PHIST',
                              'STEVOR',
                              'RIFIN',
                              'VAR',
                              'PFMC-2TM'))

my_colors <- c('gray', scales::viridis_pal(begin = 0, end = 1)(8))
names(my_colors) <- levels(col_factor)
my_scale <- scale_fill_manual(name = "Family_Grouped", values = my_colors)
#+end_src
** Join all Coverages
#+begin_src R
cor_cov_df <- cov_orf_abs_df %>%
  full_join(hdf, by = 'Gene_id') %>%
  full_join(cov_5orf3, by = 'Gene_id') %>%
  full_join(cov_pDB_df, by = 'Gene_id') %>%
  full_join(cov_manybins, by = 'Gene_id') %>%
  full_join(cov_abs_ORF, by = 'Gene_id')

positive_cov_df <- cor_cov_df %>%
  mutate(across(-Gene_id, ~ ifelse(.x > 0, .x, 0)))

full_df <- inner_join(cor_cov_df, trans_df)  %>%
  left_join(info_df)


#+end_src
** Correlations
*** Correlations
#+begin_src R
#### Correlations ####

get_cor_mtx <- function(df, contrast, trans_filter, difpeaks_filter){

  ## contrast <- c('12B', '10G')
  ## df <- full_df

  trans_col <- paste0(contrast[1], '-', contrast[2], '_MaxVal')
  difpeaks_col <- paste0('Difpeaks_', contrast[1], '_', contrast[2])


  ## df %>%
  ##   select(contains('Cov_ORF_'))

  df_dif <- df %>%
  ## Absolute bp ORF
    mutate(Cov_500orf_Dif = get(paste0('Cov_500orf_', contrast[1])) - get(paste0('Cov_500orf_', contrast[2]))) %>%
    mutate(Cov_1000orf_Dif = get(paste0('Cov_1000orf_', contrast[1])) - get(paste0('Cov_1000orf_', contrast[2]))) %>%
    mutate(Cov_1500orf_Dif = get(paste0('Cov_1500orf_', contrast[1])) - get(paste0('Cov_1500orf_', contrast[2]))) %>%

  ## Absolute bp ORF, by interval
    mutate(Cov_0_500orf_Dif = get(paste0('Cov_ORF_0_500_', contrast[1])) - get(paste0('Cov_ORF_0_500_', contrast[2]))) %>%
    mutate(Cov_500_1000orf_Dif = get(paste0('Cov_ORF_500_1000_', contrast[1])) - get(paste0('Cov_ORF_500_1000_', contrast[2]))) %>%
    mutate(Cov_1000_1500orf_Dif = get(paste0('Cov_ORF_1000_1500_', contrast[1])) - get(paste0('Cov_ORF_1000_1500_', contrast[2]))) %>%

  ## 100bp 5prime + 500bp ORF
    mutate(Cov_1000fp_500orf_Dif = get(paste0('Cov_1000fp_500orf_', contrast[1])) - get(paste0('Cov_1000fp_500orf_', contrast[2]))) %>%

  ## 100bp 5prime/ ORF / 1000bp 3prime
    mutate(Cov_1000fp_Dif = get(paste0('Cov_1000fp_', contrast[1])) - get(paste0('Cov_1000fp_', contrast[2]))) %>%
    mutate(Cov_allorf_Dif = get(paste0('Cov_allorf_', contrast[1])) - get(paste0('Cov_allorf_', contrast[2]))) %>%
    mutate(Cov_1000tp_Dif = get(paste0('Cov_1000tp_', contrast[1])) - get(paste0('Cov_1000tp_', contrast[2]))) %>%

  ## PlsmoDB 5prime and TSS
    mutate(Cov_plasmoDB_5p_Dif = get(paste0('p5utr_Cov_', contrast[1])) - get(paste0('p5utr_Cov_', contrast[2]))) %>%
    mutate(Cov_plasmoDB_TSS_Dif = get(paste0('TSS_Cov_', contrast[1])) - get(paste0('TSS_Cov_', contrast[2]))) %>%
    mutate(Cov_plasmoDB_3p_Dif = get(paste0('p3utr_Cov_', contrast[1])) - get(paste0('p3utr_Cov_', contrast[2]))) %>%

  ## Manybins (2000, 1500, 1000, 500, 1q, 2q, 3q, 4q, 500, 1000, 1500)
    mutate(Cov_2000fp_manybins_Dif = get(paste0('Cov_2000fp_manybins_', contrast[1])) - get(paste0('Cov_2000fp_manybins_', contrast[2]))) %>%
    mutate(Cov_1500fp_manybins_Dif = get(paste0('Cov_1500fp_manybins_', contrast[1]))  - get(paste0('Cov_1500fp_manybins_', contrast[2]))) %>%
    mutate(Cov_1000fp_manybins_Dif = get(paste0('Cov_1000fp_manybins_', contrast[1])) - get(paste0('Cov_1000fp_manybins_', contrast[2]))) %>%
    mutate(Cov_500fp_manybins_Dif = get(paste0('Cov_500fp_manybins_', contrast[1]))- get(paste0('Cov_500fp_manybins_', contrast[2]))) %>%

    mutate(Cov_1qorf_manybins_Dif = get(paste0('Cov_1qorf_manybins_', contrast[1])) - get(paste0('Cov_1qorf_manybins_', contrast[2]))) %>%
    mutate(Cov_2qorf_manybins_Dif = get(paste0('Cov_2qorf_manybins_', contrast[1]))  - get(paste0('Cov_2qorf_manybins_', contrast[2]))) %>%
    mutate(Cov_3qorf_manybins_Dif = get(paste0('Cov_3qorf_manybins_', contrast[1])) - get(paste0('Cov_3qorf_manybins_', contrast[2]))) %>%
    mutate(Cov_4qorf_manybins_Dif = get(paste0('Cov_4qorf_manybins_', contrast[1]))- get(paste0('Cov_4qorf_manybins_', contrast[2]))) %>%

    mutate(Cov_1500tp_manybins_Dif = get(paste0('Cov_1500tp_manybins_', contrast[1]))  - get(paste0('Cov_1500tp_manybins_', contrast[2]))) %>%
    mutate(Cov_1000tp_manybins_Dif = get(paste0('Cov_1000tp_manybins_', contrast[1])) - get(paste0('Cov_1000tp_manybins_', contrast[2]))) %>%
    mutate(Cov_500tp_manybins_Dif = get(paste0('Cov_500tp_manybins_', contrast[1]))- get(paste0('Cov_500tp_manybins_', contrast[2]))) %>%

    filter(abs(get(trans_col)) > trans_filter) %>%
    select(Gene_id, matches(trans_col), contains('_Dif'))

  ## df_dif %>%
  ##   select(Gene_id, Cov_0_500orf_Dif, Cov_500_1000orf_Dif, Cov_1000_1500orf_Dif) %>%
  ##   summary()

  ## table(df_dif$Cov_500_1000orf_Dif)

  if (difpeaks_filter){df_dif <- df_dif %>% filter(get(difpeaks_col))}

  cormtx <- cor(df_dif %>% select(-Gene_id) %>% drop_na(), method = 'pearson')
  print(paste0('Contrast ', contrast[1], ' vs ', contrast[2]))
  print(paste0('Number of genes: ', dim(df_dif %>% select(-Gene_id) %>% drop_na())[1]))
  print(as.data.frame(cormtx[,1]))
  print('+++++++++++++++++++++++++++++')

  outdf <- as.data.frame(cormtx)
  outdf['Corr_with'] <- rownames(outdf)
  outdf <- outdf %>% select(Corr_with, everything())
  outname = paste0('corr_ALL_', contrast[1], '_', contrast[2],
                   '_transth_', trans_filter, '_difpeaks_', difpeaks_filter, '.csv')
  write_csv(outdf, file = outname)
}

contrasts <- list(
  c('12B', '10G'),
  c('A7', 'E5'),
  c('A7', 'B11'),
  c('E5', 'B11')
)

trans_filter <- 0
difpeaks_filter <- F

for (contrast in contrasts) {get_cor_mtx(full_df, contrast, trans_filter, difpeaks_filter)}

cor_12B_10G <- get_cor_mtx(full_df, c('12B', '10G'), trans_filter, difpeaks_filter)
cor_A7_E5 <- get_cor_mtx(full_df, c('A7', 'E5'), trans_filter, difpeaks_filter)
cor_A7_B11 <- get_cor_mtx(full_df, c('A7', 'B11'), trans_filter, difpeaks_filter)
cor_B11_E5 <- get_cor_mtx(full_df, c('E5', 'B11'), trans_filter, difpeaks_filter)

all_Corr <- bind_cols(Corr_With = cor_12B_10G[-1,1],
                      Cor_12B_10G = cor_12B_10G[-1,2],
                      Cor_A7_E5 = cor_A7_E5[-1,2],
                      Cor_A7_B11 = cor_A7_B11[-1,2],
                      Cor_B11_E5 = cor_B11_E5[-1,2])

write_csv(all_Corr, file = paste0('./Correlations_transth_', trans_filter, '_allowoverlaps.csv'))

#+end_src
*** Correlation Plots 5p/ORF/3p
#+begin_src R
#### Correlation Plots ####

myCorPlot <- function(df, region, s1, s2, trans_th){

  df <- plot_5ORF3_df

  trans <- paste0(s1,'-',s2,'_MaxVal')
  difpeak <- paste0('Difpeaks_', s1, '_', s2)
  title_str <- paste0(s1, ' vs ', s2)
  outfile <- paste0('./Plots/corplot_', s1, '_', s2, '_', region, '.png')

  plot_df <- df %>%
    mutate(Dif_het = get(paste0('Cov_', region, '_', s1)) - get(paste0('Cov_', region, '_', s2))) %>%
    select(Gene_id, matches(trans), Dif_het, matches(difpeak)) %>%
    setNames(c('Gene_id', 'Trans', 'Het', 'Difpeak')) %>%
    filter(abs(Trans) > trans_th)

  p <- ggplot(plot_df, aes(x=Het,
                           y=Trans)) +
    scale_alpha_discrete(range = c(0.2, 1)) +
    ggtitle(title_str) +
    ylab('aMAFC') +
    xlab(paste0('Heterochromatin difference at ', region)) +
    geom_point()
  ggsave(outfile, p, device = 'png')
  print(p)
}

plot_5ORF3_df <- inner_join(cov_5ORF3_df, trans_df)  %>%
  left_join(info_df)

regions <- c('5prime', 'ORF', '3prime')

contrasts <- list(
  c('12B', '10G'),
  c('A7', 'E5'),
  c('A7', 'B11'),
  c('E5', 'B11')
)

## ## Call corr plots for 5p/ORF/3p coverage
## for (region in regions){
##   for (contrast in contrasts){
##     s1 <- contrast[1]
##     s2 <- contrast[2]
##     trans_th <- 0
##     myCorPlot(plot_5ORF3_df, region, s1, s2, trans_th)
##   }
## }

region <- 'ORF'
s1 <- 'A7'
s2 <- 'B11'
trans_th <- 1
myCorPlot(plot_5ORF3_df, region, s1, s2, trans_th)
#+end_src
*** Correlation Plots All Coverages
#+begin_src R
#### Correlation Plots ####

myCorPlot_all <- function(df, region, s1, s2, trans_th){

  trans <- paste0(s1,'-',s2,'_MaxVal')
  difpeak <- paste0('Difpeaks_', s1, '_', s2)
  title_str <- paste0(s1, ' vs ', s2)
  outfile <- paste0('./Plots/Strain_Corr/corplot_',
                    s1, '_', s2, '_', region,
                    'transth_', trans_th,
                    '.png')

  plot_df <- df %>%
    mutate(Dif_het = get(paste0(region, s1)) - get(paste0(region, s2))) %>%
    select(Gene_id, matches(trans), Dif_het, matches(difpeak)) %>%
    setNames(c('Gene_id', 'Trans', 'Het', 'Difpeak')) %>%
    filter(abs(Trans) > trans_th)

  p <- ggplot(plot_df, aes(x=Het,
                      y=Trans,
                      color = Difpeak,
                      alpha = Difpeak)) +
    scale_alpha_discrete(range = c(0.2, 1)) +
    ggtitle(title_str) +
    ylab('aMAFC') +
    xlab(paste0('Heterochromatin difference at ', region)) +
    geom_point()
  ggsave(outfile, p, device = 'png')
  print(p)
}

## Make plots for all strains and coverages
cnms <- str_replace(colnames(full_df %>% select(contains('Cov') & contains('12B'))), '12B', '')

contrasts <- list(
  c('12B', '10G'),
  c('A7', 'E5'),
  c('A7', 'B11'),
  c('E5', 'B11')
)

## ## Plot correlations for all Coverages
## for (c in cnms){
##   for (contrast in contrasts){
##     s1 <- contrast[1]
##     s2 <- contrast[2]
##     trans_th <- 1
##     myCorPlot_all(full_df, c, s1, s2, trans_th)
##   }
## }

region <- 'Cov_allorf_'
s1 <- 'A7'
s2 <- 'E5'
trans_th <- 1
myCorPlot_all(full_df, region, s1, s2, trans_th)
#+end_src
** Contingency table association measure
The idea is to use a contingency table with categorical variables with 3 values each:
- Heterochromatin difference: Positive, Negative, None.
- Transcriptional difference: Positive, Negative, None.
(This way we do not need data to be linearly correlated)
#+begin_src R
hist(cor_cov_df$Cov_500orf_12B - cor_cov_df$Cov_500orf_10G, breaks = 500)
hist(cor_cov_df$Cov_500orf_12B - cor_cov_df$Cov_500orf_A7, breaks = 500)
hist(cor_cov_df$Cov_500orf_A7 - cor_cov_df$Cov_500orf_B11, breaks = 500)

x <- positive_cov_df %>%
  filter(across(contains('Cov')) != 0)

hist(x$Cov_500orf_12B - x$Cov_500orf_10G, breaks = 5000)
hist(x$Cov_500orf_12B - x$Cov_500orf_A7, breaks = 5000)
hist(x$Cov_500orf_A7 - x$Cov_500orf_B11, breaks = 5000)

## General Approach

chi_sqared_aproach <- function(contrast, hetdif_th, transdif_th, cov_col){

  ## cat('\n##########################\n')

  ## header <- paste0(
  ##   'Calculating Chi-Sqared for: ',
  ##   cov_col, ' in ',
  ##   contrast[1], ' vs ', contrast[2]
  ## )
  ## print(header)

  trans_col <- paste0(contrast[1], '-', contrast[2], '_MaxVal')

  hetdif_df <- positive_cov_df %>%
    mutate(het_dif = get(paste0(cov_col, contrast[1])) - get(paste0(cov_col, contrast[2]))) %>%
    select(Gene_id, het_dif)

  transdif_df <- trans_df %>%
    rename(trans_dif = matches(trans_col)) %>%
    select(Gene_id, trans_dif)

  final_df <- hetdif_df %>%
    inner_join(transdif_df) %>%
    filter(complete.cases(.)) %>%
    #filter(abs(het_dif) > hetdif_th) %>%
    filter(abs(trans_dif) > transdif_th) %>%
    mutate(logical_het = ifelse(het_dif > 0, 'Positive', 'Negative')) %>%
    mutate(logical_het = ifelse(abs(het_dif) > hetdif_th, logical_het, 'Neutral')) %>%
    mutate(logical_trans = ifelse(trans_dif > 0, 'Positive', 'Negative'))
    #mutate(logical_trans = ifelse(abs(trans_dif) > transdif_th, logical_trans, 'Neutral'))

  ngenes <- dim(final_df)[1]
  ## print(paste0('Number of genes: ', as.character(ngenes)))

  cont_table <- table(
    final_df$logical_het,
    final_df$logical_trans,
    dnn = c('Het_dif', 'Trans_dif')
  )

  ## print(cont_table)

  chisq <- chisq.test(cont_table)
  ## print(chisq)

  frac_stat <- (cont_table[1,2] + cont_table[3,1]) / sum(cont_table)
  ## print(paste0('Custom fraction stat: ', as.character(frac_stat)))
  ## cat('\n##########################\n\n\n\n')

  return(list(
    pval = chisq$p.value,
    frac_stat = frac_stat,
    ngenes = ngenes,
    ##table = cont_table
    het_neg_trans_neg = cont_table[1,1],
    het_neut_trans_neg = cont_table[2,1],
    het_pos_trans_neg = cont_table[3,1],
    het_neg_trans_pos = cont_table[1,2],
    het_neut_trans_pos = cont_table[2,2],
    het_pos_trans_pos = cont_table[3,2]
    ))
}

## Manual 1 contrast 1 coverage column

contrast <- c('12B', '10G')
hetdif_th <- 0.5
transdif_th <- 1
cov_col <- 'Cov_500orf_'

chi_sqared_aproach(contrast, hetdif_th, transdif_th, cov_col)

cov_cols <- unique(sapply(colnames(positive_cov_df), function(x) gsub('12B|10G|A7|E5|B11', '', x)))
cov_cols <- cov_cols[2:length(cov_cols)]

## Create tables by strain

hetdif_th <- 0
transdif_th <- 1

contrasts <- list(
  c('12B', '10G'),
  c('A7', 'E5'),
  c('A7', 'B11'),
  c('E5', 'B11')
)

for (contrast in contrasts){

  xsq_l <- lapply(cov_cols, function(x) chi_sqared_aproach(contrast, hetdif_th, transdif_th, x))
  xsq_df <- tibble(xsq_l) %>%
    unnest_wider(xsq_l) %>%
    mutate(Cov_col = cov_cols) %>%
    select(Cov_col, everything())

  str_contrast <- paste(contrast[1], contrast[2], sep = '_')
  outname <- paste0(
    './Contingency_Table_Corr/xsquared_',
    str_contrast,
    '_transth_', as.character(transdif_th),
    '_hetth_', as.character(hetdif_th),
    '.tsv')
  write_tsv(xsq_df, outname)
}

xsq_df <- as.data.frame(t(xsq_df))
xsq_df['Cov_Col'] <- rownames(xsq_df)
as_tibble(xsq_df)

## Create Table for Pval and Frac_Stat for all strains together
hetdif_th <- 0.5
transdif_th <- 1

pvals_12B_10G <- sapply(cov_cols, function(x) chi_sqared_aproach(c('12B', '10G'), hetdif_th, transdif_th, x)$pval)
fracstats_12B_10G <- sapply(cov_cols, function(x) chi_sqared_aproach(c('12B', '10G'), hetdif_th, transdif_th, x)$frac_stat)

pvals_A7_E5 <- sapply(cov_cols, function(x) chi_sqared_aproach(c('A7', 'E5'), hetdif_th, transdif_th, x)$pval)
fracstats_A7_E5 <- sapply(cov_cols, function(x) chi_sqared_aproach(c('A7', 'E5'), hetdif_th, transdif_th, x)$frac_stat)

pvals_A7_B11 <- sapply(cov_cols, function(x) chi_sqared_aproach(c('A7', 'B11'), hetdif_th, transdif_th, x)$pval)
fracstats_A7_B11 <- sapply(cov_cols, function(x) chi_sqared_aproach(c('A7', 'B11'), hetdif_th, transdif_th, x)$frac_stat)

pvals_E5_B11 <- sapply(cov_cols, function(x) chi_sqared_aproach(c('E5', 'B11'), hetdif_th, transdif_th, x)$pval)
fracstats_E5_B11 <- sapply(cov_cols, function(x) chi_sqared_aproach(c('E5', 'B11'), hetdif_th, transdif_th, x)$frac_stat)

contingency_results <- tibble(
  Cov_Col = names(pvals_12B_10G),
  Pvals_12B_10G = pvals_12B_10G,
  Pvals_A7_E5 = pvals_A7_E5,
  Pvals_A7_B11 = pvals_A7_B11,
  Pvals_E5_B11 = pvals_E5_B11,

  Frac_12B_10G = fracstats_12B_10G,
  Frac_A7_E5 = fracstats_A7_E5,
  Frac_A7_B11 = fracstats_A7_B11,
  Frac_E5_B11 = fracstats_E5_B11) %>%
  print(n = 2000)

write_tsv(contingency_results, './Contingency_Table_Corr/contingency_aproach_results.tsv')
#+end_src
** Heat-map Functions
#+begin_src R
#### Heatmap Funtions ####

myHeatmap <- function(df, family_facet){
  p <- ggplot(df, aes(x = variable, y = Label, fill = value)) +
    geom_tile(colour="snow3") +
    theme(
      text=element_text(size=24),

      legend.position='bottom',
      legend.title = element_blank(),

      panel.background=element_blank(),
      panel.grid.minor=element_blank(),
      plot.background=element_blank(),

      axis.title = element_blank(),
      axis.line.x = element_blank(),
      axis.ticks.x = element_blank(),
      axis.title.x = element_blank()
    )
  if (family_facet){p <- p+facet_grid(Family ~., scales = "free_y", space = "free")}
  return(p)
}
hetHeatmap <- function(df, family_facet){
  p <- myHeatmap(df, family_facet)
  p <- p + scale_fill_gradient(low = "white",
                               high = "orange",
                               na.value="white",
                               limits = c(0,NA)) +
    scale_y_discrete(position = "right") +
    theme(
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),

      panel.border=element_blank(),
      panel.grid.major=element_blank(),

      strip.background = element_blank(),
      strip.text.x = element_blank(),
      strip.text.y = element_blank(),
    )
  return(p)
}
hetDifHeatmap <- function(df, family_facet){
  p <- myHeatmap(df, family_facet)
  p <- p + scale_fill_gradient2(low = "chartreuse3",
                                mid = "white",
                                high = "darkred",
                                na.value="grey90") +
    scale_y_discrete(position = "left") +
    theme(
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),

      panel.border=element_blank(),
      panel.grid.major=element_blank(),

      strip.background = element_blank(),
      strip.text.x = element_blank(),
      strip.text.y = element_blank(),
    )
  return(p)
}
transHeatmap <- function(df, family_facet){
  p <- myHeatmap(df, family_facet)
  p <- p + scale_fill_gradient2(low = "#536DFE",
                                mid = "white",
                                high = "yellow2",
                                na.value="grey90") +
    scale_y_discrete(position = "left") +
    theme(
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),

      panel.border=element_blank(),
      panel.grid.major=element_blank(),

      strip.background = element_blank(),
      strip.text.x = element_blank(),
      strip.text.y = element_blank(),
      )
  return(p)
}

family_heatmap <- function(mdf){
  p <- myHeatmap(mdf, family_facet)
  ##p <- p + geom_text(aes(label=Label))
  p <- p + my_scale
  p <- p + scale_y_discrete(limits=(rev(levels(mdf$Label))))
  p <- p + theme(
             axis.text.x = element_blank(),
             axis.text.y = element_blank(),
             axis.ticks.y = element_blank(),

             panel.border=element_blank(),
             panel.grid.major=element_blank(),

             strip.background = element_blank(),
             strip.text.x = element_blank(),
             strip.text.y = element_blank()
           )
  return(p)
}
#+end_src
** A first plot
#+begin_src R
#### A first plot ####

trans_het_df <- trans_df %>%
  left_join(het_df, by = 'Gene_id') %>%
  left_join(info_df, by = 'Gene_id')

e5_b11 <- trans_het_df %>%
  mutate(Het_dif = Het_E5 - Het_B11) %>%
  filter(abs(`E5-B11_MaxVal`) > 1 & abs(Het_dif) > 0) %>%
  arrange(desc(`E5-B11_MaxVal`)) %>%
  mutate(Label = factor(Label, levels = Label))

df_e5_b11_trans <- e5_b11 %>%
  select(Gene_id, `E5-B11_MaxVal`, Annot, Family, SubFamily, Label)

df_e5_b11_het <- e5_b11 %>%
  select(Gene_id, Het_dif, Het_B11, Het_E5, Annot, Family, SubFamily, Label)


mdf_e5_b11_het <- melt(df_e5_b11_het, id.vars = c('Gene_id', 'Annot', 'Family', 'SubFamily', 'Label'))
mdf_e5_b11_trans <- melt(df_e5_b11_trans, id.vars = c('Gene_id', 'Annot', 'Family', 'SubFamily', 'Label'))

family_facet <- FALSE

het_plot <- hetHeatmap(mdf_e5_b11_het, family_facet)
trans_plot <- transHeatmap(mdf_e5_b11_trans, family_facet)
all_plot <- grid.arrange(trans_plot, het_plot, nrow = 1, widths = c(1,3))
#+end_src
** General Plots
#+begin_src R
#### General Plots ####

all_transcov_df <- trans_df %>%
  left_join(positive_cov_df, by = 'Gene_id') %>%
  left_join(info_df, by = 'Gene_id')

finalHeatmap <- function(contrast, het_col, abs_trans_filter, abs_het_filter, family, family_facet) {

  trans_col <- paste0(contrast[1], '-', contrast[2], '_MaxVal')
  het_col_1 <- paste0(het_col, '_', contrast[1])
  het_col_2 <- paste0(het_col, '_', contrast[2])

  subset_all <- all_transcov_df %>%
    mutate(Het_dif = get(het_col_1) - get(het_col_2)) %>%
    filter(abs(get(trans_col)) > abs_trans_filter &
           (abs(Het_dif) > abs_het_filter | is.na(Het_dif))) %>%
    select(Gene_id,
           matches(trans_col),
           matches(het_col_1),
           matches(het_col_2),
           Het_dif,
           Label, Name, Annot, Family, SubFamily
           )

  ## Subset by family is needed
  if (!is.na(family)){
    subset_all <- subset_all %>%
      filter(Family == family)
  }

  ## Ordering
  if (sorting == 'clust') {
    mtx <- subset_all %>%
      select(where(is.numeric))

    ## Make hierarquical Clustering
    dmtx <- dist(scale(mtx), method = "euclidean")
    cl <- hclust(dmtx, method = 'average')
    subset_all$Label <- factor(subset_all$Label, levels = subset_all$Label[cl$order])

  } else if (sorting == 'trans') {
    subset_all <- subset_all %>%
      arrange(desc(get(trans_col))) %>%
      mutate(Label = factor(Label, levels = Label))

  } else if (sorting == 'het') {
    subset_all <- subset_all %>%
      arrange(desc(Het_dif)) %>%
      mutate(Label = factor(Label, levels = Label))
  }

  subset_trans <- subset_all %>%
    select(Gene_id, matches(trans_col), Label, Name, Annot, Family, SubFamily)

  subset_het <- subset_all %>%
    select(Gene_id, matches(het_col_1), matches(het_col_2), Label, Name, Annot, Family, SubFamily)

  subset_het %>%
    print(width = 200)

  subset_hetDif <- subset_all %>%
    select(Gene_id, Het_dif, Label, Name, Annot, Family, SubFamily)

  melt_vars <- c('Gene_id', 'Label', 'Name', 'Annot', 'Family', 'SubFamily')

  mdf_het <- melt(subset_het, id.vars = melt_vars)
  mdf_trans <- melt(subset_trans, id.vars = melt_vars)
  mdf_hetDif <- melt(subset_hetDif, id.vars = melt_vars)

  het_plot <- hetHeatmap(mdf_het, family_facet)
  trans_plot <- transHeatmap(mdf_trans, family_facet)
  hetDif_plot <- hetDifHeatmap(mdf_hetDif, family_facet)
  all_plot <- grid.arrange(trans_plot, hetDif_plot, het_plot, nrow = 1, widths = c(1,1,3))

  outname <- paste0('./Plots/Trans_Het_by_Strain/',
                    contrast[1], '_',
                    contrast[2], '_',
                    het_col, '_',
                    'transth_', as.character(abs_trans_filter),
                    '.pdf')
  print(outname)
  ggsave(outname, all_plot, device = 'pdf')
}

colnames(cor_cov_df)

contrast <- c('12B', '10G')
het_col <- 'Cov_500fp_manybins'

abs_trans_filter <- 1
abs_het_filter <- 0

family_facet <- F
family <- NA
## trans, het or clust
sorting <- 'trans'

plt <- finalHeatmap(contrast, het_col, abs_trans_filter, abs_het_filter, family, family_facet)
#+end_src
** Differences Analysis
#+begin_src R
analysis_df <- trans_df %>%
  left_join(info_df, by = 'Gene_id') %>%
  left_join(cor_cov_df %>% select(Gene_id, contains('Cov_500fp_manybins')), by = 'Gene_id')

## analysis_df %>%
##   filter(abs(`A7-E5_MaxVal`) > 2) %>%
##   select(Gene_id, `A7-E5_MaxVal`)

## analysis_df %>%
##   filter(Gene_id == 'PF3D7_1372600') %>%
##   select(Gene_id, `A7-E5_MaxVal`)

##### Plotting part #####
contrast <- c('E5', 'B11')
het_col <- 'Cov_500fp_manybins'

trans_col <- paste0(contrast[1], '-', contrast[2], '_MaxVal')
het_col_1 <- paste0(het_col, '_', contrast[1])
het_col_2 <- paste0(het_col, '_', contrast[2])

infocols <- colnames(info_df)

x <- analysis_df %>%
  select(Gene_id,
         Family_Grouped,
         matches(trans_col),
         matches(het_col_1),
         matches(het_col_2),
         one_of(infocols)
         ) %>%
  filter(abs(get(trans_col)) > 1)

table(x$Gam_specific)
table(x$Family_Grouped)
table(x$Variant)

## Test for Gam Genes enrichment
count_mtx <- matrix(
  c(sum(x$Gam_specific),
    sum(info_df$Gam_specific),
    sum(!x$Gam_specific),
    sum(!info_df$Gam_specific)),
  nrow=2,ncol=2)

fisher.test(count_mtx, alternative="greater")
#+end_src
** Dount Plots
#+begin_src R
## Donut Plot

contrasts_donuts <- function(contrast, het_col, df){
  trans_col <- paste0(contrast[1], '-', contrast[2], '_MaxVal')
  het_col_1 <- paste0(het_col, '_', contrast[1])
  het_col_2 <- paste0(het_col, '_', contrast[2])

  infocols <- colnames(info_df)

  x <- df %>%
    select(Gene_id,
           Family_Grouped,
           matches(trans_col),
           matches(het_col_1),
           matches(het_col_2),
           one_of(infocols)
           ) %>%
    filter(abs(get(trans_col)) > 1)
  data <- as.data.frame(table(x$Family_Grouped))
  colnames(data) <- c('category', 'count')

  ## Compute percentages
  data$fraction = data$count / sum(data$count)

  ## Compute the cumulative percentages (top of each rectangle)
  data$ymax = cumsum(data$fraction)

  ## Compute the bottom of each rectangle
  data$ymin = c(0, head(data$ymax, n=-1))

  ## Compute label position
  data$labelPosition <- (data$ymax + data$ymin) / 2

  ## Compute a good label
  data$label <- paste0(data$category, "\n value: ", data$count)

  ## Make the plot
  p <- ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category)) +
    geom_rect(color="white") +
                                        #geom_label( x=4.2, aes(y=labelPosition, label=label), size=3) +
    coord_polar(theta="y") + # Try to remove that to understand how the chart is built initially
    xlim(c(2, 4)) +# Try to remove that to see how to make a pie chart
    theme_void() + my_scale#scale_fill_viridis(discrete=TRUE)

  print(p)
  outname <- paste0('./Plots/Donuts/',
                    contrast[1], '_',
                    contrast[2], '_',
                    'families',
                    '.svg')

  ggsave(outname, p, device = 'svg')
}

contrasts <- list(
  c('12B', '10G'),
  c('A7', 'E5'),
  c('A7', 'B11'),
  c('E5', 'B11')
  )
het_col <- 'Cov_500fp_manybins'
contrast <-   c('12B', '10G')
df <- analysis_df

for(contrast in contrasts){
  print(contrast)
  contrasts_donuts(contrast, het_col, analysis_df)
}

info_df %>%
  filter(Family_Grouped == 'Not CVGs')

table(info_df$Variant)

info_df %>%
  filter(!Variant) %>%
  filter(Family_Grouped != 'Not CVGs')


#+end_src
** 5/ORF/3 Plots (to be fixed, need to add Label)
#+begin_src R
#### 5/ORF/3 Plots ####

finalHeatmap <- function(trans_col, het_col_1, het_col_2, abs_trans_filter, abs_het_filter, family, family_facet) {

  subset_all <- trans_het_df %>%
    filter(abs(get(trans_col)) > abs_trans_filter) %>%
    arrange(desc(get(trans_col))) %>%
    mutate(Gene_id = factor(Gene_id, levels = Gene_id))

  if (!is.na(family)){
    subset_all <- subset_all %>%
      filter(Family == family)
  }

  subset_trans <- subset_all %>%
    select(Gene_id, Label, matches(trans_col), Annot, Family, SubFamily)

  subset_het <- cov_5ORF3_df %>%
    left_join(info_df %>% select(Gene_id), by = 'Gene_id') %>%
    select(Gene_id, contains(het_col_1), contains(het_col_2))

  hetcol_names <- c(paste(rep(het_col_1, 3), c('5p', 'ORF', '3p'), sep = '_'),
                    paste(rep(het_col_2, 3), c('5p', 'ORF', '3p'), sep = '_'))

  subset_het <- subset_het %>% setNames(c('Gene_id', hetcol_names))

  subset_het <- subset_trans %>%
    left_join(subset_het, by = 'Gene_id') %>%
    select(-matches(trans_col)) %>%
    mutate(Label = factor(Label, levels = Label))

  table(is.na(subset_het$Label))
  subset_het %>%
    filter(is.na(Label))

  info_df %>%
    filter(Gene_id == 'PF3D7_0112400')


  cols_5p <- colnames(subset_het %>% select(contains('5p')))
  cols_ORF <- colnames(subset_het %>% select(contains('ORF')))
  cols_3p <- colnames(subset_het %>% select(contains('3p')))

  subset_hetDif <- subset_het %>%
    mutate(Dif_5p = get(cols_5p[1]) - get(cols_5p[2])) %>%
    mutate(Dif_ORF = get(cols_ORF[1]) - get(cols_ORF[2])) %>%
    mutate(Dif_3p = get(cols_3p[1]) - get(cols_3p[2])) %>%
    select(Gene_id, Label, Annot, Family, SubFamily, contains('Dif'))

  melt_vars <- c('Gene_id', 'Label', 'Annot', 'Family', 'SubFamily')

  mdf_het <- melt(subset_het, id.vars = melt_vars)
  mdf_trans <- melt(subset_trans, id.vars = melt_vars)
  mdf_hetDif <- melt(subset_hetDif, id.vars = melt_vars)

  het_plot <- hetHeatmap(mdf_het, family_facet)
  trans_plot <- transHeatmap(mdf_trans, family_facet)
  hetDif_plot <- hetDifHeatmap(mdf_hetDif, family_facet)
  all_plot <- grid.arrange(trans_plot, hetDif_plot, het_plot, nrow = 1, widths = c(0.7,1,3))
}

trans_col <- 'A7-E5_MaxVal'
het_col_1 <- 'A7'
het_col_2 <- 'E5'

abs_trans_filter <- 1.5
abs_het_filter <- 0

family_facet <- T

family <- NA


finalHeatmap(trans_col, het_col_1, het_col_2, abs_trans_filter, abs_het_filter, family, family_facet)



#+end_src
** Get Trans ON/OFF genes, from filtered tables
#+begin_src R
old_arrays <- '../Microarrays/New_Old_separate_approach/Old_Arrays/R_results_OldArrays_Variantome/'

filtered_12B_10G <- read_tsv(paste0(old_arrays, '12B_10G_final_df.tsv')) %>%
  filter(PassRed & PassDuplDel)
filtered_12B_3D7B <- read_tsv(paste0(old_arrays, '12B_3D7B_final_df.tsv')) %>%
  filter(PassRed & PassDuplDel)
filtered_10G_3D7B <- read_tsv(paste0(old_arrays, '10G_3D7B_final_df.tsv')) %>%
  filter(PassRed & PassDuplDel)

new_arrays <- '../Microarrays/New_Old_separate_approach/New_Arrays/R_results_NewArray/'

filtered_A7_B11 <- read_tsv(paste0(new_arrays, 'A7_B11_final_df.tsv')) %>%
  filter(PassRed & PassDuplDel)
filtered_A7_E5 <- read_tsv(paste0(new_arrays, 'A7_E5_final_df.tsv')) %>%
  filter(PassRed & PassDuplDel)
filtered_B11_E5 <- read_tsv(paste0(new_arrays, 'B11_E5_final_df.tsv')) %>%
  filter(PassRed & PassDuplDel)

## Swich B11vsE5 for E5vsB11
filtered_E5_B11 <- filtered_B11_E5 %>%
  rename(`E5-B11_MaxVal` = `B11-E5_MaxVal`, `E5-B11_MaxTime` = `B11-E5_MaxTime`) %>%
  mutate(`E5-B11_MaxVal` = -`E5-B11_MaxVal`)

trans_df %>%
  filter(!Gene_id %in% filtered_12B_10G$Gene_id) %>%
  filter(!Gene_id %in% filtered_12B_3D7B$Gene_id) %>%
  filter(!Gene_id %in% filtered_10G_3D7B$Gene_id) %>%
  filter(!Gene_id %in% filtered_A7_B11$Gene_id) %>%
  filter(!Gene_id %in% filtered_A7_E5$Gene_id) %>%
  filter(!Gene_id %in% filtered_E5_B11$Gene_id) %>%
  write_tsv('filtered_out_genes_by_Red_DuplDel.tsv')

## Select MaxDif for each gene (once filtered by redfilter and dupl_del)
maxDif_df <- tibble()
for (gid in trans_df$Gene_id){

  ## Create a list with each contrast difference df
  difs <- list(
    filtered_12B_10G,
    filtered_12B_3D7B,
    filtered_10G_3D7B,
    filtered_A7_B11,
    filtered_A7_E5,
    filtered_E5_B11
  )

  ## Filter by Gene_id
  dif_dfs <- lapply(difs, function(x) x %>% filter(Gene_id == gid))

  ## Function to get MaxVal of each df and join them in a vector
  get_MaxVal <- function(x){
    maxVal <- x %>%
      select(contains('MaxVal')) %>%
      pull()
    if (identical(maxVal, numeric(0))) {maxVal <- NA}
    return(maxVal)
  }

  maxVect <- sapply(dif_dfs, get_MaxVal)
  max_idx <- which.max(abs(maxVect))

  ## Handle genes that don't pass filters (set to NA)
  if (identical(maxVect, rep(NA, 6))) {
    out_row <- tibble(
      Gene_id = gid,
      Max_aMAFC = NA,
      Max_Time = NA,
      On_trans = NA,
      Off_trans = NA,
      PassMaxtime = FALSE
    )
    ## Handle rest of genes
  } else {
    ## Get on/off strain names
    maxDif <- dif_dfs[[max_idx]] %>% select(contains('_MaxVal'))
    maxVal <- maxDif %>% pull()

    maxStrains <- colnames(maxDif)
    strains <- strsplit(maxStrains, split = '_', fixed = T)[[1]][1]
    strains <- strsplit(strains, split = '-', fixed = T)[[1]]
    if (maxVal >= 0){
      On <- strains[1]
      Off <- strains[2]
    } else {
      On <- strains[2]
      Off <- strains[1]
    }

    ## Collect MaxDif row from the appropiate df
    out_row <- dif_dfs[[max_idx]] %>%
      select(Gene_id, contains('_MaxVal'), contains('_MaxTime'), PassMaxtime) %>%
      setNames(c('Gene_id', 'Max_aMAFC', 'Max_Time', 'PassMaxtime')) %>%
      mutate(
        On_trans = On,
        Off_trans = Off
      )

  }
  maxDif_df <- bind_rows(maxDif_df, out_row)
}

maxDif_df <- maxDif_df %>%
  arrange(-abs(Max_aMAFC)) %>%
  left_join(trans_df, by = 'Gene_id')

maxDif_df %>%
  print(width = 400)
#+end_src
** Replace 3D7B with pertinent new array subclone
#+begin_src R
pre3D7_substitution <- maxDif_df
new_array_areas <- read_csv('/mnt/Disc4T/Projects/PhD_Project/Microarrays/New_Old_separate_approach/New_Arrays/R_results_NewArray/area_geneLevel.csv') %>%
  select(-Name, -Annot, -Variant)

max_trans_newarray <- maxDif_df %>%
  left_join(new_array_areas)

get_new_onoff <- function(gid) {

  #gid <- 'PF3D7_0421500'
  on <- max_trans_newarray %>%
    filter(Gene_id == gid) %>%
    select(On_trans) %>%
    pull()

  off <- max_trans_newarray %>%
    filter(Gene_id == gid) %>%
    select(Off_trans) %>%
    pull()

  time <- max_trans_newarray %>%
    filter(Gene_id == gid) %>%
    select(Max_Time) %>%
    pull()

  onoff <- TRUE
  if (is.na(on) | is.na(off)){
    onoff <- FALSE
  } else {
    if (on == '3D7B') {func <- which.max}
    if (off == '3D7B') {func <- which.min}
    if (on != '3D7B' & off != '3D7B') {onoff <- FALSE}
  }

  if (is.na(time)){
    out <- NA
  } else if (!onoff){
    out <- NA
  } else {
    strains <- c('A7', 'B11', 'E5')

    vect <- max_trans_newarray %>%
      filter(Gene_id == gid) %>%
      select(contains(time))

    ## Filter by red percent if 3D7B is 'On' strain
    red_pcnts <- red_df %>%
      filter(Gene_id == gid) %>%
      select(A7, B11, E5)

    red_mask <- red_pcnts > 15
    if (on != '3D7B'){red_mask <- c(TRUE, TRUE, TRUE)}

    ## Filter by dupl/del
    dupl_del_mask <- c(
      !gid %in% dupl_del$A7K9$Gene_id,
      !gid %in% dupl_del$B11$Gene_id,
      !gid %in% dupl_del$E5K9$Gene_id
    )

    ## Apply both filters
    whole_mask <- red_mask & dupl_del_mask

    vect <- vect[whole_mask]
    strains <- strains[whole_mask]

    ## Final output
    ifelse(all(is.na(vect)) | !any(whole_mask), out <- NA, out <- strains[func(vect)])
  }
  return(out)
}

newonoffs <- sapply(max_trans_newarray$Gene_id, get_new_onoff)
maxDif_df['New_OnOffs'] <- newonoffs
max_trans_newarray['New_OnOffs'] <- newonoffs

max_trans_newarray %>%
  select(Gene_id, On_trans, Off_trans, New_OnOffs) %>%
  print(n = 50)


maxDif_df <- maxDif_df %>%
  mutate(On_trans = ifelse(On_trans == '3D7B',
                           New_OnOffs,
                           On_trans)) %>%
  mutate(Off_trans = ifelse(Off_trans == '3D7B',
                           New_OnOffs,
                           Off_trans)) %>%
  mutate(Is_3D7B = !is.na(New_OnOffs)) %>%
  select(-New_OnOffs)

maxDif_df %>%
  select(-contains('_MaxVal'), -contains('_MaxTime'))

#+end_src
** Replace old maxTrans_df with new
#+begin_src R
#old_maxTrans_df <- maxTrans_df
maxTrans_df <- maxDif_df
#+end_src
** Trans FC filter
*** Remove tRNAs
#+begin_src R
## Remove tRNAs
transFC_df <- maxTrans_df %>%
  left_join(info_df, by = 'Gene_id') %>%
  filter(!Is_tRNA)
#+end_src
*** Check Red filter
#+begin_src R
## Add red percentile
get_red_percent_onstrain <- function(gid){
  on_strain <- transFC_df %>%
    filter(Gene_id == gid) %>%
    select(On_trans) %>%
    pull()

  if (is.na(on_strain) | !gid %in% red_df$Gene_id){
    pcnt <- NA
  } else {
    pcnt <- red_df %>%
      filter(Gene_id == gid) %>%
      select(matches(on_strain)) %>%
      pull()
  }
  return(pcnt)
}

percs <- sapply(transFC_df$Gene_id, get_red_percent_onstrain)

transFC_df <- transFC_df %>%
  mutate(Red_Pcnt_Onstrain = percs)

transFC_df %>%
  filter(abs(Max_aMAFC) > 2) %>%
  filter(Red_Pcnt_Onstrain < 15) %>%
  select(Gene_id, Label, Max_aMAFC, On_trans, Off_trans, Red_Pcnt_Onstrain, Variant) %>%
  write_csv('max_red_percentile_15_filter_failed.csv')

transFC_df %>%
  filter(abs(Max_aMAFC) > 2) %>%
  filter(Red_Pcnt_Onstrain < 15) %>%
  select(Gene_id, Label, Max_aMAFC, On_trans, Off_trans, Red_Pcnt_Onstrain, Variant)


transFC_df %>%
  mutate(Red_filter = case_when(
           abs(Max_aMAFC) >= 1 & Red_Pcnt_Onstrain > 20 ~ 'Trans_Red',
           abs(Max_aMAFC) >= 1 & Red_Pcnt_Onstrain <= 20 ~ 'Trans_NoRed',
           abs(Max_aMAFC) < 1 & Red_Pcnt_Onstrain > 20 ~ 'NoTrans_Red',
           abs(Max_aMAFC) < 1 & Red_Pcnt_Onstrain <= 20 ~ 'NoTrans_NoRed',
           )) %>%
  count(Red_filter)

#+end_src
*** Max timepoint of expression filter
#+begin_src R
## New approach
## Check which areas does maxtimepoint overlapp -> check if aAFC > th at this areas

point_overlap <- function(point, interval){
  point >= interval[1] & point <= interval[2]
}

transFC_df_noNAs <- transFC_df %>%
  filter(!is.na(On_trans) & !is.na(Off_trans))

aFC_in_maxtime <- c()
gids <- c()
th <- 2
for (gid in transFC_df_noNAs$Gene_id){

  #gid <- 'PF3D7_0900200'
  ## Get max contrast
  strains <- max_trans_newarray %>% ## this is the one where 3D7B appears as such
    filter(Gene_id == gid) %>%
    select(On_trans, Off_trans) %>%
    as.character()

  if (!any(is.na(strains))) {
    ## Check wehter its old/new df
    batch <- ifelse(any(c('A7', 'E5', 'B11') %in% strains), 'New', 'Old')

    ## Create time-regions
    breaks <- breaks_df %>%
      select(contains(batch)) %>%
      pull()

    left <- c(breaks[1], breaks[3])
    right <- c(breaks[3], breaks[5])
    mid <- c(breaks[2], breaks[4])
    sides_l <- c(breaks[1], breaks[2])
    sides_r <- c(breaks[4], breaks[5])

    ## Get maxtime
    maxtime <- maxtime_df %>%
      filter(Gene_id == gid) %>%
      select(contains(batch)) %>%
      pull()

    ## Ensure maxtime is in the areas intervals
    if (maxtime < breaks[1]) {maxtime <- breaks[1]}
    if (maxtime > breaks[5]) {maxtime <- breaks[5]}

    ## Get overlappped areas
    areas <- list('left' = left, 'right' = right, 'mid' = mid,
                  'sides' = sides_l, 'sides' = sides_r)
    overlaps <- sapply(areas, function(x) point_overlap(maxtime, x))

    ## Get aAFC in overlapping areas
    aFCs <- arees_df %>%
      filter(Gene_id == gid) %>%
      select(contains(names(areas[overlaps])) &
             contains(strains[1]) &
             contains(strains[2])) %>%
      as.numeric()

    aFC_in_maxtime <- c(aFC_in_maxtime, any(abs(aFCs) > th))
    gids <- c(gids, gid)
  } else {
    aFC_in_maxtime <- c(aFC_in_maxtime, NA)
  }
}

maxtime_aAFC_df <- tibble(Gene_id = gids, aAFC_at_maxtime = aFC_in_maxtime)

transFC_df_noNAs <- transFC_df_noNAs %>%
  left_join(maxtime_aAFC_df)

transFC_df_noNAs %>%
  filter(abs(Max_aMAFC) > 2) %>%
  filter(!aAFC_at_maxtime) %>%
  select(Label, Max_aMAFC, On_trans, Off_trans, Annot) %>%
  write_csv('areaFC_in_maxtp_filter_failed.csv')

transFC_df_noNAs %>%
  filter(abs(Max_aMAFC) > 2) %>%
  filter(!aAFC_at_maxtime) %>%
  select(Label, Max_aMAFC, On_trans, Off_trans, Annot)


#+end_src
*** Check Filter by Duplications/Deletions
#+begin_src R
transFC_df_noNAs

check_dupldel <- function(gid){

  #gid <- 'PF3D7_0831700'
  strains <- transFC_df_noNAs %>%
    filter(Gene_id == gid) %>%
    select(On_trans, Off_trans) %>%
    as.character()
  #print(strains)

                                        #f_path <- '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/Duplication_Deletion_Regions/Crossed_with_genes/'
  ## file_list <- list.files(path=f_path)
  ## genes_tsv <- file_list[sapply(file_list, function(x) grepl(strains[1], x) & grepl(strains[2], x))]
  ## #print(genes_tsv)
  ## dd_genes <- read_tsv(paste0(f_path, genes_tsv), col_names = F, col_types = cols())
  ## gid %in% dd_genes$X1

  gid %in% dupl_del[[strains[1]]]$Gene_id | gid %in% dupl_del[[strains[2]]]$Gene_id
}


dupl_del <- sapply(transFC_df_noNAs$Gene_id, check_dupldel)
transFC_df_noNAs['Dupl_Del_in_Contrast'] <- dupl_del


transFC_df_noNAs %>%
  filter(Dupl_Del_in_Contrast) %>%
  write_csv('genes_with_dupl_del.csv')

transFC_df_noNAs %>%
  filter(Dupl_Del_in_Contrast) %>%
  select(Gene_id, Max_aMAFC, On_trans, Off_trans, Dupl_Del_in_Contrast) %>%
  print(n = 100)

filtered_10G_3D7B %>%
  filter(Gene_id == 'PF3D7_0935400')

#+end_src
**** Check CGH
#+begin_src R
#### Check CGH data matches out input derived dupl/del data ####

## Load old_array for translation
old <- read_csv('../Microarrays/New_Old_separate_approach/Old_Arrays/gene_level_raw_table.csv') %>%
  select(Old_id, Gene_id)

cgh <- read_xls('../Microarrays/New_Old_separate_approach/Old_Arrays/Variantome_Original/3D7_Variantome_AllData_withGam.xls', sheet = 4)

cgh <- cgh %>%
  select(
    `...1`,
    X1.2b,
    X10g,
    X3d7b
  ) %>%
  rename(
    Old_id = `...1`,
    CGH_12B = X1.2b,
    CGH_10G = X10g,
    CGH_3D7B = X3d7b
  ) %>%
  mutate(across(contains('CGH'), as.numeric)) %>%
  left_join(old) %>%
  relocate(Gene_id, Old_id) %>%
  filter(!is.na(Gene_id))

cgh_th <- 0.7
cgh <- cgh %>%
  mutate(CGH_12B_10G = abs(CGH_12B - CGH_10G) > cgh_th) %>%
  mutate(CGH_12B_3D7B = abs(CGH_12B - CGH_3D7B) > cgh_th) %>%
  mutate(CGH_10G_3D7B = abs(CGH_10G - CGH_3D7B) > cgh_th)

f_path <- '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/Duplication_Deletion_Regions/Crossed_with_genes/'
file_list <- c(
  "12B_minus_10G_100bp_500smth_RPKM_cov_norm_pdf_0999999_minlen500_genes.tsv",
  "12B_minus_3D7_100bp_500smth_RPKM_cov_norm_pdf_0999999_minlen500_genes.tsv",
  "10G_minus_3D7_100bp_500smth_RPKM_cov_norm_pdf_0999999_minlen500_genes.tsv"
)

dupl_dl_12B_10G <- read_tsv(paste0(f_path, file_list[1]), col_names = F) %>%
  select(X1) %>% pull()

dupl_dl_12B_3D7B <- read_tsv(paste0(f_path, file_list[2]), col_names = F) %>%
  select(X1) %>% pull()

dupl_dl_10G_3D7B <- read_tsv(paste0(f_path, file_list[3]), col_names = F) %>%
  select(X1) %>% pull()

## 3D7B no Ã©s el que toca!!!!

cgh %>%
  filter(CGH_12B_10G) %>%
  select(Gene_id) %>%
  pull() %in% dupl_dl_12B_10G


cgh <- cgh %>%
  mutate(In_Dupl_Del_12B_10G = Gene_id %in% dupl_dl_12B_10G) %>%
  mutate(In_Dupl_Del_12B_3D7B = Gene_id %in% dupl_dl_12B_3D7B) %>%
  mutate(In_Dupl_Del_10G_3D7B = Gene_id %in% dupl_dl_10G_3D7B)

cgh %>%
  select(
    Gene_id, Old_id,
    CGH_12B, CGH_10G,
    CGH_12B_10G, In_Dupl_Del_12B_10G
  ) %>%
  write_csv('cgh_inputs_12B_10G.csv')

## cgh %>%
##   select(
##     Gene_id, Old_id,
##     CGH_12B, CGH_10G, CGH_3D7B,
##     CGH_12B_3D7B, In_Dupl_Del_12B_3D7B
##   ) %>%
##   filter(CGH_12B_3D7B) %>%
##   write_csv('cgh_inputs_12B_3D7B.csv')

## cgh %>%
##   select(
##     Gene_id, Old_id,
##     CGH_12B, CGH_10G, CGH_3D7B,
##     CGH_10G_3D7B, In_Dupl_Del_10G_3D7B
##   ) %>%
##   filter(CGH_10G_3D7B) %>%
##   write_csv('cgh_inputs_10G_3D7B.csv')




#+end_src
*** Final filtered table
#+begin_src R
finalFC <- transFC_df_noNAs %>%
  filter(abs(Max_aMAFC) > 2) %>%
  filter(Red_Pcnt_Onstrain > 15) %>%
  filter(aAFC_at_maxtime) %>%
  filter(!Dupl_Del_in_Contrast)

write_csv(finalFC, 'max_log2FC2_filters_passed.csv')

## transFC_df_noNAs %>%
##   filter(abs(Max_aMAFC) > 2) %>%
##   filter(Red_Pcnt_Onstrain > 15)

## transFC_df_noNAs %>%
##   select(Red_Pcnt_Onstrain) %>%
##   summary()


## colnames(transFC_df_noNAs)

## transFC_df_noNAs %>%
##   select(aAFC_at_maxtime) %>%
##   summary()

## transFC_df_noNAs %>%
##   filter(abs(Max_aMAFC) > 1) %>%
##   filter(Red_Pcnt_Onstrain > 15) %>%
##   filter(!aAFC_at_maxtime) %>%
##   write_csv('maxFC_lg2FC1_fail_aAFCmaxtime.csv')

## transFC_df_noNAs %>%
##   filter(abs(Max_aMAFC) > 1)

finalFC %>%
  filter(On_trans == 'B11' |
         Off_trans == 'B11')

finalFC %>%
  count(Variant)

## From Peak-Calling
transFC_df_noNAs %>%
  filter(!Gene_id %in% finalFC$Gene_id) %>%
  filter(Difpeaks_12B_10G | Difpeaks_A7_E5 | Difpeaks_A7_B11 | Difpeaks_E5_B11) %>%
  select(
    Gene_id, Max_aMAFC,
    On_trans, Off_trans,
    #contains('Difpeaks'),
    Red_Pcnt_Onstrain,
    aAFC_at_maxtime,
    Dupl_Del_in_Contrast
  ) %>%
  left_join(info_df, by = 'Gene_id') %>%
  write_tsv('genes_with_difpeaks_not_in_FC_tables.tsv')
#+end_src
*** Final table Donuts
#+begin_src R
on_off_donut <- function(col){
  data <- finalFC %>%
    count(get(col)) %>%
    set_names('category', 'count')

  ## Compute percentages
  data$fraction = data$count / sum(data$count)

  ## Compute the cumulative percentages (top of each rectangle)
  data$ymax = cumsum(data$fraction)

  ## Compute the bottom of each rectangle
  data$ymin = c(0, head(data$ymax, n=-1))

  ## Compute label position
  data$labelPosition <- (data$ymax + data$ymin) / 2

  ## Compute a good label
  data$label <- paste0(data$category, "\n value: ", data$count)

  ## Make the plot
  p <- ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category))
  p <- p +  geom_rect(color="white")
  ##p <- p + geom_label( x=4.2, aes(y=labelPosition, label=label), size=3)
  p <- p + coord_polar(theta="y") # Try to remove that to understand how the chart is built initially
  p <- p + xlim(c(2, 4)) # Try to remove that to see how to make a pie chart
  p <- p + theme_void()
  p <- p + scale_fill_viridis(discrete=TRUE)
  p
}

ggsave('../Plots/on_difgenes_donut.pdf', on_off_donut('On_trans'), device = 'pdf')
ggsave('../Plots/off_difgenes_donut.pdf', on_off_donut('Off_trans'), device = 'pdf')

#+end_src
** Get coverage for ON/OFF genes with sign
We always get the same sample order in the contrasts (12B vs 10G, A7 vs B11...) both regarding transcription and coverage.
#+begin_src R
## Select transcription cols

tdf <- transFC_df_noNAs %>%
  select(Gene_id, Max_aMAFC, On_trans, Off_trans, Is_3D7B)

#print(maxTrans_df[63,], width = 400)

## Create empty DF
hetcols <- colnames(cor_cov_df %>% select(contains('12B')))
hetcols <- str_replace(hetcols, '_12B', '')

col_names <- c('Gene_id',
               paste0(hetcols, '_On'),
               paste0(hetcols, '_Off'),
               paste0(hetcols, '_Dif'))

cn <- setNames(rep('', length(col_names)), col_names)
df <- bind_rows(cn)[0,]

## Traverse max trans. df and get coverage cols

## which(tdf$Gene_id == 'PF3D7_0100300')
## i <- 63
## tdf[63,]

for (i in 1:dim(tdf)[1]){

  gid <- as.character(tdf$Gene_id[i])
  on <- tdf$On_trans[i]
  off <- tdf$Off_trans[i]

  ## Select contrast in which difference sign must be switched
  contrast <- paste0(on, '-', off)
  positive_contrasts <- c(
    '12B-10G', '12B-A7', '12B-E5', '12B-B11',
    '10G-A7', '10G-E5', '10G-B11',
    'A7-E5', 'A7-B11',
    'E5-B11'
  )

  ifelse(
    contrast %in% positive_contrasts,
    neg_dif <- FALSE,
    neg_dif <- TRUE
    )

  ## Main Loop
  if (gid %in% cor_cov_df$Gene_id & !is.na(on) & !is.na(off)){

    onvect <- cor_cov_df %>%
      filter(Gene_id == gid) %>%
      select(contains(on))

    offvect <- cor_cov_df %>%
      filter(Gene_id == gid) %>%
      select(contains(off))

    diffvect <- onvect-offvect
    if (neg_dif) {diffvect <- -diffvect}

    row <- c(gid,
             unlist(onvect, use.names = F),
             unlist(offvect, use.names = F),
             unlist(diffvect, use.names = F))
    row <- setNames(row, col_names)
    df <- df %>% add_row(bind_rows(row))
  }
}

signed_maxtrans_cov <- df %>%
  mutate(across(-Gene_id,  as.numeric)) %>%
  full_join(tdf, by = 'Gene_id') %>%
  #mutate(Max_aMAFC = abs(Max_aMAFC)) %>%
  left_join(info_df)

## genes_nocov <- unsigned_maxtrans_cov %>%
##      select(Gene_id, contains('Cov_500fp_manybins')) %>%
##      filter(!complete.cases(.)) %>%
##      select(Gene_id) %>% pull()

## maxTrans_df %>%
##   filter(is.na(On_trans) | is.na(Off_trans))

## cor_cov_df %>%
##   select(Gene_id, contains('Cov_500fp_manybins')) %>%
##   filter(!complete.cases(.)) %>%
##   print(width = 400)


#+end_src
** Get coverage for ON/OFF genes unsigned
We always get the same sample order in the contrasts (12B vs 10G, A7 vs B11...) both regarding transcription and coverage.
#+begin_src R
## Select transcription cols

tdf <- transFC_df_noNAs %>%
  select(Gene_id, Max_aMAFC, On_trans, Off_trans, Is_3D7B)

#print(maxTrans_df[63,], width = 400)

## Create empty DF
hetcols <- colnames(cor_cov_df %>% select(contains('12B')))
hetcols <- str_replace(hetcols, '_12B', '')

col_names <- c('Gene_id',
               paste0(hetcols, '_On'),
               paste0(hetcols, '_Off'),
               paste0(hetcols, '_Dif'))

cn <- setNames(rep('', length(col_names)), col_names)
df <- bind_rows(cn)[0,]

## Traverse max trans. df and get coverage cols

## which(tdf$Gene_id == 'PF3D7_0100300')
## i <- 63
## tdf[63,]

for (i in 1:dim(tdf)[1]){

  gid <- as.character(tdf$Gene_id[i])
  on <- tdf$On_trans[i]
  off <- tdf$Off_trans[i]

  ## Select contrast in which difference sign must be switched
  ## contrast <- paste0(on, '-', off)
  ## positive_contrasts <- c(
  ##   '12B-10G', '12B-A7', '12B-E5', '12B-B11',
  ##   '10G-A7', '10G-E5', '10G-B11',
  ##   'A7-E5', 'A7-B11',
  ##   'B11-E5'
  ## )

  ## ifelse(
  ##   contrast %in% positive_contrasts,
  ##   neg_dif <- FALSE,
  ##   neg_dif <- TRUE
  ##   )

  ## Main Loop
  if (gid %in% positive_cov_df$Gene_id & !is.na(on) & !is.na(off)){

    onvect <- positive_cov_df %>%
      filter(Gene_id == gid) %>%
      select(contains(on))

    offvect <- positive_cov_df %>%
      filter(Gene_id == gid) %>%
      select(contains(off))

    diffvect <- onvect-offvect
    #if (neg_dif) {diffvect <- -diffvect}

    row <- c(gid,
             unlist(onvect, use.names = F),
             unlist(offvect, use.names = F),
             unlist(diffvect, use.names = F))
    row <- setNames(row, col_names)
    df <- df %>% add_row(bind_rows(row))
  }
}

unsigned_maxtrans_cov <- df %>%
  mutate(across(-Gene_id,  as.numeric)) %>%
  full_join(tdf, by = 'Gene_id') %>%
  mutate(Max_aMAFC = abs(Max_aMAFC)) %>%
  left_join(info_df)

genes_nocov <- unsigned_maxtrans_cov %>%
     select(Gene_id, contains('Cov_500fp_manybins')) %>%
     filter(!complete.cases(.)) %>%
     select(Gene_id) %>% pull()

maxTrans_df %>%
  filter(is.na(On_trans) | is.na(Off_trans))

unsigned_maxtrans_cov %>%
  select(Gene_id, contains('Cov_500fp_manybins')) %>%
  filter(!complete.cases(.)) %>%
  print(width = 400)
#+end_src
** Analysis of differential genes
#+begin_src R
## Non-Variant With transFC analysis
non_variant_transDif <- unsigned_maxtrans_cov %>%
  filter(!Variant) %>%
  filter(!Is_tRNA) %>%
  filter(abs(Max_aMAFC) > 1) %>%
  select(Label, Max_aMAFC, On_trans, Off_trans, Family, Gam_specific, Annot, Gene_id)

write_csv(non_variant_transDif, 'non_variant_transth_1.csv')

non_variant_transDif %>%
  print(n = 50)

non_variant_transDif %>%
  count(Family)

non_variant_transDif %>%
  count(Gam_specific)

non_variant_transDif %>%
  filter(!is.na(Family))

non_variant_transDif %>%
  filter(On_trans == 'B11' | Off_trans == 'B11')


non_variant_transDif %>%
  filter(On_trans != '12B' & Off_trans != '12B' &
         On_trans != '10G' & Off_trans != '10G') %>%
  select(Gene_id, Max_aMAFC) %>%
  write_csv('non_variant_log2FC1_newarrays.csv')


non_variant_transDif

unsigned_maxtrans_cov %>%
  filter(abs(Max_aMAFC) > 1) %>%
  filter(Variant) %>%
  filter(On_trans != '12B' & Off_trans != '12B' &
         On_trans != '10G' & Off_trans != '10G') %>%
  write_csv('variant_log2fc1_newarrays.csv')

unsigned_maxtrans_cov %>%
  filter(abs(Max_aMAFC) > 1) %>%
  count(Family_Grouped)

unsigned_maxtrans_cov %>%
  filter(abs(Max_aMAFC) > 1.5)

hist(abs(unsigned_maxtrans_cov$Max_aMAFC), breaks = 1000)


unsigned_maxtrans_cov %>%
  filter(abs(Max_aMAFC) > 3) %>%
  count(Variant) %>%
  filter(Variant) %>%
  pull()

unsigned_maxtrans_cov %>%
  filter(abs(Max_aMAFC) > 2)


## percs <- c()
## for (x in seq(0, 7, by = 0.1)){

##   total <- dim(unsigned_maxtrans_cov %>%
##     filter(abs(Max_aMAFC) > x))[1]

##   var <- unsigned_maxtrans_cov %>%
##     filter(abs(Max_aMAFC) > x) %>%
##     count(Variant) %>%
##     filter(Variant) %>%
##     pull()

##   perc <- (var/total)*100
##   percs <- c(percs, perc)
## }
## percs

## df <- tibble('Thresolds' = seq(0, 7, by = 0.1), 'Perc.Variant' = percs)


## p <- ggplot(df, aes(x = Thresholds, y = Perc.Variant))
## p <- p + geom_point()
## p <- p + scale_x_continuous(breaks = scales::pretty_breaks(n = 10))
## p <- p + scale_y_continuous(breaks = scales::pretty_breaks(n = 10))
## p





#+end_src
** Get correlations ON/OFF genes
#+begin_src R
## Get Correlations

cor_signed_maxtrans <- signed_maxtrans_cov %>%
  filter(!Is_3D7B)

## Subset column by column
clnms <- colnames(cor_signed_maxtrans %>% select(contains('_Dif')))
for (c in clnms) {
  print(c)
  cor_genes <- cor_signed_maxtrans %>%
    select(Max_aMAFC, matches(c)) %>%
    filter(abs(Max_aMAFC) > 1.5) %>%
    drop_na()

  cormtx <- cor(cor_genes, method = 'pearson')
  print(paste0('Number of genes: ', dim(cor_genes)[1]))
  print(as.data.frame(cormtx[,1]))
  print('------------------')
}

## All toghether

trans_th <- 1

cor_genes <- cor_signed_maxtrans %>%
  select(Max_aMAFC, contains('_Dif')) %>%
  filter(abs(Max_aMAFC) > trans_th) %>%
  drop_na()

cor_genes

cormtx <- cor(cor_genes, method = 'pearson')
print(paste0('Number of genes: ', dim(cor_genes)[1]))
print(as.data.frame(cormtx[,1]))

outdf <- as.data.frame(cormtx)
outdf['Corr_with'] <- rownames(outdf)
outdf <- outdf %>% select(Corr_with, everything())
outname = paste0('corr_MaxFC_', trans_th, '_allowoverlaps.csv')
write_csv(outdf, outname)

## By subsets

get_corr <- function(df){
  cor_genes <- df %>%
    select(-Gene_id) %>%
    filter(abs(Max_aMAFC) > trans_th) %>%
    drop_na()

  cormtx <- cor(cor_genes, method = 'pearson')
  print(paste0('Number of genes: ', dim(cor_genes)[1]))

  outdf <- as.data.frame(cormtx)
  outdf['Corr_with'] <- rownames(outdf)
  outdf <- outdf %>% select(Corr_with, everything())
  outdf <- as_tibble(outdf[,c(1,2)])
  print(outdf)
}

trans_th <- 1

## Abs bins
abs_bins <- cor_signed_maxtrans %>%
  select(Gene_id, Max_aMAFC,
         Cov_1500fp_manybins_Dif,
         Cov_1000fp_manybins_Dif,
         Cov_500fp_manybins_Dif,
         contains('ORF', ignore.case = F) & contains('Dif'),
         Cov_500tp_manybins_Dif,
         Cov_1000tp_manybins_Dif
         )

abs_bins_cor <- get_corr(abs_bins)

## Rel bins

rel_bins <- cor_signed_maxtrans %>%
  select(Gene_id, Max_aMAFC,
         p5utr_Cov_Dif,
         contains('qorf') & contains('Dif'),
         p3utr_Cov_Dif
         )

rel_bins_cor <- get_corr(rel_bins)

## TSS

tss_bins <- cor_signed_maxtrans %>%
  select(Gene_id, Max_aMAFC,
         TSS_Cov_Dif,
         Cov_500fp_manybins_Dif,
         p5utr_Cov_Dif
         )

tss_bins_cor <- get_corr(tss_bins)


## Plots

df <- cor_signed_maxtrans %>% filter(abs(Max_aMAFC) > 1)

for (c in clnms){
  p <- ggplot(df,
              aes(x = Max_aMAFC, y = get(c), color = Gam_specific)) +
    geom_point() +
    geom_label_repel(data=subset(df, get(c) > 1),
                     aes(label = Gene_id),
                     box.padding   = 0.35,
                     point.padding = 0.5,
                     segment.color = 'grey50')
  ggsave(paste0('./Plots/MaxFC_Cor_Plots/cor_signed_maxFC_', c, '_allowoverlaps.png'), p, device = 'png')
}

#+end_src
** Make correlation by bin plots STEP
#+begin_src R
corr_data <- as_tibble(outdf[,1:2])

corr_data %>%
  arrange(Max_aMAFC) %>%
  print(n = 40)

bins <- c(
  'Cov_2000fp_manybins_Dif',
  'Cov_1500fp_manybins_Dif',
  'Cov_1000fp_manybins_Dif',
  'Cov_500fp_manybins_Dif',
  'Cov_500orf_Dif',
  'Cov_1000orf_Dif',
  'Cov_1500orf_Dif',
  'Cov_500tp_manybins_Dif',
  'Cov_1000tp_manybins_Dif',
  'Cov_1500tp_manybins_Dif'
  )


## Geom_step approach

pos <- c(-2000, -1500, -1000, -500, 0, 500, 1000, 2500, 3000, 3500)

cor_bins <- corr_data %>%
  filter(Corr_with %in% bins) %>%
  arrange(factor(Corr_with, levels = bins)) %>%
  mutate(Pos = pos)

cor_bins

cor_bins2 <- cor_bins %>%
  add_row(Corr_with = 'start', Max_aMAFC = 0, Pos = -2500) %>%
  add_row(Corr_with = 'end_of_gene', Max_aMAFC = 0, Pos = 1500) %>%
  add_row(Corr_with = 'end', Max_aMAFC = 0, Pos = 4000) %>%
  add_row(Corr_with = 'endtail', Max_aMAFC = 0, Pos = 4500) %>%
  arrange(Pos)

xbreaks <- c(
  '',
  'ATG-2000',
  'ATG-1500',
  'ATG-1000',
  'ATG-500',
  'ATG',
  'ATG+500',
  'ATG+1000',
  'ATG+1500',
  'End',
  'End+500',
  'End+1000',
  'End+1500',
  ''
  )

p <- ggplot(cor_bins2, aes(x = Pos, y = -Max_aMAFC, group = 1)) +
  geom_step() +
  ylim(0, 1) +
  ylab('- Pearson Corr') + xlab('Region') +
  theme_minimal() +
  scale_x_continuous(breaks = cor_bins2$Pos, labels = xbreaks) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  geom_vline(xintercept = 0, linetype = 'dashed', color = 'gray') +
  geom_vline(xintercept = 2500, linetype = 'dashed', color = 'gray')

p
ggsave('corr_genemodel_steps_allowoverlaps.png', p, device = 'png')
#+end_src
** Make correlation by bin plots BAR
#+begin_src R
## Geom Bar approach

cor_bins_plot <- function(df, labs, regions){
  corplot_df <- df %>%
    filter(Corr_with != 'Max_aMAFC') %>%
    mutate(Corr_with = factor(Corr_with, levels = Corr_with)) %>%
    arrange(Corr_with) %>%
    mutate(Labs = factor(labs, levels = labs)) %>%
    mutate(Region = regions)

  p <- ggplot(corplot_df, aes(x = Labs, y = -Max_aMAFC, color = Region)) +
    geom_boxplot(key_glyph = "point") +
    ylim(0, 1) +
    ylab('- Pearson Corr\n') + xlab('\nRegion') +
    theme_classic() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1),
      text = element_text(size=30),
            legend.position = "none"
          )

  ggsave(paste0('./Plots/Correlations/', deparse(substitute(df)), '_allowoverlaps.pdf'), p, device = 'pdf')
  p
}


## Abs

labs = c(
  '-1500 to -1000',
  '-1000 to -500',
  '-500 to ATG',
  'ATG to 500',
  '500 to 1000',
  '1000 to 1500',
  'End to +500',
  '+500 to +1000'
)

regions = c(rep('5prime', 3), rep('ORF', 3), rep('3prime', 2))

cor_bins_plot(abs_bins_cor, labs, regions)

## Rel

labs = c(
  '5\'UTR',
  'ORF 1/4',
  'ORF 2/4',
  'ORF 3/4',
  'ORF 4/4',
  '3\'UTR'
)

regions = c(rep('5prime', 1), rep('ORF', 4), rep('3prime', 1))

cor_bins_plot(rel_bins_cor, labs, regions)

## TSS

labs = c(
  'TSS',
  '-500 to ATG',
  '5\'UTR'
)

regions = c(rep('5prime', 3), rep('ORF', 0), rep('3prime', 0))

cor_bins_plot(tss_bins_cor, labs, regions) + geom_boxplot(color = 'green')



## cor_bins <- corr_data %>%
##   filter(Corr_with %in% bins) %>%
##   mutate(Corr_with = factor(Corr_with, levels = bins)) %>%
##   arrange(Corr_with)

## labs = c(
##   'ATG-2000',
##   'ATG-1500',
##   'ATG-1000',
##   'ATG-500',
##   'ATG+500',
##   'ATG+1000',
##   'ATG+1500',
##   'End+500',
##   'End+1000',
##   'End+1500'
## )

## cor_bins2 <- cor_bins %>%
##   mutate(Region = c(rep('5prime', 4), rep('ORF', 3), rep('3prime', 3))) %>%
##   mutate(Labs = factor(labs, levels = labs))

## p <- ggplot(cor_bins2, aes(x = Labs, y = -Max_aMAFC, color = Region)) +
##   geom_boxplot(key_glyph = "point") +
##   ylim(0, 1) +
##   ylab('- Pearson Corr') + xlab('Region') +
##   theme_minimal() +
##   theme(axis.text.x = element_text(angle = 45, hjust = 1))

## p

## ggsave('corr_genemodel_lines_abs.png', p, device = 'png')


## bins <- c(
##   'TSS_Cov_Dif',
##   'p5utr_Cov_Dif',
##   'Cov_1qorf_manybins_Dif',
##   'Cov_2qorf_manybins_Dif',
##   'Cov_3qorf_manybins_Dif',
##   'Cov_4qorf_manybins_Dif',
##   'p3utr_Cov_Dif'
## )

## cor_bins2 <- corr_data %>%
##   filter(Corr_with %in% bins) %>%
##   arrange(factor(Corr_with, levels = bins)) %>%
##   mutate(Corr_with = factor(Corr_with, levels = bins)) %>%
##   mutate(Region = c(rep('5prime', 2), rep('ORF', 4), rep('3prime', 1)))

## p <- ggplot(cor_bins2, aes(x = Corr_with, y = -Max_aMAFC, color = Region)) +
##   geom_boxplot(key_glyph = "point") +
## #  geom_bar(stat='identity', aes(fill = Region), width = 1, color = 'darkslategray') +
##   ylim(0, 1) +
##   ylab('- Pearson Corr') + xlab('Region') +
##   theme_minimal() +
##   theme(axis.text.x = element_text(angle = 45, hjust = 1))
## p

## ggsave('corr_genemodel_lines_rel.png', p, device = 'png')

## corr_data$Corr_with
#+end_src
** Make correlation Heatmap
#+begin_src R
trans_th <- 1

cor_genes <- cor_signed_maxtrans %>%
  select(Max_aMAFC, contains('_Dif')) %>%
  filter(abs(Max_aMAFC) > trans_th) %>%
  drop_na()

cor_genes

cormtx <- cor(cor_genes, method = 'pearson')
print(paste0('Number of genes: ', dim(cor_genes)[1]))
print(as.data.frame(cormtx[,1]))

outdf <- as.data.frame(cormtx)
outdf['Corr_with'] <- rownames(outdf)
outdf <- outdf %>% select(Corr_with, everything()) %>% as_tibble()

plotdf <- outdf %>% select(Corr_with, Max_aMAFC) %>% arrange(Max_aMAFC)
mplotdf <- melt(plotdf)
mplotdf$Corr_with <- factor(mplotdf$Corr_with, levels = mplotdf$Corr_with)

ggplot(mplotdf, aes(x = variable, y = Corr_with)) +
  geom_tile(aes(fill = value)) +
  geom_text(aes(label=value)) +
  scale_fill_gradient2(low = "chartreuse3",
                       mid = "white",
                       high = "darkred",
                       na.value="grey90")
#+end_src
** Plot Heatmap with ON/OFF genes
#+begin_src R
plot_df <- unsigned_maxtrans_cov %>%
  arrange(desc(Max_aMAFC)) %>%
  mutate(Gene_id = factor(Gene_id, levels = Gene_id))

heatMap_allstrains_trans <- function(aMAFC_th, cov_col, family, family_facet){

  on_col <- paste0(cov_col, '_On')
  off_col <- paste0(cov_col, '_Off')
  dif_col <- paste0(cov_col, '_Dif')

  subset_all <- plot_df %>%
    filter(abs(Max_aMAFC) > aMAFC_th) %>%
    select(Gene_id,
           Label,
           Max_aMAFC,
           matches(on_col),
           matches(off_col),
           matches(dif_col),
           Annot,
           Family,
           SubFamily
           ) %>%
    filter(complete.cases(.))

  if (!is.na(family)){
    subset_all <- subset_all %>%
      filter(Family == family)
  }

  ## Ordering
  if (sorting == 'clust') {
    mtx <- subset_all %>%
      select(matches(on_col),
             matches(off_col),
             matches(dif_col))
      #select(where(is.numeric))

    ##Make hierarquical Clustering
    dmtx <- dist(scale(mtx), method = "euclidean")
    cl <- hclust(dmtx, method = 'average')
    subset_all['Cluster'] <- cutree(cl, nclust)
    subset_all$Label <- factor(subset_all$Label, levels = subset_all$Label[cl$order])

    ## ## Make k-means Clustering
    ## cl <- kmeans(scale(mtx), nclust)
    ## subset_all$Label <- factor(subset_all$Label, levels = subset_all$Label[cl$cluster])

  } else if (sorting == 'trans') {
    subset_all <- subset_all %>%
      arrange(desc(Max_aMAFC)) %>%
      mutate(Label = factor(Label, levels = Label))

  } else if (sorting == 'het') {
    subset_all <- subset_all %>%
      arrange(desc(dif_col)) %>%
      mutate(Label = factor(Label, levels = Label))
  }


  subset_trans <- subset_all %>%
    select(Gene_id, Max_aMAFC, Label, Annot, Family, SubFamily)

  subset_het <- subset_all %>%
    select(Gene_id, matches(on_col), matches(off_col), Label, Annot, Family, SubFamily)

  subset_hetDif <- subset_all %>%
    select(Gene_id, matches(dif_col), Label, Annot, Family, SubFamily)

  melt_vars <- c('Gene_id', 'Label', 'Annot', 'Family', 'SubFamily')
  mdf_het <- melt(subset_het, id.vars = melt_vars)
  mdf_trans <- melt(subset_trans, id.vars = melt_vars)
  mdf_hetDif <- melt(subset_hetDif, id.vars = melt_vars)

  het_plot <- hetHeatmap(mdf_het, family_facet)
  trans_plot <- transHeatmap(mdf_trans, family_facet)
  hetDif_plot <- hetDifHeatmap(mdf_hetDif, family_facet)
  all_plot <- grid.arrange(trans_plot, hetDif_plot, het_plot, nrow = 1, widths = c(1,1,3))
}

aMAFC_th <- 1.5
family_facet <- F
family <- NA
cov_col <- 'Cov_500fp_manybins'
sorting <- 'trans'
nclust <- 5

##colnames(plot_df)


## Inspect NAs
plot_df %>%
  filter(is.na(Cov_500orf_Dif)) %>%
  select(Gene_id, Name, contains('Cov_500orf')) %>%
  print(n = 300)

heatMap_allstrains_trans(aMAFC_th, cov_col, family, family_facet)

plot_df %>%
  filter(Name == 'CLAG3.1') %>%
  select(Gene_id)
#+end_src
** Plot Heatmap with ON/OFF genes Clustered
#+begin_src R
plot_df <- unsigned_maxtrans_cov %>%
  arrange(desc(Max_aMAFC)) %>%
  mutate(Gene_id = factor(Gene_id, levels = Gene_id))

length(unsigned_maxtrans_cov$Label)
unique(length(unsigned_maxtrans_cov$Label))

plot_df %>%
  filter(abs(Max_aMAFC) > 1)

plot_df %>%
  filter(abs(Max_aMAFC) > 1) %>%
  select(Family_Grouped) %>%
  table()

plot_df %>%
  filter(abs(Max_aMAFC) > 1) %>%
  filter(Family_Grouped == 'Not CVGs') %>%
  select(Gene_id, Name, Max_aMAFC, Gam_specific) %>%
  arrange(-abs(Max_aMAFC)) %>%
  print(n=40)

plot_df$Chrom


plot_df %>%
  filter(abs(Max_aMAFC) > 1) %>%
  filter(Family_Grouped == 'Not CVGs') %>%
  filter(Annot == 'conserved Plasmodium protein, unknown function')

plot_df %>%
  filter(abs(Max_aMAFC) > 1) %>%
  filter(Family_Grouped == 'Not CVGs') %>%
  filter(Annot == 'Plasmodium exported protein, unknown function')

plot_df %>%
  filter(abs(Max_aMAFC) > 1) %>%
  filter(Family_Grouped == 'Not CVGs') %>%
  select(Gam_specific) %>%
  table()


table(info_df$Difpeaks_E5_B11)

heatMap_allstrains_trans <- function(aMAFC_th, cov_col, family, family_facet){

  on_col <- paste0(cov_col, '_On')
  off_col <- paste0(cov_col, '_Off')
  dif_col <- paste0(cov_col, '_Dif')

  subset_all <- plot_df %>%
    filter(abs(Max_aMAFC) > aMAFC_th) %>%
    select(Gene_id,
           Label,
           Max_aMAFC,
           matches(on_col),
           matches(off_col),
           matches(dif_col),
           Annot,
           Family,
           Family_Grouped,
           SubFamily
           ) %>%
    filter(complete.cases(.))

  if (!is.na(family)){
    subset_all <- subset_all %>%
      filter(Family == family)
  }


  ## Hierarchical Clustering
  mtx <- subset_all %>%
    select(matches(on_col),
           matches(off_col))

  ##Make hierarquical Clustering
  dmtx <- dist(scale(mtx), method = "euclidean")
  cl <- hclust(dmtx, method = 'average')
  subset_all['Cluster'] <- cutree(cl, nclust)

  ## Ordering
  if (sorting == 'clust') {
    subset_all$Label <- factor(subset_all$Label, levels = subset_all$Label[cl$order])

    ## ## Make k-means Clustering
    ## cl <- kmeans(scale(mtx), nclust)
    ## subset_all$Label <- factor(subset_all$Label, levels = subset_all$Label[cl$cluster])

  } else if (sorting == 'trans') {
    subset_all <- subset_all %>%
      arrange(desc(Max_aMAFC)) %>%
      mutate(Label = factor(Label, levels = Label))

  } else if (sorting == 'het') {
    subset_all <- subset_all %>%
      arrange(desc(dif_col)) %>%
      mutate(Label = factor(Label, levels = Label))
  }


  subset_trans <- subset_all %>%
    select(Gene_id, Max_aMAFC, Label, Annot, Family, Family_Grouped, SubFamily, Cluster)

  subset_het <- subset_all %>%
    select(Gene_id, matches(on_col), matches(off_col), Label, Annot, Family, Family_Grouped, SubFamily, Cluster)

  subset_hetDif <- subset_all %>%
    select(Gene_id, matches(dif_col), Label, Annot, Family, Family_Grouped, SubFamily, Cluster)

  melt_vars <- c('Gene_id', 'Label', 'Annot', 'Family', 'Family_Grouped', 'SubFamily', 'Cluster')
  mdf_het <- melt(subset_het, id.vars = melt_vars)
  mdf_trans <- melt(subset_trans, id.vars = melt_vars)
  mdf_hetDif <- melt(subset_hetDif, id.vars = melt_vars)

  het_plot <- hetHeatmap(mdf_het, family_facet)

  trans_plot <- transHeatmap(mdf_trans, family_facet)

  hetDif_plot <- hetDifHeatmap(mdf_hetDif, family_facet)
  hetDif_plot <- hetDif_plot + scale_fill_gradient(low = "chartreuse3",
                                                   high = "white",
                                                   na.value="white")

  #all_plot <- grid.arrange(trans_plot, hetDif_plot, het_plot, nrow = 1, widths = c(1,1,3))
  all_plot <- grid.arrange(hetDif_plot, het_plot, nrow = 1, widths = c(1,3))
  #ggsave('./Plots/MaxAMFC_Heatmaps/max_mafc_cov.svg', all_plot, device = 'svg')

}

aMAFC_th <- 3
family_facet <- T
family <- NA
cov_col <- 'Cov_500fp_manybins'
sorting <- 'clust'
nclust <- 5

##colnames(plot_df)
heatMap_allstrains_trans(aMAFC_th, cov_col, family, family_facet)

## ## Inspect NAs
## plot_df %>%
##   filter(is.na(Cov_500orf_Dif)) %>%
##   select(Gene_id, Name, contains('Cov_500orf')) %>%
##   print(n = 300)
#+end_src

** Gene Model Analysis
*** Load Data
#+begin_src R
#### Load Data ####
cov_dir <- '/home/lucas/ISGlobal/Projects/Phd_Project/ChIP_Seq/RPKMs_normInput/'

## Coverage
gm_12B <- read_csv(paste0(cov_dir, '1.2B_me_sort_q5_RPKMs_normInput_5binned_cov_2prevpost.csv'))
gm_10G <- read_csv(paste0(cov_dir, '10G_me_sort_q5_RPKMs_normInput_5binned_cov_2prevpost.csv'))
gm_A7 <- read_csv(paste0(cov_dir, 'A7K9_me_sort_q5_RPKMs_normInput_5binned_cov_2prevpost.csv'))
gm_E5 <- read_csv(paste0(cov_dir, 'E5K9_me_sort_q5_RPKMs_normInput_5binned_cov_2prevpost.csv'))
gm_B11 <- read_csv(paste0(cov_dir, 'B11_me_sort_q5_RPKMs_normInput_5binned_cov_2prevpost.csv'))


gm_strains <- list(df12B=gm_12B,
                df10G=gm_10G,
                dfA7=gm_A7,
                dfE5=gm_E5,
                dfB11=gm_B11
                )

## Change dfs in a list
gm_strains <- lapply(gm_strains, function(df) {
    colnames(df)[1] <- "Gene_id"
    df
})

## Convert list into individual objects again
list2env(gm_strains, envir=.GlobalEnv)

##Create numeric non-na mtxs
nona.mtxs <- lapply(gm_strains, function(df) {
    mtx <- as.matrix(df[complete.cases(df),-1])
    rownames(mtx) <- df[complete.cases(df),1] %>% pull()
    mtx
})



nona_gm_strains <- lapply(gm_strains, function(tibble) {
  tibble %>%
    filter(complete.cases(tibble))
  tibble
})


names(nona.mtxs) <- c("mtx12B", "mtx10G", 'mtxA7', 'mtxE5', 'mtxB11')
names(nona_gm_strains) <- c('nona_12B', 'nona_10G', 'nona_A7', 'nona_E5', 'nona_B11')

## Create side-by-side matrices
#mtx_12b10g <- cbind(nona.mtxs$mtx12B, nona.mtxs$mtx10G)

mtx_all <- cbind(nona.mtxs$mtx12B,
                 nona.mtxs$mtx10G,
                 nona.mtxs$mtxA7,
                 nona.mtxs$mtxE5,
                 nona.mtxs$mtxB11
                 )

colnames(mtx_all) <- 1:dim(mtx_all)[2]

bins <- paste0('bin', c(1:23))
all_cols <- c(paste0(bins, '_12B'),
              paste0(bins, '_10G'),
              paste0(bins, '_A7'),
              paste0(bins, '_E5'),
              paste0(bins, '_B11')
              )

gmodel_all <- gm_strains$df12B %>%
  full_join(gm_strains$df10G, by = 'Gene_id') %>%
  full_join(gm_strains$dfA7, by = 'Gene_id') %>%
  full_join(gm_strains$dfE5, by = 'Gene_id') %>%
  full_join(gm_strains$dfB11, by = 'Gene_id') %>%
  setNames(c('Gene_id', all_cols))

nona_gm_all <- gmodel_all %>%
  filter(complete.cases(gmodel_all))
#+end_src
*** PCA
#+begin_src R
## Clonally Variant genes

#cvgDF <- geneDFnona[geneDFnona$Epi != "non-variant",]
cvgDF <- nona_gm_all %>%
  left_join(info_df)



#cvg_mtx <- dif_12b10g[rownames(dif_12b10g) %in% cvgDF$Gene_id,]
cvg_mtx <- cvgDF %>%
  filter(Variant) %>%
  select(contains('bin'))

cvg_pca <- prcomp(cvg_mtx)
cvg_pca_df <- as.data.frame(cvg_pca$x[, c(1,2)])
cvg_pca_df <- cbind(cvg_pca_df, cvgDF %>% filter(Variant))
#alpha <- sapply(dif_pca_df$Epi == "non-variant", function(x) if (x) {0.1} else {1})


## All genes, filtered by transcription

trans_th <- 0

gm_trans <- maxTrans_df %>%
  left_join(gmodel_all) %>%
  left_join(info_df) %>%
  filter(abs(Max_aMAFC) > trans_th) %>%
  filter(across(contains('bin'), complete.cases))

gm_trans_mtx <- gm_trans %>%
  select(contains('bin'))

gm_trans_pca <- prcomp(gm_trans_mtx)
gm_trans_df <- as_tibble(gm_trans_pca$x[, c(1,2)])
gm_trans <- bind_cols(gm_trans_df,  gm_trans)

## Create 'fixed' color palette
col_factor <- factor(unique(analysis_df$Family_Grouped),
                     levels=c('Not CVGs',
                              'Other CVGs',
                              'FIKK',
                              'HYP',
                              'PHIST',
                              'STEVOR',
                              'RIFIN',
                              'VAR'))

my_colors <- c('gray', scales::viridis_pal()(7))
names(my_colors) <- levels(col_factor)
my_scale2 <- scale_color_manual(name = "Family_Grouped", values = my_colors)

#### PCA plots ####
## All-genes, transcription filter
p <- ggplot(gm_trans, aes(x=PC1, y=PC2, color = Family_Grouped))
p <- p + geom_point() + my_scale2
p

ggsave('./Plots/pca_families.svg', p, device = 'svg')

p <- ggplot(gm_trans, aes(x=PC1, y=PC2, color = Gam_specific))
p <- p + geom_point()
p

p <- ggplot(gm_trans, aes(x=PC1, y=PC2, color = Max_aMAFC))
p <- p + geom_point()
p <- p + scale_color_gradient2(midpoint = 0, low="red", mid = "black", high="green")
p

## CVGs
p <- ggplot(cvg_pca_df, aes(x=PC1, y=PC2, color = Family_Grouped))
p <- p + geom_point() + my_scale2
p

p <- ggplot(cvg_pca_df, aes(x=PC1, y=PC2, color = Gam_specific))
p <- p + geom_point()
p

p <- ggplot(cvg_pca_df, aes(x=PC1, y=PC2, color = Variant))
p <- p + geom_point()
p <- p
p

#+end_src
*** Heatmap function
#+begin_src R
customHeatmap <- function(df, family_facet, limits){
  df <- melt(df)
  p <- ggplot(df, aes(x = variable, y = Gene_id, fill = value)) +
    geom_tile(colour="snow3",size=0.10) +
    scale_fill_gradient2(midpoint = 0,
                         low = "green",
                         mid = "black",
                         high = "red",
                         limits = limits,
                         oob=squish) +
    theme(
      strip.background = element_blank(),
      axis.title = element_blank(),
      strip.text.x = element_blank(),
      axis.line.x = element_blank(),
      axis.ticks.x = element_blank(),
      axis.text.x = element_blank())
  if (family_facet){p <- p+facet_grid(vars(Family), scales = "free", space = "free")}
  p
}
#+end_src
*** Difference approach
#+begin_src R
## Absolute value of difference
#heatDF <- cbind(hetdifDF[,-3], abs(hetdif_mtx))

gm_dif_heatmap <- function(contrast, trans_th, difpeaks, family_facet){
  difpeaks_col <- paste0('Difpeaks_', contrast[1], '_', contrast[2])
  trans_col <- paste0(contrast[1], '-', contrast[2], '_MaxVal')

  gm_dif <- nona_gm_all %>%
    left_join(info_df) %>%
    left_join(trans_df) %>%
    filter(abs(get(trans_col)) > trans_th)

  if (difpeaks) {gm_dif <- gm_dif %>% filter(get(difpeaks_col))}

  x <- gm_dif %>%
    select(contains(contrast[1]) & contains('bin'))

  y <- gm_dif %>%
    select(contains(contrast[2]) & contains('bin'))

  mtx <- abs(x-y)

  out_df <- gm_dif %>%
    select(-contains('bin'), -contains('MaxVal'), -contains('MaxTime')) %>%
    bind_cols(mtx)

  vals <- out_df %>%
    select(contains('bin')) %>%
    pull()

  ## Make hierarquical Clustering
  dmtx <- dist(mtx, method = "euclidean")
  cl <- hclust(dmtx, method = 'average')
  out_df$Gene_id <- factor(out_df$Gene_id, levels = out_df$Gene_id[cl$order])
  customHeatmap(out_df, family_facet, c(min(vals),max(vals)))
}

contrast <- c('12B', '10G')
trans_th <- 1
difpeaks <- F
family_facet <- F

gm_dif_heatmap(contrast, trans_th, difpeaks, family_facet)
#+end_src
*** Side by Side approach
#+begin_src R :results graphics :file heatmap1.png
#difpeak_mtx <- mtx_12b10g[rownames(mtx_12b10g) %in% hetdifgenes,]
#heatDF <- cbind(hetdifDF[,-4], difpeak_mtx)

gm_sidebyside_heatmap <- function(contrast, family_facet, trans_th){
  trans_col <- paste0(contrast[1], '-', contrast[2], '_MaxVal')

  gm_df <- nona_gm_all %>%
    select(Gene_id, contains(contrast)) %>%
    left_join(info_df, by = 'Gene_id') %>%
    left_join(trans_df, by = 'Gene_id') %>%
    filter(abs(get(trans_col)) > trans_th)

  gm_mtx <- gm_df %>%
    select(contains('bin'))


  ## Make hierarquical Clustering
  dmtx <- dist(gm_mtx, method = "euclidean")
  cl <- hclust(dmtx, method = 'complete')
  gm_df$Gene_id <- factor(gm_df$Gene_id, levels = gm_df$Gene_id[cl$order])

  #customHeatmap(gm_df, c(min(gm_mtx), max(gm_mtx)))

  #head(gm_df)
  mdf <- melt(gm_df %>% select(-c(contains('MaxVal'), contains('MaxTime'))))
  mdf["Strain"] <- sapply(mdf$variable, function(x) strsplit(as.character(x), split = "_", fixed = TRUE)[[1]][2])

  p <- ggplot(mdf, aes(x = variable, y = Gene_id, fill = value)) +

    geom_tile(colour="snow3") +
              #size=0.10,
              #height=.9) +

    scale_fill_gradient2(midpoint = 0,
                         low = "white",
                         high = "red") +

    scale_y_discrete(position = "right") +

    theme(
      strip.background = element_blank(),
      axis.title = element_blank(),
      #strip.text.x = element_blank(),
      axis.line.x = element_blank(),
      axis.ticks.x = element_blank(),
      axis.text.x = element_blank()) +

    facet_grid(~Strain,
               scales="free_x",
               space="free")

  if (family_facet){p <- p+facet_grid(vars(Family), vars(Strain), scales = "free", space = "free")}

  p

}

contrast <- c('E5', 'B11')
family_facet <- F
trans_th <- 1.5

gm_sidebyside_heatmap(contrast, family_facet, trans_th)


##ggsave("/mnt/Disc4T/Projects/PhD_Project/dif12b_10g_heatmap.png", p,
##       device = "png", width = 40, height = 20,  units = "cm")


## Labeling each row of the melted df
## n <- dim(heatDF)[1]
## strain <- factor(c(rep("12Bpre2", n),
##                    rep("12Bpre2", n),
##                    rep("12Bpre1", n),
##                    rep("12Bpre1", n),
##                    rep(rep("12Bprom", 5), n),
##                    rep(rep("12Bbody", 5), n),
##                    rep(rep("12Bterm", 5), n),
##                    rep("12Bpost1", n),
##                    rep("12Bpost1", n),
##                    rep("12Bpost2", n),
##                    rep("12Bpost2", n),

##                    rep("10Gpre2", n),
##                    rep("10Gpre2", n),
##                    rep("10Gpre1", n),
##                    rep("10Gpre1", n),
##                    rep(rep("10Gprom", 5), n),
##                    rep(rep("10Gbody", 5), n),
##                    rep(rep("10Gterm", 5), n),
##                    rep("10Gpost1", n),
##                    rep("10Gpost1", n),
##                    rep("10Gpost2", n),
##                    rep("10Gpost2", n)),

##                  levels = c("12Bpre2", "12Bpre1",
##                             "12Bprom", "12Bbody", "12Bterm",
##                             "12Bpost1", "12Bpost2",
##                             "10Gpre2", "10Gpre1",
##                             "10Gprom", "10Gbody", "10Gterm",
##                             "10Gpost1", "10Gpost2"))
#+end_src
*** Max trans Dif. Approach
#+begin_src R
## tdf <- maxTrans_df %>%
##   select(Gene_id, Max_aMAFC, On_trans, Off_trans, Is_3D7B)

tdf <- transFC_df_noNAs %>%
  select(Gene_id, Max_aMAFC, On_trans, Off_trans, Is_3D7B)

gmodel_all_pos <- gmodel_all %>%
  mutate(across(-Gene_id, ~ ifelse(.x > 0, .x, 0)))

## Create empty DF
hetcols <- gmodel_all %>%
  select(contains('12B') & contains('bin')) %>%
  colnames(.) %>%
  gsub('12B', '', ., fixed=TRUE)

col_names <- c('Gene_id',
               paste0(hetcols, 'On'),
               paste0(hetcols, 'Off'),
               paste0(hetcols, 'Dif'))

cn <- setNames(rep('', length(col_names)), col_names)
df <- bind_rows(cn)[0,]

## Traverse max trans. df and get coverage cols

for (i in 1:dim(tdf)[1]){

  gid <- as.character(tdf$Gene_id[i])
  on <- tdf$On_trans[i]
  off <- tdf$Off_trans[i]

  ## Select contrast in which difference sign must be switched
  ## contrast <- paste0(on, '-', off)
  ## positive_contrasts <- c(
  ##   '12B-10G', '12B-A7', '12B-E5', '12B-B11',
  ##   '10G-A7', '10G-E5', '10G-B11',
  ##   'A7-E5', 'A7-B11',
  ##   'B11-E5'
  ## )

  ## ifelse(
  ##   contrast %in% positive_contrasts,
  ##   neg_dif <- FALSE,
  ##   neg_dif <- TRUE
  ## )

  ### Main Loop
  if (gid %in% gmodel_all_pos$Gene_id & !is.na(on) & !is.na(off)){

    onvect <- gmodel_all_pos %>%
      filter(Gene_id == gid) %>%
      select(contains(on))

    offvect <- gmodel_all_pos %>%
      filter(Gene_id == gid) %>%
      select(contains(off))

    diffvect <- onvect-offvect
    #if (neg_dif) {diffvect <- -diffvect}

    row <- c(gid,
             unlist(onvect, use.names = F),
             unlist(offvect, use.names = F),
             unlist(onvect-offvect, use.names = F))
    row <- setNames(row, col_names)
    df <- df %>% add_row(bind_rows(row))
  }
}

df <- df %>%
  mutate(across(-Gene_id, as.numeric))

df %>% select(contains('Off'))
tdf %>% filter(Gene_id == 'PF3D7_0832200')
gmodel_all %>%
  filter(Gene_id == 'PF3D7_0832200') %>%
  select(contains('B11'))

gm_pos_maxtrans <- df %>%
  full_join(tdf, by = 'Gene_id') %>%
  left_join(info_df) %>%
  mutate(Max_aMAFC = abs(Max_aMAFC))

#+end_src
*** Max trans Dif. Heatmap
#+begin_src R

heatMap_allstrains_trans <- function(df, aMAFC_th, family, family_facet){

  ## Returns a list object with list = (df, plot)

  subset_all <- df %>%
    filter(abs(Max_aMAFC) > aMAFC_th)

  if (!is.na(family)){
    subset_all <- subset_all %>%
      filter(Family == family)
  }

  subset_all <- subset_all %>%
    filter(across(
      contains('bin'),
      complete.cases
    ))

  ## mtx <- subset_all %>%
  ##   select(contains('bin'))

  mtx <- subset_all %>%
    select(contains('bin'),
           -contains('bin1_'),
           -contains('bin2_'),
           -contains('bin3_'),
           -contains('bin4_'),
           -contains('bin20_'),
           -contains('bin21_'),
           -contains('bin22_'),
           -contains('bin23_'),
           )

  ## Make hierarquical Clustering
  dmtx <- dist(mtx, method = "euclidean")
  cl <- hclust(dmtx, method = 'complete')
  subset_all$Label <- factor(subset_all$Label, levels = subset_all$Label[cl$order])
  subset_all['Cluster'] <- cutree(cl, nclust)
  subset_all$Label <- factor(subset_all$Label, levels = subset_all$Label[cl$order])

  subset_trans <- subset_all %>%
    select(Gene_id, Max_aMAFC, Label, Name, Annot, Family, SubFamily, Cluster)

  subset_het_on <- subset_all %>%
    select(Gene_id, Label,
           contains('On') & contains('bin'),
           Name, Annot, Family, SubFamily, Cluster)

  subset_het_off <- subset_all %>%
    select(Gene_id, Label,
           contains('Off') & contains('bin'),
           Name, Annot, Family, SubFamily, Cluster)

  ##write_csv(subset_het %>% select(-contains('bin')) %>% arrange(Cluster), './het_trans_genemodel.csv')

  subset_hetDif <- subset_all %>%
    select(Gene_id, contains('_Dif'), Label, Name, Annot, Family, SubFamily, Cluster)

  melt_vars <- c('Gene_id', 'Label', 'Name', 'Annot', 'Family', 'SubFamily', 'Cluster')
  mdf_het_on <- melt(subset_het_on, id.vars = melt_vars)
  mdf_het_off <- melt(subset_het_off, id.vars = melt_vars)
  mdf_trans <- melt(subset_trans, id.vars = melt_vars)
  mdf_hetDif <- melt(subset_hetDif, id.vars = melt_vars)

  het_plot_on <- hetHeatmap(mdf_het_on, family_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free") +
    theme(
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank(),

      panel.border=element_blank(),
      panel.grid.major=element_blank(),

      strip.background = element_blank(),
      strip.text.x = element_blank(),
      strip.text.y = element_blank(),
      )


  het_plot_off <- hetHeatmap(mdf_het_off, family_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free")

  trans_plot <- transHeatmap(mdf_trans, family_facet) +
    scale_fill_gradient(low = "white",
                        high = "blue",
                        na.value="gray",
                        limits = c(0,NA))  +
    facet_grid(Cluster ~., scales = "free_y", space = "free")

  hetDif_plot <- hetDifHeatmap(mdf_hetDif, family_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free")

  all_plot <- grid.arrange(hetDif_plot, het_plot_on, het_plot_off, nrow = 1, widths = c(1,1,2))

  result <- list(df = subset_all %>% arrange(Label), plot = all_plot)
  return(result)
}


##info_df %>% select(Family) %>% pull() %>% unique()

aMAFC_th <- 2
family_facet <- F
family <- NA
nclust <- 5
df <- gm_pos_maxtrans ##%>% filter(is.na(Family))

x <- heatMap_allstrains_trans(df, aMAFC_th, family, family_facet)
ggsave('./Plots/current_genemodel_plot_with_neighbors.pdf', x$plot, device = 'pdf', height = 80, width = 60, units = 'cm')

x$df %>%
  select(-contains('bin')) %>%
  select(Label, Annot, Family)

all_gmodel_heat <- x$df

trans_df %>%
  filter(Gene_id == 'PF3D7_0713100') %>%
  print(width = 400)

## Plot by Family

for (family in info_df %>% select(Family) %>% pull() %>% unique()){

  aMAFC_th <- 1
  family_facet <- F
  nclust <- 3
  df <- gm_pos_maxtrans
  n <- dim(gm_pos_maxtrans %>% filter(Family == family & abs(Max_aMAFC) > aMAFC_th))[1]

  if (n >= nclust & !is.na(family)){
    plotname <- paste0('./Plots/Gene_Model/genemodel_positive_complete_', family, '.svg')
    csvname <- paste0('./Gene_Model_Tables/', family, '_log2trans_', aMAFC_th, '.csv')

    x <- heatMap_allstrains_trans(gm_pos_maxtrans, aMAFC_th, family, family_facet)

    ggsave(plotname, x$plot, device = 'svg')
    write_csv(x$df %>% select(-contains('bin')), csvname)
  }
}

## Plot the "NA" Family

aMAFC_th <- 2
family_facet <- F
family <- NA
nclust <- 3
df <- gm_pos_maxtrans %>%
  filter(is.na(Family) & !Is_tRNA)
x <- heatMap_allstrains_trans(df, aMAFC_th, family, family_facet)
plotname <- paste0('./Plots/Gene_Model/genemodel_positive_complete_', family, '.svg')
csvname <- paste0('./Gene_Model_Tables/', family, '_log2trans_', aMAFC_th, '.csv')
ggsave(plotname, x$plot, device = 'svg')
write_csv(x$df %>% select(-contains('bin')), csvname)
#+end_src
*** K-Means Functions
#+begin_src R
test_kmeans <- function(mtx){

  ## Set max k for k analysis
  maxk <- mtx %>% distinct() %>% nrow()
  maxk <- min(maxk, 20)

  ## Elbow method, keep reducing maxk if it fails
  while (maxk > 0) {
    test <- try(
      ## elbow plot
      elbow <- fviz_nbclust(mtx, kmeans, method = "wss", k.max = maxk) +
        labs(subtitle = "Elbow method")
    , silent = T)
    ## If kmax throws an error, reduce it by 1
    if (class(test)[1] != "gg") {
      maxk <- maxk -1
    } else {
      break
    }
  }

  ## Silhouette method (if kmax works for elbow it will work for silhouette)
  silhouette <- fviz_nbclust(mtx, kmeans, method = "silhouette", k.max = maxk) +
    labs(subtitle = "Silhouette method")

  result = list(elbow = elbow, silhouette = silhouette)
}

heatMap_allstrains_kmeans <- function(df, aFC_th, fam, fam_facet, nclu, tbar, fbar){

  ## Returns a list object with list = (df, plot)

  subset_all <- df %>%
    filter(abs(Max_aMAFC) > aFC_th)

  if (!is.na(fam)){
    subset_all <- subset_all %>%
      filter(Family == fam)
  }

  subset_all <- subset_all %>%
    filter(across(
      contains('bin'),
      complete.cases
    ))

  mtx <- subset_all %>%
    select(contains('bin'),
           -contains('bin1_'),
           -contains('bin2_'),
           -contains('bin3_'),
           -contains('bin4_'),
           -contains('bin20_'),
           -contains('bin21_'),
           -contains('bin22_'),
           -contains('bin23_'),
           )
    #select(contains('On'), contains('Off'))
    #select(contains('Dif'))

  ## Make K-means Clustering

  km_fit <- kmeans(mtx, nclu, iter.max = 1000)
  cl <- km_fit$cluster
  subset_all['Cluster'] <- cl

  ## Test optimal k's
  k_tests <- test_kmeans(mtx)
  elbow <- k_tests$elbow
  silhouette <- k_tests$silhouette

  ## Subset DF for different heatmaps

  subset_trans <- subset_all %>%
    select(Gene_id, Max_aMAFC, Label, Name, Annot, Family, SubFamily, Cluster)

  subset_het_on <- subset_all %>%
    select(Gene_id, Label,
           contains('On') & contains('bin'),
           Name, Annot, Family, SubFamily, Cluster)

  subset_het_off <- subset_all %>%
    select(Gene_id, Label,
           contains('Off') & contains('bin'),
           Name, Annot, Family, SubFamily, Cluster)

  subset_hetDif <- subset_all %>%
    select(Gene_id, contains('_Dif'), Label, Name, Annot, Family, SubFamily, Cluster)

  subset_fambar <- subset_all %>%
    select(Gene_id, Label,
           Family_Grouped,
           Name, Annot, Family, SubFamily, Cluster) %>%
    #mutate(Label = factor(Label, levels = Label)) %>%
    replace_na(list(Family_Grouped = 'Non CVGs'))

  ## Melt Data-Frames

  melt_vars <- c('Gene_id', 'Label', 'Name', 'Annot', 'Family', 'SubFamily', 'Cluster')
  mdf_het_on <- melt(subset_het_on, id.vars = melt_vars)
  mdf_het_off <- melt(subset_het_off, id.vars = melt_vars)
  mdf_trans <- melt(subset_trans, id.vars = melt_vars)
  mdf_hetDif <- melt(subset_hetDif, id.vars = melt_vars)
  mdf_fambar <- melt(subset_fambar, id.vars = melt_vars)

  head(mdf_fambar)

  ## Create individual Heatmaps

  het_plot_on <- hetHeatmap(mdf_het_on, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free") +
    theme(axis.text.x = element_blank())

  het_plot_off <- hetHeatmap(mdf_het_off, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free")+
    theme(axis.text.x = element_blank())

  trans_plot <- transHeatmap(mdf_trans, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free") +
    theme(axis.text.x = element_blank()) +
    scale_fill_gradient(low = "white",
                        high = "blue",
                        na.value="gray",
                        limits = c(0,NA))

  hetDif_plot <- hetDifHeatmap(mdf_hetDif, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free") +
    theme(axis.text.x = element_blank())

  fambar_plot <- family_heatmap(mdf_fambar) +
    facet_grid(Cluster ~., scales = "free_y", space = "free")

  ## Create fake Heatmap for Labels

  labels_df <- mdf_trans %>%
    select(Label, Family, Cluster) %>%
    mutate(value = 1, variable = 'fake_val')

  labels_plot <- hetHeatmap(labels_df, fam_facet) +
    facet_grid(Cluster ~., scales = "free_y", space = "free") +
    theme(
      axis.text.y = element_text(),
      axis.ticks.y = element_line(),
      axis.text.x = element_blank()
    )

  ## Arrange plots (with or without transcription heatmap and fambar)

  pl_wd <- tibble(P_names = c('trans', 'het_dif', 'het_on', 'het_off', 'fambar', 'labels'),
                  Plots = list(
                       trans_plot,
                       hetDif_plot,
                       het_plot_on,
                       het_plot_off,
                       fambar_plot,
                       labels_plot),
                  widths = c(0.1,1,1,1,0.1,1))

  if (!tbar){pl_wd <- pl_wd %>% filter(P_names != 'trans')}
  if (!fbar){pl_wd <- pl_wd %>% filter(P_names != 'fambar')}

  all_plot <- grid.arrange(grobs = pl_wd$Plots, nrow = 1, widths = pl_wd$widths)

  ## Create output
  result <- list(df = subset_all, plot = all_plot, elbow = elbow, silhouette = silhouette)
  return(result)
}



## set.seed(123)

## x <- heatMap_allstrains_kmeans(
##   df = gm_pos_maxtrans,
##   aFC_th = 2,
##   fam = NA,
##   fam_facet = F,
##   nclu = 7,
##   tbar = F,
##   fbar = T
## )

#+end_src
*** K-means clustering
#+begin_src R
## Current Heatmap

set.seed(123)

x <- heatMap_allstrains_kmeans(
  df = gm_pos_maxtrans,
  aFC_th = 2,
  fam = NA,
  fam_facet = F,
  nclu = 7,
  tbar = F,
  fbar = T
)

## Save resulting Heatmap and DF

ggsave('./Plots/current_genemodel_plot_with_neighbors_Kmeans_021121.pdf', x$plot, device = 'pdf', height = 80, width = 60, units = 'cm')

all_gmodel_kmeans <- x$df

all_gmodel_kmeans %>%
  select(-contains('bin')) %>%
  write_tsv('current_kmeans_clusters.tsv')

## Check output
x$elbow
x$silhouette
plot(x$plot)

## Some tests
cl1 <- all_gmodel_kmeans %>%
  filter(Cluster == 1)

cl1$Label[order(cl1$Label)]

cl1$Label
cl1 %>%
  arrange(desc(Label)) %>%
  select(Label)


all_gmodel_kmeans %>%
  select(-contains('bin')) %>%
  group_by(Cluster) %>%
  summarize(Mean_aMAFC = mean(Max_aMAFC))


#+end_src
*** Families Bar (deprecated)
#+begin_src R
## famdf <- all_gmodel_kmeans %>%
##   arrange(Cluster, desc(Label))

## famdf <- famdf %>%
##   mutate(Label = factor(Label, levels = Label)) %>%
##   select(Label, Family_Grouped) %>%
##   replace_na(list(Family = 'Non CVGs'))

## mfamdf <- melt(famdf, id='Label')

## fam_bar <- ggplot(mfamdf, aes(x = variable, y = Label)) +
##   geom_tile(aes(fill = value)) +
##   #geom_text(aes(label=value)) +
##   my_scale +
##   scale_y_discrete(limits=(rev(levels(famdf$Label)))) +
##   theme(
##       panel.border=element_blank(),
##       panel.grid.major=element_blank(),
##       #strip.background = element_blank(),
##       strip.text.x = element_blank(),
##     )

## fam_bar

## ggsave('./Plots/Kmeans/families_bar.pdf', fam_bar, device = 'pdf')
#+end_src
*** K-means by family
#+begin_src R
## Plot by Family

set.seed(123)

info_df %>%
  count(Family)

fam_plot <- heatMap_allstrains_kmeans(
  df = gm_pos_maxtrans %>%
    mutate(Label = paste(Gene_id, SubFamily, sep = ': ')),
  aFC_th = 0,
  fam = 'CLAG',
  fam_facet = F,
  nclu = 3,
  tbar = T,
  fbar = F
)


fam_plot$elbow
fam_plot$silhouette
plot(fam_plot$plot)

## Current famillies and k's
fams_ks <- list(
  c('ACS', 3),
  c('CLAG', 2),
  c('HYP', 3),
  c('OTHER', 7),
  c('PFMC-2TM', 3),
  c('PHIST', 6),
  c('RIFIN', 5),
  c('STEVOR', 3),
  c('VAR', 5)
)

for (fam_k in fams_ks){

  print(fam_k)

  fam_plot <- heatMap_allstrains_kmeans(
    df = gm_pos_maxtrans %>%
      mutate(Label = paste(Gene_id, SubFamily, sep = ': ')),
    aFC_th = 0,
    fam = fam_k[1],
    fam_facet = F,
    nclu = as.numeric(fam_k[2]),
    tbar = T,
    fbar = F
  )

  ggsave(paste0('./Plots/Kmeans/Families/', fam_k[1], '_aMAFC', aMAFC_th, '_k', fam_k[2], '.pdf'),
         fam_plot$plot, width = 60, units = 'cm', device = 'pdf')
  ggsave(paste0('./Plots/Kmeans/Families/', fam_k[1], '_elbow', '.pdf'),
         fam_plot$elbow, device = 'pdf')
  ggsave(paste0('./Plots/Kmeans/Families/', fam_k[1], '_silhouette', '.pdf'),
         fam_plot$silhouette, device = 'pdf')
}



for (family in info_df %>% select(Family) %>% pull() %>% unique()){

  #family <- 'RIFIN'
  aMAFC_th <- 0
  family_facet <- F
  df <- gm_pos_maxtrans
  n <- dim(gm_pos_maxtrans %>% filter(Family == family & abs(Max_aMAFC) > aMAFC_th))[1]
  nclust <- n%/%10

  if (n >= nclust & !is.na(family)){
    plotname <- paste0('./Plots/Gene_Model/genemodel_positive_complete_', family, '.svg')
    csvname <- paste0('./Gene_Model_Tables/', family, '_log2trans_', aMAFC_th, '.csv')

    x <- heatMap_allstrains_kmeans(gm_pos_maxtrans, aMAFC_th, family, family_facet, nclust)
    #ggsave(plotname, x$plot, device = 'svg')
    #write_csv(x$df %>% select(-contains('bin')), csvname)
  }
}

## Plot the "NA" Family

aMAFC_th <- 2
family_facet <- F
family <- NA
nclust <- 3
df <- gm_pos_maxtrans %>%
  filter(is.na(Family) & !Is_tRNA)
x <- heatMap_allstrains_trans(df, aMAFC_th, family, family_facet)
plotname <- paste0('./Plots/Gene_Model/genemodel_positive_complete_', family, '.svg')
csvname <- paste0('./Gene_Model_Tables/', family, '_log2trans_', aMAFC_th, '.csv')
ggsave(plotname, x$plot, device = 'svg')
write_csv(x$df %>% select(-contains('bin')), csvname)

#+end_src
*** Cluster Tendency Plots
#+begin_src R
tendency_plot_loess <- function(df, cluster){

  max_y <- max(df %>% select(contains('_On') | contains('_Off')))
  min_y <- min(df %>% select(contains('_On') | contains('_Off')))

  plt_df <-  df %>%
    select(Gene_id, contains('On'), contains('Off'), Cluster) %>%
    filter(Cluster == cluster) %>%
    select(-Cluster)

  plot_mdf <- melt(plt_df)
  head(plot_mdf)

  plot_mdf['State'] <- sapply(plot_mdf$variable, function(x) str_split(x, '_')[[1]][2])
  plot_mdf <- plot_mdf %>%
    mutate(variable = as.numeric(sub("bin(\\d+).*", "\\1", variable)))

  head(plot_mdf)

  p <- ggplot(plot_mdf, aes(x = variable, y = value, group = State))
  p <- p + geom_smooth(aes(color = State), method = 'loess', level = 0.95)
  p <- p + scale_color_manual(values = c('red', 'green'))
  p <- p + ggtitle(paste0('Cluster ', cluster))
  p <- p + geom_vline(xintercept = 4.5, linetype="solid")
  p <- p + geom_vline(xintercept = 9.5, linetype="dotted")
  p <- p + geom_vline(xintercept = 14.5, linetype="dotted")
  p <- p + geom_vline(xintercept = 19.5, linetype="solid")
  p <- p + theme_classic()
  p <- p + theme(axis.title.x = element_blank())
  p <- p + ylab('H3K9me3 enrichment')
  p <- p + scale_x_continuous(
             breaks=c(2.5,4.5,7,12,17,19.5, 21.5),
             labels=c('Prev\nGenes', "ATG", "5'UTR", "CDS", "3'UTR", "END", 'Post\nGenes'),
             expand = c(0, 0)
           )
  p <- p + scale_y_continuous(limits = c(min_y-0.3, max_y+0.3), expand = c(0, 0))
  p
}

tendency_plot_mean_sd <- function(df, cluster){

  onoff_df <- df %>%
    select(-contains('_Dif'))

  mean_df <- onoff_df %>%
    group_by(Cluster) %>%
    summarize(across(contains('bin'), list(mean))) %>%
    pivot_longer(!Cluster, values_to = 'mean')

  sd_df <- onoff_df %>%
    group_by(Cluster) %>%
    summarize(across(contains('bin'), list(sd))) %>%
    pivot_longer(!Cluster, values_to = 'sd')

  plot_df <- mean_df %>%
    full_join(sd_df, by = c('Cluster', 'name'))

  max_y <- max(plot_df$mean + plot_df$sd)
  min_y <- min(plot_df$mean - plot_df$sd)

  plot_df <- plot_df %>%
    filter(Cluster == cluster) %>%
    select(-Cluster)

  plot_df['State'] <- sapply(plot_df$name, function(x) str_split(x, '_')[[1]][2])
  plot_mdf <- plot_df %>%
    mutate(variable = as.numeric(sub("bin(\\d+).*", "\\1", name)))

  #print(min_y)

  p <- ggplot(plot_mdf, aes(x = variable, group = State))
  p <- p + geom_line(aes(y = mean, color = State), size = 1)
  p <- p + geom_ribbon(aes(y = mean, ymin = mean - sd, ymax = mean + sd, fill = State),
                       alpha = .2)
  p <- p + scale_color_manual(values = c('red', 'green'))
  p <- p + ggtitle(paste0('Cluster ', cluster))
  p <- p + geom_vline(xintercept = 4.5, linetype="solid")
  p <- p + geom_vline(xintercept = 9.5, linetype="dotted")
  p <- p + geom_vline(xintercept = 14.5, linetype="dotted")
  p <- p + geom_vline(xintercept = 19.5, linetype="solid")
  p <- p + theme_classic()
  p <- p + theme(axis.title.x = element_blank())
  p <- p + ylab('H3K9me3 enrichment')
  p <- p + scale_x_continuous(
             breaks=c(2.5,4.5,7,12,17,19.5, 21.5),
             labels=c('Prev\nGenes', "ATG", "5'UTR", "CDS", "3'UTR", "END", 'Post\nGenes'),
             expand = c(0, 0)
           )
  p <- p + scale_y_continuous(limits = c(min_y, max_y), expand = c(0, 0))
  p
}


## 1 cluster plots
tendency_plot_loess(all_gmodel_heat, 6)
tendency_plot_loess(all_gmodel_kmeans, 6)
tendency_plot_mean_sd(all_gmodel_kmeans, 6)

## All cluster plots, overlapped

## Hierarchical clustering loess
nclust <- length(unique(all_gmodel_heat$Cluster))

plots <- lapply(1:nclust, function(x) tendency_plot_loess(all_gmodel_heat, x))
clusters_plot <- grid.arrange(grobs = plots, nrow = length(plots), ncol = 1)

ggsave(
  paste0('./Plots/clusters_plot_overlapped_with_neighbors.pdf'),
  clusters_plot,
  height = 80, width = 15, units = 'cm',
  device = 'pdf'
)


## K-means loess
plots <- lapply(1:nclust, function(x) tendency_plot_loess(all_gmodel_kmeans, x))
clusters_plot <- grid.arrange(grobs = plots, nrow = length(plots), ncol = 1)

ggsave(
  paste0('./Plots/clusters_plot_overlapped_with_neighbors_kmeans.pdf'),
  clusters_plot,
  height = 80, width = 15, units = 'cm',
  device = 'pdf'
)

## K-means means +- sd
plots <- lapply(1:nclust, function(x) tendency_plot_mean_sd(all_gmodel_kmeans, x))
clusters_plot <- grid.arrange(grobs = plots, nrow = length(plots), ncol = 1)

ggsave(
  paste0('./Plots/clusters_plot_overlapped_with_neighbors_kmeans_means_sd.pdf'),
  clusters_plot,
  height = 80, width = 15, units = 'cm',
  device = 'pdf'
)


#+end_src
*** Box and whiskers Plots
#+begin_src R
box_df <- all_gmodel_kmeans %>%
  select(Gene_id, Max_aMAFC, Cluster)

p <- ggplot(all_gmodel_kmeans, aes(x = as.character(Cluster), y= Max_aMAFC))
p <- p + stat_boxplot(geom = "errorbar", width = 0.5) #add perpendicular whiskers
p <- p + geom_boxplot(outlier.colour="red")
p <- p + theme_classic()
p <- p + xlab('Cluster')
p <- p + ylab('Level of expression (aMAFC)')
p

ggsave(paste0('./Plots/cluster_boxplots.pdf'), p, device = 'pdf')

#+end_src
*** Cluster Donuts (to redo with kmeans clusters)
#+begin_src R
## Donut Plot

## ## Create 'fixed' color palette
## all_fams <- c('Not CVGs',
##               'Other CVGs',
##               '6-CYS',
##               'ACBP',
##               'ACS',
##               'CLAG',
##               'DNAJ',
##               'GBP',
##               'PFMC-2TM',
##               'SURFIN',
##               'FIKK',
##               'HYP',
##               'PHIST',
##               'STEVOR',
##               'RIFIN',
##               'VAR')

## col_factor <- factor(all_fams, levels=all_fams)

## my_colors <- c('gray', scales::viridis_pal()(15))
## names(my_colors) <- levels(col_factor)
## my_scale_dount <- scale_fill_manual(name = "Family_Grouped", values = my_colors)


## donut_df <- all_gmodel_heat %>%
##   mutate(Family_Dount = case_when(
##            Family %in% col_factor ~ Family,
##            Family == 'OTHER' ~ 'Other CVGs',
##            is.na(Family) ~ 'Not CVGs'))


donut_plot <- function(df, cluster) {
    x <- df %>%
      filter(Cluster == cluster)

    data <- as.data.frame(table(x$Family_Grouped))
    colnames(data) <- c('category', 'count')

    count(info_df, Family)

    ## Compute percentages
    data$fraction = data$count / sum(data$count)

    ## Compute the cumulative percentages (top of each rectangle)
    data$ymax = cumsum(data$fraction)

    ## Compute the bottom of each rectangle
    data$ymin = c(0, head(data$ymax, n=-1))

    ## Compute label position
    data$labelPosition <- (data$ymax + data$ymin) / 2

    ## Compute a good label
    data$label <- paste0(data$category, "\n value: ", data$count)

    ## Make the plot
    p <- ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category)) +
      geom_rect(color="white") +
      #geom_label( x=4.2, aes(y=labelPosition, label=label), size=3) +
      coord_polar(theta="y") + # Try to remove that to understand how the chart is built initially
      xlim(c(2, 4)) +# Try to remove that to see how to make a pie chart
      theme_void() + my_scale

    outname <- paste0('./Plots/Donuts/gmodel_hetmap_cluster_',
                      as.character(cluster),
                      '.svg')
    #ggsave(outname, p, device = 'svg')
    p
}

count(all_gmodel_kmeans, Cluster)

p1 <- donut_plot(all_gmodel_heat, 1)
p2 <- donut_plot(all_gmodel_heat, 2)
p3 <- donut_plot(all_gmodel_heat, 3)
p4 <- donut_plot(all_gmodel_heat, 4)
p5 <- donut_plot(all_gmodel_heat, 5)
p6 <- donut_plot(all_gmodel_heat, 6)
p7 <- donut_plot(all_gmodel_heat, 7)

all_donuts <- grid.arrange(p1, p2, p3, p4, p5, p6, p7,  nrow = 7, ncol = 1)
ggsave('./Plots/Donuts_with_neighbors/gmodel_heatmap_alldonuts.svg', all_donuts, device = 'svg')


## Plot all genes to get legend
## all_genes_donut <- info_df %>%
##   mutate(Family_Dount = case_when(
##            Family %in% col_factor ~ Family,
##            Family == 'OTHER' ~ 'Other CVGs',
##            is.na(Family) ~ 'Not CVGs'))


data <- as.data.frame(table(info_df$Family_Grouped))
colnames(data) <- c('category', 'count')

count(info_df, Family)

## Compute percentages
data$fraction = data$count / sum(data$count)

## Compute the cumulative percentages (top of each rectangle)
data$ymax = cumsum(data$fraction)

## Compute the bottom of each rectangle
data$ymin = c(0, head(data$ymax, n=-1))

## Compute label position
data$labelPosition <- (data$ymax + data$ymin) / 2

## Compute a good label
data$label <- paste0(data$category, "\n value: ", data$count)

## Make the plot
p <- ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category)) +
  geom_rect(color="white") +
                                        #geom_label( x=4.2, aes(y=labelPosition, label=label), size=3) +
  coord_polar(theta="y") + # Try to remove that to understand how the chart is built initially
  xlim(c(2, 4)) +# Try to remove that to see how to make a pie chart
  theme_void() + my_scale

ggsave('./Plots/Donuts/all_genes_donut.svg', p, device = 'svg')
p


## Create 'fixed' color palette
col_factor <- factor(unique(analysis_df$Family_Grouped),
                     levels=c('Not CVGs',
                              'Other CVGs',
                              'FIKK',
                              'HYP',
                              'PHIST',
                              'STEVOR',
                              'RIFIN',
                              'VAR'))

my_colors <- c('gray', scales::viridis_pal(begin = 0, end = 1)(7))
names(my_colors) <- levels(col_factor)
my_scale <- scale_fill_manual(name = "Family_Grouped", values = my_colors)
#+end_src
*** Tinkering
#+begin_src R
all_gmodel_heat %>%
  filter(Cluster == 1) %>%
  select(Gene_id) %>%
  left_join(transFC_df_noNAs) %>%
  left_join(red_df) %>%
  select(Gene_id, Max_aMAFC, On_trans, Off_trans, Is_3D7B, A7, E5, B11) %>%
  arrange(Gene_id) %>%
  print(n = 50)



red_df



transFC_df_noNAs
#+end_src
** Load Active Genes List
#+begin_src R
## Load gene state tables

state_old <- read_csv('/mnt/Disc4T/Projects/Active_gene_list/Results_Tables/gene_state_final.csv') %>%
  select(Gene_id, category_12B, category_10G)

state_new <- read_tsv('/mnt/Disc4T/Projects/Active_gene_list/New_Arrays_Results/state_df_rna25_red25_redresc40_reddw15_areaFC1_redpcntdif30_allstrains.csv')%>%
  select(Gene_id, category_A7, category_E5, category_B11)

state_df <- state_old %>%
  full_join(state_new, by = 'Gene_id') %>%
  rename_with(~ gsub('category_', 'Gene_State_', .x))


v <- c('Var_Repressed', 'Var_Repressed')
my_difstate_filter(v)

silenced <- any(grepl('Var_Repressed', state_vect)) | any(grepl('Inactive', state_vect))



## Check for which genes we have a strain in an active state and a strain in a silenced state
my_difstate_filter <- function(state_vect){
  active <- any(grepl('Active', state_vect))
  silenced <- any(grepl('Var_Repressed', state_vect)) | any(grepl('Inactive', state_vect))
  return(active & silenced)
}



state_df <- state_df %>%
  mutate(DifState = apply(select(., contains('State')), 1, my_difstate_filter))

stinfo_df <- state_df %>%
  left_join(info_df, by='Gene_id')

stinfo_df %>%
  filter(DifState) %>%
  select(Gene_id, contains('State'), Variant, Annot) %>%
  print(width = 200)


stinfo_df %>%
  filter(DifState) %>%
  count(Variant)

vars <- stinfo_df %>%
  filter(DifState) %>%
  filter(Variant) %>%
  select(Gene_id, contains('State'), Annot) %>%
  print(width = 200)

novars <- stinfo_df %>%
  filter(DifState) %>%
  filter(!Variant) %>%
  select(Gene_id, contains('State'), Annot) %>%
  print(width = 200)

vh <- gm_pos_maxtrans %>%
  filter(Gene_id %in% vars$Gene_id)

nvh <- gm_pos_maxtrans %>%
  filter(Gene_id %in% novars$Gene_id)


x <- heatMap_allstrains_kmeans(
  df = nvh,
  aFC_th = 0,
  fam = NA,
  fam_facet = F,
  nclu = 1,
  tbar = F,
  fbar = T
)

x$silhouette


#+end_src
** Gene Model Analysis No Neighboring genes (deprecated)
*** Load Data
#+begin_src R
#### Load Data ####

## ## Remove neighboring genes bins
## gmodel_noneighbors <- gmodel_all %>%
##   select(
##     -contains('bin1_'),
##     -contains('bin2_'),
##     -contains('bin3_'),
##     -contains('bin4_'),
##     -contains('bin20_'),
##     -contains('bin21_'),
##     -contains('bin22_'),
##     -contains('bin23_'),
##     )

## bins <- paste0('bin', c(1:15))
## all_cols <- c(paste0(bins, '_12B'),
##               paste0(bins, '_10G'),
##               paste0(bins, '_A7'),
##               paste0(bins, '_E5'),
##               paste0(bins, '_B11')
##               )
## gmodel_noneighbors <- gmodel_noneighbors %>%
##   set_names('Gene_id', all_cols)

## nona_gm_noneighbors <- gmodel_noneighbors %>%
##   filter(complete.cases(gmodel_noneighbors))
#+end_src
*** Difference approach
#+begin_src R
## gm_dif_heatmap <- function(contrast, trans_th, difpeaks, family_facet){
##   difpeaks_col <- paste0('Difpeaks_', contrast[1], '_', contrast[2])
##   trans_col <- paste0(contrast[1], '-', contrast[2], '_MaxVal')

##   gm_dif <- nona_gm_noneighbors %>%
##     left_join(info_df) %>%
##     left_join(trans_df) %>%
##     filter(abs(get(trans_col)) > trans_th)

##   if (difpeaks) {gm_dif <- gm_dif %>% filter(get(difpeaks_col))}

##   x <- gm_dif %>%
##     select(contains(contrast[1]) & contains('bin'))

##   y <- gm_dif %>%
##     select(contains(contrast[2]) & contains('bin'))

##   mtx <- abs(x-y)

##   out_df <- gm_dif %>%
##     select(-contains('bin'), -contains('MaxVal'), -contains('MaxTime')) %>%
##     bind_cols(mtx)

##   vals <- out_df %>%
##     select(contains('bin')) %>%
##     pull()

##   ## Make hierarquical Clustering
##   dmtx <- dist(mtx, method = "euclidean")
##   cl <- hclust(dmtx, method = 'average')
##   out_df$Gene_id <- factor(out_df$Gene_id, levels = out_df$Gene_id[cl$order])
##   customHeatmap(out_df, family_facet, c(min(vals),max(vals)))
## }

## contrast <- c('12B', '10G')
## trans_th <- 1
## difpeaks <- F
## family_facet <- F

## gm_dif_heatmap(contrast, trans_th, difpeaks, family_facet)

#+end_src
*** Side by Side approach
#+begin_src R :results graphics :file heatmap1.png
#difpeak_mtx <- mtx_12b10g[rownames(mtx_12b10g) %in% hetdifgenes,]
#heatDF <- cbind(hetdifDF[,-4], difpeak_mtx)

## gm_sidebyside_heatmap <- function(contrast, family_facet, trans_th){
##   trans_col <- paste0(contrast[1], '-', contrast[2], '_MaxVal')

##   gm_df <- nona_gm_noneighbors %>%
##     select(Gene_id, contains(contrast)) %>%
##     left_join(info_df, by = 'Gene_id') %>%
##     left_join(trans_df, by = 'Gene_id') %>%
##     filter(abs(get(trans_col)) > trans_th)

##   gm_mtx <- gm_df %>%
##     select(contains('bin'))


##   ## Make hierarquical Clustering
##   dmtx <- dist(gm_mtx, method = "euclidean")
##   cl <- hclust(dmtx, method = 'complete')
##   gm_df$Gene_id <- factor(gm_df$Gene_id, levels = gm_df$Gene_id[cl$order])

##   #customHeatmap(gm_df, c(min(gm_mtx), max(gm_mtx)))

##   #head(gm_df)
##   mdf <- melt(gm_df %>% select(-c(contains('MaxVal'), contains('MaxTime'))))
##   mdf["Strain"] <- sapply(mdf$variable, function(x) strsplit(as.character(x), split = "_", fixed = TRUE)[[1]][2])

##   p <- ggplot(mdf, aes(x = variable, y = Gene_id, fill = value)) +

##     geom_tile(colour="snow3") +
##               #size=0.10,
##               #height=.9) +

##     scale_fill_gradient2(midpoint = 0,
##                          low = "white",
##                          high = "red") +

##     scale_y_discrete(position = "right") +

##     theme(
##       strip.background = element_blank(),
##       axis.title = element_blank(),
##       #strip.text.x = element_blank(),
##       axis.line.x = element_blank(),
##       axis.ticks.x = element_blank(),
##       axis.text.x = element_blank()) +

##     facet_grid(~Strain,
##                scales="free_x",
##                space="free")

##   if (family_facet){p <- p+facet_grid(vars(Family), vars(Strain), scales = "free", space = "free")}

##   p

## }

## contrast <- c('E5', 'B11')
## family_facet <- F
## trans_th <- 1.5

## gm_sidebyside_heatmap(contrast, family_facet, trans_th)
#+end_src
*** Max trans Dif. Approach
#+begin_src R
## tdf <- transFC_df_noNAs %>%
##   select(Gene_id, Max_aMAFC, On_trans, Off_trans, Is_3D7B)

## gmodel_noneighbors_pos <- gmodel_noneighbors %>%
##   mutate(across(-Gene_id, ~ ifelse(.x > 0, .x, 0)))

## ## Create empty DF
## hetcols <- gmodel_noneighbors %>%
##   select(contains('12B') & contains('bin')) %>%
##   colnames(.) %>%
##   gsub('12B', '', ., fixed=TRUE)

## col_names <- c('Gene_id',
##                paste0(hetcols, 'On'),
##                paste0(hetcols, 'Off'),
##                paste0(hetcols, 'Dif'))

## cn <- setNames(rep('', length(col_names)), col_names)
## df <- bind_rows(cn)[0,]

## ## Traverse max trans. df and get coverage cols

## for (i in 1:dim(tdf)[1]){

##   gid <- as.character(tdf$Gene_id[i])
##   on <- tdf$On_trans[i]
##   off <- tdf$Off_trans[i]

##   ## Select contrast in which difference sign must be switched
##   ## contrast <- paste0(on, '-', off)
##   ## positive_contrasts <- c(
##   ##   '12B-10G', '12B-A7', '12B-E5', '12B-B11',
##   ##   '10G-A7', '10G-E5', '10G-B11',
##   ##   'A7-E5', 'A7-B11',
##   ##   'B11-E5'
##   ## )

##   ## ifelse(
##   ##   contrast %in% positive_contrasts,
##   ##   neg_dif <- FALSE,
##   ##   neg_dif <- TRUE
##   ## )

##   ### Main Loop
##   if (gid %in% gmodel_noneighbors_pos$Gene_id & !is.na(on) & !is.na(off)){

##     onvect <- gmodel_noneighbors_pos %>%
##       filter(Gene_id == gid) %>%
##       select(contains(on))

##     offvect <- gmodel_noneighbors_pos %>%
##       filter(Gene_id == gid) %>%
##       select(contains(off))

##     diffvect <- onvect-offvect
##     #if (neg_dif) {diffvect <- -diffvect}

##     row <- c(gid,
##              unlist(onvect, use.names = F),
##              unlist(offvect, use.names = F),
##              unlist(onvect-offvect, use.names = F))
##     row <- setNames(row, col_names)
##     df <- df %>% add_row(bind_rows(row))
##   }
## }

## df <- df %>%
##   mutate(across(-Gene_id, as.numeric))

## gm_noneighbors_pos_maxtrans <- df %>%
##   full_join(tdf, by = 'Gene_id') %>%
##   left_join(info_df) %>%
##   mutate(Max_aMAFC = abs(Max_aMAFC))

#+end_src
*** Max trans Dif. Heatmap
#+begin_src R

## heatMap_allstrains_trans <- function(df, aMAFC_th, family, family_facet){

##   ## Returns a list object with list = (df, plot)

##   df
##   subset_all <- df %>%
##     filter(abs(Max_aMAFC) > aMAFC_th)

##   if (!is.na(family)){
##     subset_all <- subset_all %>%
##       filter(Family == family)
##   }

##   subset_all <- subset_all %>%
##     filter(across(
##       contains('bin'),
##       complete.cases
##     ))

##   mtx <- subset_all %>%
##     select(contains('_On') | contains('_Off'))

##   ## Make hierarquical Clustering
##   dmtx <- dist(mtx, method = "euclidean")
##   cl <- hclust(dmtx, method = 'complete')
##   subset_all$Label <- factor(subset_all$Label, levels = subset_all$Label[cl$order])
##   subset_all['Cluster'] <- cutree(cl, nclust)
##   subset_all$Label <- factor(subset_all$Label, levels = subset_all$Label[cl$order])

##   subset_trans <- subset_all %>%
##     select(Gene_id, Max_aMAFC, Label, Name, Annot, Family, SubFamily, Cluster)

##   subset_het_on <- subset_all %>%
##     select(Gene_id, Label,
##            contains('On') & contains('bin'),
##            Name, Annot, Family, SubFamily, Cluster)

##   subset_het_off <- subset_all %>%
##     select(Gene_id, Label,
##            contains('Off') & contains('bin'),
##            Name, Annot, Family, SubFamily, Cluster)

##   ##write_csv(subset_het %>% select(-contains('bin')) %>% arrange(Cluster), './het_trans_genemodel.csv')

##   subset_hetDif <- subset_all %>%
##     select(Gene_id, contains('_Dif'), Label, Name, Annot, Family, SubFamily, Cluster)

##   melt_vars <- c('Gene_id', 'Label', 'Name', 'Annot', 'Family', 'SubFamily', 'Cluster')
##   mdf_het_on <- melt(subset_het_on, id.vars = melt_vars)
##   mdf_het_off <- melt(subset_het_off, id.vars = melt_vars)
##   mdf_trans <- melt(subset_trans, id.vars = melt_vars)
##   mdf_hetDif <- melt(subset_hetDif, id.vars = melt_vars)

##   het_plot_on <- hetHeatmap(mdf_het_on, family_facet) +
##     facet_grid(Cluster ~., scales = "free_y", space = "free") +
##     theme(
##       axis.text.y = element_blank(),
##       axis.ticks.y = element_blank(),

##       panel.border=element_blank(),
##       panel.grid.major=element_blank(),

##       strip.background = element_blank(),
##       strip.text.x = element_blank(),
##       strip.text.y = element_blank(),
##       )


##   het_plot_off <- hetHeatmap(mdf_het_off, family_facet) +
##     facet_grid(Cluster ~., scales = "free_y", space = "free")

##   trans_plot <- transHeatmap(mdf_trans, family_facet) +
##     scale_fill_gradient(low = "white",
##                         high = "blue",
##                         na.value="gray",
##                         limits = c(0,NA))  +
##     facet_grid(Cluster ~., scales = "free_y", space = "free")

##   hetDif_plot <- hetDifHeatmap(mdf_hetDif, family_facet) +
##     facet_grid(Cluster ~., scales = "free_y", space = "free")

##   all_plot <- grid.arrange(hetDif_plot, het_plot_on, het_plot_off, nrow = 1, widths = c(1,1,2))

##   result <- list(df = subset_all %>% arrange(Label), plot = all_plot)
##   return(result)
## }


## ##info_df %>% select(Family) %>% pull() %>% unique()

## aMAFC_th <- 2
## family_facet <- F
## family <- NA
## nclust <- 8
## df <- gm_noneighbors_pos_maxtrans ##%>% filter(is.na(Family))

## x <- heatMap_allstrains_trans(df, aMAFC_th, family, family_facet)

## x$df %>%
##   select(Gene_id, Annot, Max_aMAFC, On_trans, Off_trans, Variant, Cluster) %>%
##   filter(Cluster == 6)

## #ggsave('./Plots/current_genemodel_plot.pdf', x$plot, device = 'pdf', height = 40, width = 60, units = 'cm')

## x$df %>%
##   select(-contains('bin')) %>%
##   select(Label, Annot, Family)

## all_noneighbors_gmodel_heat <- x$df

## trans_df %>%
##   filter(Gene_id == 'PF3D7_0713100') %>%
##   print(width = 400)

## ## Plot by Family

## for (family in info_df %>% select(Family) %>% pull() %>% unique()){

##   aMAFC_th <- 1
##   family_facet <- F
##   nclust <- 3
##   df <- gm_pos_maxtrans
##   n <- dim(gm_pos_maxtrans %>% filter(Family == family & abs(Max_aMAFC) > aMAFC_th))[1]

##   if (n >= nclust & !is.na(family)){
##     plotname <- paste0('./Plots/Gene_Model/genemodel_positive_complete_noneighbors_', family, '.svg')
##     csvname <- paste0('./Gene_Model_Tables/', family, '_log2trans_', aMAFC_th, '.csv')

##     x <- heatMap_allstrains_trans(gm_pos_maxtrans, aMAFC_th, family, family_facet)

##     ggsave(plotname, x$plot, device = 'svg')
##     write_csv(x$df %>% select(-contains('bin')), csvname)
##   }
## }

## ## Plot the "NA" Family

## aMAFC_th <- 2
## family_facet <- F
## family <- NA
## nclust <- 3
## df <- gm_pos_maxtrans %>%
##   filter(is.na(Family) & !Is_tRNA)
## x <- heatMap_allstrains_trans(df, aMAFC_th, family, family_facet)
## plotname <- paste0('./Plots/Gene_Model/genemodel_positive_complete_noneighbors_', family, '.svg')
## csvname <- paste0('./Gene_Model_Tables/', family, '_log2trans_', aMAFC_th, '.csv')
## ggsave(plotname, x$plot, device = 'svg')
## write_csv(x$df %>% select(-contains('bin')), csvname)



#+end_src
*** Max trans Dif. Tendency Plots
#+begin_src R
## my_tendency_plot_sides <- function(df, cluster){

##   max_y <- max(df %>% select(contains('bin')))
##   min_y <- min(df %>% select(contains('bin')))

##   on <-  df %>%
##     select(Gene_id, contains('On'), Cluster) %>%
##     filter(Cluster == cluster) %>%
##     select(-Cluster)

##   plot_on_df <- melt(on) %>%
##     mutate(variable = as.numeric(gsub('_On', '', gsub('bin', '', variable))))

##   p_on <- ggplot(plot_on_df, aes(x = variable, y = value))
##   p_on <- p_on + geom_smooth(method = 'loess', level = 0.95, color = 'green')
##   p_on <- p_on + ylim(min_y, max_y)


##   off <-  df %>%
##     select(Gene_id, contains('Off'), Cluster) %>%
##     filter(Cluster == cluster) %>%
##     select(-Cluster)

##   plot_off_df <- melt(off) %>%
##     mutate(variable = as.numeric(gsub('_Off', '', gsub('bin', '', variable))))

##   p_off <- ggplot(plot_off_df, aes(x = variable, y = value))
##   p_off <- p_off + geom_smooth(method = 'loess', level = 0.95, color = 'red')
##   p_off <- p_off + ylim(min_y, max_y)

##   title = paste0('Cluster ', as.character(cluster))
##   all_plot <- grid.arrange(p_on, p_off, nrow = 1, widths = c(1,1), top = title)
## }

## my_tendency_plot_overlapped <- function(df, cluster){

##   max_y <- max(df %>% select(contains('bin')))
##   min_y <- min(df %>% select(contains('bin')))

##   plt_df <-  df %>%
##     select(Gene_id, contains('On'), contains('Off'), Cluster) %>%
##     filter(Cluster == cluster) %>%
##     select(-Cluster)

##   plot_mdf <- melt(plt_df)
##   head(plot_mdf)

##   plot_mdf['State'] <- sapply(plot_mdf$variable, function(x) str_split(x, '_')[[1]][2])
##   plot_mdf <- plot_mdf %>%
##     mutate(variable = as.numeric(sub("bin(\\d+).*", "\\1", variable)))

##   head(plot_mdf)

##   p <- ggplot(plot_mdf, aes(x = variable, y = value, group = State))
##   p <- p + geom_smooth(aes(color = State), method = 'loess', level = 0.95)
##   p <- p + ylim(min_y, max_y)
##   p <- p + scale_color_manual(values = c('red', 'green'))
##   p <- p + ggtitle(paste0('Cluster ', cluster))
##   p
## }

## ## 1 cluster plots
## my_tendency_plot_sides(all_noneighbors_gmodel_heat, 5)
## my_tendency_plot_overlapped(all_noneighbors_gmodel_heat, 5)

## ## All cluster plots, side-by-side
## nclust <- length(unique(all_noneighbors_gmodel_heat$Cluster))

## plots <- lapply(1:nclust, function(x) my_tendency_plot_sides(all_noneighbors_gmodel_heat, x))
## clusters_plot <- grid.arrange(grobs = plots, nrow = length(plots), ncol = 1)

## ggsave(
##   paste0('./Plots/clusters_plot_sides.pdf'),
##   clusters_plot,
##   height = 80, width = 15, units = 'cm',
##   device = 'pdf'
## )


## plots <- lapply(1:nclust, function(x) my_tendency_plot_overlapped(all_noneighbors_gmodel_heat, x))
## clusters_plot <- grid.arrange(grobs = plots, nrow = length(plots), ncol = 1)

## ggsave(
##   paste0('./Plots/clusters_plot_overlapped.pdf'),
##   clusters_plot,
##   height = 80, width = 15, units = 'cm',
##   device = 'pdf'
## )




#+end_src
*** Max trans Dif. Heatmap Donuts
#+begin_src R
## Donut Plot

## ## Create 'fixed' color palette
## all_fams <- c('Not CVGs',
##               'Other CVGs',
##               '6-CYS',
##               'ACBP',
##               'ACS',
##               'CLAG',
##               'DNAJ',
##               'GBP',
##               'PFMC-2TM',
##               'SURFIN',
##               'FIKK',
##               'HYP',
##               'PHIST',
##               'STEVOR',
##               'RIFIN',
##               'VAR')

## col_factor <- factor(all_fams, levels=all_fams)

## my_colors <- c('gray', scales::viridis_pal()(15))
## names(my_colors) <- levels(col_factor)
## my_scale_dount <- scale_fill_manual(name = "Family_Grouped", values = my_colors)


## donut_df <- all_gmodel_heat %>%
##   mutate(Family_Dount = case_when(
##            Family %in% col_factor ~ Family,
##            Family == 'OTHER' ~ 'Other CVGs',
##            is.na(Family) ~ 'Not CVGs'))


## donut_plot <- function(df, cluster) {
##     x <- df %>%
##       filter(Cluster == cluster)

##     data <- as.data.frame(table(x$Family_Grouped))
##     colnames(data) <- c('category', 'count')

##     count(info_df, Family)

##     ## Compute percentages
##     data$fraction = data$count / sum(data$count)

##     ## Compute the cumulative percentages (top of each rectangle)
##     data$ymax = cumsum(data$fraction)

##     ## Compute the bottom of each rectangle
##     data$ymin = c(0, head(data$ymax, n=-1))

##     ## Compute label position
##     data$labelPosition <- (data$ymax + data$ymin) / 2

##     ## Compute a good label
##     data$label <- paste0(data$category, "\n value: ", data$count)

##     ## Make the plot
##     p <- ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category)) +
##       geom_rect(color="white") +
##       #geom_label( x=4.2, aes(y=labelPosition, label=label), size=3) +
##       coord_polar(theta="y") + # Try to remove that to understand how the chart is built initially
##       xlim(c(2, 4)) +# Try to remove that to see how to make a pie chart
##       theme_void() + my_scale

##     outname <- paste0('./Plots/Donuts/gmodel_hetmap_cluster_noneighbors',
##                       as.character(cluster),
##                       '.svg')
##     #ggsave(outname, p, device = 'svg')
##     p
## }

## count(all_noneighbors_gmodel_heat, Cluster)

## p1 <- donut_plot(all_noneighbors_gmodel_heat, 1)
## p2 <- donut_plot(all_noneighbors_gmodel_heat, 2)
## p3 <- donut_plot(all_noneighbors_gmodel_heat, 3)
## p4 <- donut_plot(all_noneighbors_gmodel_heat, 4)
## p5 <- donut_plot(all_noneighbors_gmodel_heat, 5)
## p6 <- donut_plot(all_noneighbors_gmodel_heat, 6)
## p7 <- donut_plot(all_noneighbors_gmodel_heat, 7)
## p8 <- donut_plot(all_noneighbors_gmodel_heat, 8)

## all_donuts <- grid.arrange(p1, p2, p3, p4, p5, p6, p7, p8,  nrow = 8, ncol = 1)
## ggsave('./Plots/Donuts/gmodel_heatmap_alldonuts.svg', all_donuts, device = 'svg')


## ## Plot all genes to get legend
## ## all_genes_donut <- info_df %>%
## ##   mutate(Family_Dount = case_when(
## ##            Family %in% col_factor ~ Family,
## ##            Family == 'OTHER' ~ 'Other CVGs',
## ##            is.na(Family) ~ 'Not CVGs'))


## data <- as.data.frame(table(info_df$Family_Grouped))
## colnames(data) <- c('category', 'count')

## count(info_df, Family)

## ## Compute percentages
## data$fraction = data$count / sum(data$count)

## ## Compute the cumulative percentages (top of each rectangle)
## data$ymax = cumsum(data$fraction)

## ## Compute the bottom of each rectangle
## data$ymin = c(0, head(data$ymax, n=-1))

## ## Compute label position
## data$labelPosition <- (data$ymax + data$ymin) / 2

## ## Compute a good label
## data$label <- paste0(data$category, "\n value: ", data$count)

## ## Make the plot
## p <- ggplot(data, aes(ymax=ymax, ymin=ymin, xmax=4, xmin=3, fill=category)) +
##   geom_rect(color="white") +
##                                         #geom_label( x=4.2, aes(y=labelPosition, label=label), size=3) +
##   coord_polar(theta="y") + # Try to remove that to understand how the chart is built initially
##   xlim(c(2, 4)) +# Try to remove that to see how to make a pie chart
##   theme_void() + my_scale

## ggsave('./Plots/Donuts/all_genes_donut.svg', p, device = 'svg')
## p


## ## Create 'fixed' color palette
## col_factor <- factor(unique(analysis_df$Family_Grouped),
##                      levels=c('Not CVGs',
##                               'Other CVGs',
##                               'FIKK',
##                               'HYP',
##                               'PHIST',
##                               'STEVOR',
##                               'RIFIN',
##                               'VAR'))

## my_colors <- c('gray', scales::viridis_pal(begin = 0, end = 1)(7))
## names(my_colors) <- levels(col_factor)
## my_scale <- scale_fill_manual(name = "Family_Grouped", values = my_colors)
#+end_src
** Save/load environtment
#+begin_src R
#### Save/load environtment ####
#save.image('binned_coverage_021121.RData')
setwd('/mnt/Disc4T/Projects/PhD_Project/Binned_Coverage/')
#load('binned_coverage_061021.RData')
#+end_src
* Notes
+ Paper: PMID:31390575 [[https://www.ncbi.nlm.nih.gov/pubmed/31390575]] Uses an
interesting Random Forest implementation to create a prtein-interaction netwrok.
+ Idea: Mirar l'slope de ls gens que han perdut heterochromatina comparat amb
els que en tenen. Els que en tenen tenen lÃ­mits molt clar i els que no fa una
pujada suau. Inidicatiu de que Ã©s un fenÃ²men progressiu?
+ QuÃ¨ passa amb els spikes a non coding regions? Estudiar.
+ Slopes sense gens: gens que han desaparegut?
+ Quasi tots els gens amb diferÃ¨ncies transcripcionals sense diferÃ¨ncies
d'heterochromatina estÃ n en zones heterocromÃ tiques.
+ Dos tipus de canvis d'het. grans zones en sec/ "bomba".
+ Crear parÃ metre gens het en telÃ²mers/ gens het a "illes".
* Old scripts
*** Get Trans for ON/OFF genes
#+begin_src R
#### Get On/OFF genes ####
## Select ON-OFF by transcription

contrasts <- colnames(trans_df %>% select(contains('MaxVal')))#, -`12B-3D7B_MaxVal`, -`10G-3D7B_MaxVal`))

getMaxMin <- function(x, contrasts){
  y <- abs(x)
  if (all(is.na(y))){
    return(list(NA, NA, NA, NA))
  } else {
    pos <- which.max(y)
    maxVal <- x[pos]
    maxContrast <- contrasts[pos]
    maxTime <- gsub('MaxVal', 'MaxTime', maxContrast, fixed = T)
    strains <- strsplit(maxContrast, split = '_', fixed = T)[[1]][1]
    strains <- strsplit(strains, split = '-', fixed = T)[[1]]
    if (maxVal >= 0){
      On <- strains[1]
      Off <- strains[2]
    } else {
      On <- strains[2]
      Off <- strains[1]
    }
    return(list(maxVal, On, Off, maxTime))
  }
}

maxTrans_df <- trans_df %>%
  mutate(Max_aMAFC = apply(select(., contains('MaxVal')), 1, function(x) getMaxMin(x, contrasts )[[1]])) %>%
  mutate(Max_Time = apply(select(., contains('MaxVal')), 1, function(x) getMaxMin(x, contrasts )[[4]])) %>%
  mutate(On_trans = apply(select(., contains('MaxVal')), 1, function(x) getMaxMin(x, contrasts)[[2]])) %>%
  mutate(Off_trans = apply(select(., contains('MaxVal')), 1, function(x) getMaxMin(x, contrasts)[[3]])) %>%
  rowwise() %>%
  mutate(Max_Time = ifelse(!is.na(Max_Time), get(Max_Time), NA)) %>%
  ungroup() %>%
  select(Gene_id, Max_aMAFC, Max_Time, On_trans, Off_trans, contains('MaxVal'), contains('MaxTime'), everything()) %>%
  arrange(desc(abs(Max_aMAFC)))

maxTrans_df %>%
  count(On_trans)

## print(maxTrans_df) %>%
##   print(width = 400, n = 20)

new_array_areas <- read_csv('/mnt/Disc4T/Projects/PhD_Project/Microarrays/New_Old_separate_approach/New_Arrays/R_results_NewArray/area_geneLevel.csv') %>%
  select(-name, -Annot, -Variant)

max_trans_newarray <- maxTrans_df %>%
  left_join(new_array_areas)

get_new_onoff <- function(gid) {

  on <- max_trans_newarray %>%
    filter(Gene_id == gid) %>%
    select(On_trans) %>%
    pull()

  off <- max_trans_newarray %>%
    filter(Gene_id == gid) %>%
    select(Off_trans) %>%
    pull()

  time <- max_trans_newarray %>%
    filter(Gene_id == gid) %>%
    select(Max_Time) %>%
    pull()

  onoff <- TRUE
  if (is.na(on) | is.na(off)){
    onoff <- FALSE
  } else {
    if (on == '3D7B') {func <- which.max}
    if (off == '3D7B') {func <- which.min}
    if (on != '3D7B' & off != '3D7B') {onoff <- FALSE}
  }

  if (is.na(time)){
    out <- NA
  } else if (!onoff){
    out <- NA
  } else {
    strains <- c('A7', 'B11', 'E5')

    vect <- max_trans_newarray %>%
      filter(Gene_id == gid) %>%
      select(contains(time))

    ifelse(all(is.na(vect)), out <- NA, out <- strains[func(vect)])
  }
  return(out)
}

newonoffs <- sapply(max_trans_newarray$Gene_id, get_new_onoff)
maxTrans_df['New_OnOffs'] <- newonoffs
max_trans_newarray['New_OnOffs'] <- newonoffs

max_trans_newarray %>%
  select(Gene_id, On_trans, Off_trans, New_OnOffs) %>%
  print(n = 50)


maxTrans_df <- maxTrans_df %>%
  mutate(On_trans = ifelse(On_trans == '3D7B',
                           New_OnOffs,
                           On_trans)) %>%
  mutate(Off_trans = ifelse(Off_trans == '3D7B',
                           New_OnOffs,
                           Off_trans)) %>%
  mutate(Is_3D7B = !is.na(New_OnOffs)) %>%
  select(-New_OnOffs)

write_csv(maxTrans_df, 'maxTrans_df.csv')
write_csv(max_trans_newarray, 'maxTrans_3D7B_df.csv')

#+end_src

* TODO's
** TODO Curate and upload datasets on mosquito and gams:
- Elena GÃ³mez diaz (Scientific reports?)
- Fraschka et al -> gens de gams
- Oriol gens de gams: in External_Data/Sexual_ring_markers_FCabove2.xlsx
** TODO Cross Fraschka's list with our ChIPs
